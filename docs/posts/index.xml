<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The curse of λ</title>
    <link>https://myuon.github.io/posts/</link>
    <description>Recent content in Posts on The curse of λ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Mon, 30 Dec 2019 22:18:25 +0900</lastBuildDate>
    
      <atom:link href="https://myuon.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>2019年を振り返って</title>
        <link>https://myuon.github.io/posts/end-of-2019/</link>
        <pubDate>Mon, 30 Dec 2019 22:18:25 +0900</pubDate>
        <guid>https://myuon.github.io/posts/end-of-2019/</guid>
        <description>2019年も終わりそうなので振り返ります。色々あったような気もするし大していつもと変わらなかったような気もする。
草 GitHubの草
 初めて年間で4000contributionを超えたけど下半期は仕事でこのアカウントを使うようになったこともあり仕事の分が結構入ってしまっている。趣味だけだと3000弱くらい？(たぶん)
仕事など 夏くらいに転職しました。無職期間が3週間くらい(最初の1週間は有給消化期間だったので本当に雇用されてなかったのは2週間くらい)あったが、一生無職でいいなという気持ちになった。今も年末年始で少し長い休みだけど、一生こんな感じがいいなと思っている。人間は労働するようには出来ていない。
仕事ではGoでWebサービス作ったりRustでWebサービス作ったりTypeScriptとReactでWebサービスの画面を作ったりなどしている。仕事のおかげで今年一番伸びたスキルはReactな気がする。あとAWS？
&amp;ldquo;ふつうの&amp;rdquo;(ふつうとは)Webサービスのバックエンドやるならまず間違いなくGoが一番無難な選択肢だと思うけど、様々な罠を乗り越え不便を破壊する強い意志があればRustでもまぁ普通に開発できるなという知見を得られたのは良かった。来年はdieselを破壊する(予告)。
日曜定理証明士 そういえば今年は定理証明士として証明を書くなどしていた。記事も書いた。
https://myuon.github.io/posts/isabelle-cbc-casper-safety-proof/
趣味開発 何か色々やっていた気がするけど記憶があんまない。
 ghc-compiler-notes: GHCのソースコードのコメントを読むやつ。ブログも書いたが結構良い感じの仕上がりになった気がする。たまにGHCについてググるとヒットしたりして笑ってしまう。 debil: Rust製のORM。ある程度ちゃんと仕上げたらdieselを破壊して仕事で使おうかと目論んでいる。 minilight: Haskell製のグラフィックエンジン。ゲームを作るために作ったが、yamlで設定を書くのはつらい+Haskellでコードスワップをやるのは本当にしんどいという(当然の)結論に至る。 quartz: 自作言語のインタープリター。minilightと組み合わせてゲームを記述するスクリプト言語として使う。 あと趣味でWebサービスを作ったりなどしていたが正式リリースすら出来てない。来年気が向いたら続きやろうかと思っているが果たして。  直近ではminilightとquartzの開発を主にやっていた。言語を作るという、ある種憧れにも近いが特にやる意味を感じなくて今までやらなかったことを、いよいよ手を付けるというのはこんな気持ちなんだなと思ったりした。世の言語はよく考えられてるなと振り返って思うことが多かった気がする。
あと早くゲームを作りたい。ゲームエンジンを作ろう/言語を作ろうと思い立った瞬間は「こいつマジでゲームを作る気がないな」と思っていたものだがここにきてゲームを作るためのものが着々と揃いつつあるので来年は本当に作っていきたい所存。
その他 昨年にも増して漫画買ったりゲーム買ったりしていた気がするが、昨年の記憶がないのでヨクワカラナイ。
ブログは11本くらい書いていたらしい。
勉強はそこそこしてたような？通勤時間で本を読めることに気がついてから下半期は本もちょこちょこ読んでいた気がする。
どうでもいいがいい加減ブログを作り直したい。hugoをやめたい。
来年に向けて 今年の抱負は最強になることだったらしい。来年の抱負は魔王になることかな…。</description>
      </item>
    
      <item>
        <title>IsabelleによるCBC CasperのSafetyの証明をしました</title>
        <link>https://myuon.github.io/posts/isabelle-cbc-casper-safety-proof/</link>
        <pubDate>Sun, 27 Oct 2019 15:33:19 +0900</pubDate>
        <guid>https://myuon.github.io/posts/isabelle-cbc-casper-safety-proof/</guid>
        <description>日記です。
リポジトリ: LayerXcom/cbc-casper-proof
概要 (私は LayerX の人ではないですが)LayerX 社の人と色々あって CBC Casper というブロックチェーンのプロトコルの検証作業を行いました。(主に定理証明士としてのお手伝い)
半年くらいかかったけどやりたかった証明についにたどり着いたよという話。
CBC Casper って何 わからん。(無知)
何かブロックチェーンのプロトコルの名前らしい。Ethereum 財団が目をつけてるらしい。いわゆるビットコインとは違ってブロックを頑張ってマシンをぶん回してマイニングしたりしないらしい(ビットコインは PoW で CBC Casper は PoS)。
詳しいことは詳しい人に聞いたほうがいいよ(真理)。
cf: CBC Casper と形式的検証
Isabelle で検証って何するの ブロックチェーンはコンセンサス(分散合意)アルゴリズムの一種で、みんなで合意を取りましょうみたいなやつ。コンセンサスアルゴリズムで言われる正当性というのは主に次の 2 つ。
 Safety: 1 つの round でたかだか 1 つの値にしか合意しないこと Liveness: 必ず 1 つの値にいずれは合意できること(一生合意できないみたいな状態に陥らないこと)  実際のステートメントでは色々条件はあるがそういうのは一旦おいておいて、CBC Casper に対しては Safety は示されていて(論文があり) Liveness はまだ示されていないみたいなステータスだったはず。定理証明はどちらもされていないので、今回は簡単な(というか参考になる論文がすでにある)Safety の方を示した。
実際の証明について 証明は基本的に論文に沿って進めた: https://github.com/cbc-casper/cbc-casper-paper
ただし Safety Oracle の証明について、論文では clique というタイプのグラフについての性質を示すことで証明を行っているが、今回はこれを inspector(finality detector)というやつに一般化して証明を行った。
完走した感想 ドメイン知識がないこともあってめっちゃ大変だったというのが正直なところ。アタリマエであるが、論文に書いてない行間を埋める作業や誤植・足りない仮定を追加するなどの作業はちゃんと理論側の理解がないとやはりつらい。
一方で、今回は「理論側は別の人・定理証明は私」という分担を行ったが、そういう感じでもこういう証明の仕事を行うことは不可能ではないなという手応えを感じることが出来たのも良かった気がする。
証明がめっちゃ汚いのとまだ一般化する余地がそれなりに残っているので(あと Liveness の証明という大仕事も手付かずだし…)、気が向いたらまた続きをやりたいと思います。</description>
      </item>
    
      <item>
        <title>Genericなデータマッパーを書いた</title>
        <link>https://myuon.github.io/posts/database-generic-mapper/</link>
        <pubDate>Sat, 28 Sep 2019 17:15:06 +0900</pubDate>
        <guid>https://myuon.github.io/posts/database-generic-mapper/</guid>
        <description>まだライブラリとしては公開してませんが
背景 Haskell でサーバーサイドを書いてみようと思い立って色々やっていたところ、ORM 的なものが欲しい気持ちになってきた。 業界では persistent がデファクト感あるが、思ったほど細かいところに手が届かない(？)上にドキュメントが全然なくて使う気がなくなったので自分なりに解決策を考えた結果 database-generic-mapper というパッケージを作るに至った。
(実際のところ私は全然 persistent の全容を把握していない、そもそもドキュメントがないので把握のしようがない)
ていうか Generic Programming なるものを初めてやったけど普通に便利だった。TH より簡単で使いやすいのでアイデア次第で色々できそうではある(今更〜〜〜〜)。
database-generic-mapper database と銘打ってるが実体はただの record mapper 的な何かである。
特徴:
 Generic インスタンスなレコードと値の列を mapping してくれるやつ(DB にデータを保存することを考えると mapping するレコードは Generic インスタンスになっていると仮定しても良いだろうという感じで) TH なし 実際のデータのマッピングはライブラリ側の型クラスを使っているので自分で型を定義してインスタンスを書けば挙動はカスタマイズ可能 私は一応 MySQL で使ってるが特に DB 依存はない気がする(ただしマッピングされる先の型はライブラリ側で定義されてるものから選ぶ必要はある) 本当に誰でも思いつきそうな仕組みなので絶対すでに作られてるでしょって思って調べたけど見つからなかった…何でみんな TH するんだ…レコード定義したくないのか…  使い方 適当なデータ型を定義する。制約を書きたいときは幽霊型に載せる(これは attribute として後で文字列のリストとして取得可能)
mapper は (:-) だけは特別扱いしていて、 a :- xs を後で (a,[String]) の型に mapping する(:-ではないときは、 (a,[])に mapping する)
data Sample = Sample { key :: VarChar 20 :- &amp;#39;[&amp;#34;PRIMARY KEY&amp;#34;], -- 制約書きたいときは (:-) を使う name :: BigInt :- &amp;#39;[&amp;#34;NOT NULL&amp;#34;], single :: String } deriving (Eq, Show, Generic) -- レコードのフィールドは全て次の型クラスのインスタンスである必要がある -- SQLValuesはStringやIntなどのunion class SQLField a where fieldType :: a -&amp;gt; String encode :: a -&amp;gt; SQLValue decode :: SQLValue -&amp;gt; a MySQL で使う都合上、 VarChar (s :: Nat) や BigInt を定義しているがこれらはインスタンスを導出するためのただの newtype wrapper である(実体は Text や Int64 など)</description>
      </item>
    
      <item>
        <title>Pipeline Resolverを使ったAppSync Authorizerパターン</title>
        <link>https://myuon.github.io/posts/pipeline-resolver-authorizer/</link>
        <pubDate>Sun, 16 Jun 2019 14:26:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/pipeline-resolver-authorizer/</guid>
        <description>調べたけどあんまり情報がなかったので。
AppSync Pipeline Resolver AppSyncにはPipeline Resolverというリゾルバーがあり、これによって複数のリゾルバーを指定できる、とある。
CFnにはfunctionConfigurationを指定するといいよと書いてある。serverless-appsync-pluginだと次のように書ける。
custom:appSync:mappingTemplates:-type:Queryfield:testPipelineQueryrequest:&amp;#39;./mapping-templates/before.vtl&amp;#39;# the pipeline&amp;#39;s &amp;#34;before&amp;#34; mapping templateresponse:&amp;#39;./mapping-templates/after.vtl&amp;#39;# the pipeline&amp;#39;s &amp;#34;after&amp;#34; mapping templatekind:PIPELINEfunctions:-authorizeFunction-fetchDataFunctionfunctionConfigurations:-dataSource:graphqlLambdaname:&amp;#39;authorizeFunction&amp;#39;request:&amp;#39;./mapping-templates/authorize-request.vtl&amp;#39;response:&amp;#39;./mapping-templates/common-response.vtl&amp;#39;-dataSource:dataTablename:&amp;#39;fetchDataFunction&amp;#39;request:&amp;#39;./mapping-templates/fetchData.vtl&amp;#39;response:&amp;#39;./mapping-templates/common-response.vtl&amp;#39;でこれが意外とわかりにくいのだがドキュメントをよく読むと次のような意味であることがわかる。
 リゾルバーに対して指定できる処理の単位を&amp;quot;function&amp;quot;とここでは呼んでいる functionを複数指定すると、それぞれが順番に実行される functionには(通常のリゾルバー同様)リクエスト・レスポンスマッピングテンプレートを指定する 上記とは別に、pipelineの最初と最後にマッピングテンプレートを指定する DynamoDBリゾルバー、Lambdaリゾルバーも内部では1つの&amp;quot;functionからなる&amp;rdquo; Pipeline ResolverでLambdaに通してからDynamoDBに送るみたいなことをしたいなら2つのfunctionをlambda dataSource, dynamodb dataSourceを指定して作成する必要がある  で、上のような例だと次のように処理が進む
before mapping template ↓ authorizeFunction request mapping template ↓ authorizeFunction本体 ↓ authorizeFunction response mapping template ↓ fetchDataFunction request mapping template ↓ fetchDataFunction本体 ↓ fetchDataFunction response mapping template ↓ after mapping template functionという概念はpipeline resolverにしか出てこないが他のリゾルバーでも内部的には使われてるとみなして良いと思う。
Authorizer 上の例でもあるように、DyanmoDB Resolverにcustom authorizerを付けたいというようなユースケースではPipeline Resolverを使うのが良い。
設定例を以下に示す。</description>
      </item>
    
      <item>
        <title>GHC Coreのパーサー書いてたけど諦めた</title>
        <link>https://myuon.github.io/posts/giving-up-core-parser/</link>
        <pubDate>Tue, 21 May 2019 23:25:02 +0900</pubDate>
        <guid>https://myuon.github.io/posts/giving-up-core-parser/</guid>
        <description>-ddump-simpl で出力されるSimplified Coreをいい感じに解析して読めるやつを作ろうかと思ってたけどつらすぎたので(少なくともこの方針では)やめた。
以下愚痴を述べますがこれは私が結構無理なことをやろうとしているだけでGHCに(そこまで)非はないと思うし直してくれという意味で言ってるわけでもない。いや直してくれるならありがたいんだけど。
様子 様子です
CoreSyn CoreSynにCoreのSyntaxがある。ASTが用意されてて便利〜かと思いきや、これがなんとコンストラクタが公開されてないものがある(TypeとかCoercionとか)。
まずこの時点で嫌な予感がするよねという感じ。CoreSynは自作することになる。
PprCore -ddump-simplの出力フォーマットはPprCoreによって制御されている。中を読むとわかるがこれが実はASTとあまり対応がない。
ASTに乗ってない情報が付加されていたり、あるいはASTの情報が一部出力されてなかったりする。
そもそもPprCoreは何かしらの規則やdatatypeに則って書かれたものではなくdumpするという目的を果たすだけのために書かれている感じがありアドホックな処理が大量に入っている。どう考えてもこれに合わせてパーサーを書くとバージョンアップで即死である。
また、面倒な問題の一つにIdInfoがあり、Coreは次のように識別子に関する統計情報をコードに埋め込んで出してくれる。
foobar :: Type [GblId, Str=&amp;lt;S,U&amp;gt;, Unf=Unf{...なんやらかんやら, Guidance=ALWAYS_IF(arity=0,unsat_ok=True,boring_ok=True) Tmpl= piyo `cast` ..}] foobar = ... 当然こんなものを埋め込まれてもHaskellのコードとしてはvalidでないため、ここで専用のパーサーを書かなければいけないこともほぼ確定である。idinfoだけ剥がしてexpressionは組み込みのを使う手もあるがそれも後述の理由により多分上手く行かない。
また、上のCoreコードは実際にあるようなものであるが、他のフィールド間には区切りのカンマがあるのに Tmpl の前にはカンマがないことや Guidance だけなぜかHaskellのレコード構文と全然違う謎の構文になっているなど、不可解な点が多々ある。まぁ細かいことを気にしてはいけないのかもしれない。
識別子 ここまでで、パーサーとASTを自作することになった。Lexerはまぁなんとかなるだろうと期待したいところであるが、実はLexerですらGHC提供のものでは動かないことを見ていく。
(ちなみにGHCはGHC拡張をオンにするとParserどころかLexerもゴリゴリ挙動が変わるので結構すごいと思う。MagicHashとか典型例ですね。あとはCPP入れると複数行文字列リテラルを改行をエスケープすることで書けるようになるとか。変態的すぎると思う。)
識別子は主に $ 問題と # 問題の2つ？ある。
GHC Coreにはworker/wrapper変換という有名な最適化が入っているがこれにより新たに導入されるworkerには識別子の先頭に $w マークが付与される。ユーザー側で識別子に使えない文字を割り振ることで衝突等を回避してるんだろうか(しかしRenamerとかで上手く処理することも可能な気はする。そうでもないんだろうか)。しかしこれによりLexerが正しくtokenizeできなくなる(Module.$wfoobar は qualified operator Module.$ と varid foobar に分解される)。
次に、出現条件はよくわからないがラムダ式で束縛される変数等で、文字の途中に # 記号が付与されるものがある。 n#_a8qS みたいな。おそらく元々の変数 n に対してrenamerでuniqueな名前が振られた結果こういうコトになっているのだと思われる。これもGHCのLexerは(MagicHashを入れた状態で) n# と _a8qS としかtokenizeできない。
というわけでLexerも自作することになる。
この辺で諦めた ここまで来ていや〜厳しいってなった。Lexer Parser ASTまで自作するとか何と戦ってるんだという感じだしそもそもCoreくらいちゃんと読んでって言われるとまぁそうね…という気持ちになる。そもそもここでこれを頑張ったところでGHCのCore付近は毎バージョンごとにめちゃくちゃ変わりまくるのでどうせすぐ動かなくなると思うとメンテも大変そうだしなぁという後ろ向きな感情しかない。</description>
      </item>
    
      <item>
        <title>Haskellで解くAtCoder</title>
        <link>https://myuon.github.io/posts/haskell-atcoder/</link>
        <pubDate>Sun, 28 Apr 2019 16:44:29 +0900</pubDate>
        <guid>https://myuon.github.io/posts/haskell-atcoder/</guid>
        <description>最近HaskellでAtCoderの問題を解いたりしているのでごく基本的な知見をまとめておく。
テクニック集 多くは割と色んな人がすでに言っていることではある。また、想定解法を正しく実装すれば以下のようなことを守らなくても時間内に収まるだろうが、GHCは最適化が効かなければ10倍遅くなる言語であるので普段から守っておくに越したことはないと思う。
 環境: AtCoderのGHCは2019.04現在7.10なので注意が必要。そのうち上がるかもしれないけど。  Strict拡張がない BangPatterns拡張はある 環境構築がhaskell-platformらしいのでそれに入ってるライブラリしか使えない   文字列  基本はData.ByteString.Chan8 Stringは死んでも使わない(遅いので) Unicode文字列の扱いが必要(今の所みたことないけど)とかならtextを使うといいかもしれない   リスト  リストは遅延リストをイテレータとして利用するだけに限るようにする(それでも全ての要素を走査するならVectorの方が大体速い(fromListのコストは除く)) 添字アクセスと結合は死んでもしない 遅延リストは作って即畳めば最適化によってコストは消えてなくなるので、そういう使い方ならあまり心配はしなくて良い(畳み込みはiループ目にi番目の要素にのみアクセスするように書くこと) 累積和はscan系を使うといいよ   Vector: 基本はData.Vector.Unboxed  BoxedなVectorを使ってサンクを不必要に消費しないコードを書くのは結構難しいのでUnboxedを使うほうが無難 push_backがないのが致命的 グラフの構築とかは困ると思うので事前に何かしら考えておいたほうがいいかも(2秒制限に引っかかるほどではないのであまり気にしなくても良いが) Vectorにはfusionがあるので、遅延リスト同様作って即畳めば最適化によってデータ生成のコストを消すことが出来る 便利なAPI: create, unfoldrN 注意すべきAPI: generate(Boxed Vectorの方は中の要素が遅延される), modify(呼ぶたびにコピーが取られる)   データ構造  その他のデータ構造にほとんど出番はない(Vectorで書けるならVectorで書いたほうが速いことがほとんど) Data.Set: priority queueの実装が面倒な場合 Data.Graph: グラフの構築やdfsが必要で、問題ごとに実装を考えたくない場合   再帰の実装  単なるループはfoldl&#39;, 早期リターンが必要ならfoldr 雑に再帰したいときはControl.Monad.Fix.fixを使っても良い Data.IORefなどはポインタ経由になるので遅い 関数の引数にするかStateを使うこと   GHC最適化系:  繰り返し適用される関数の引数は全てbang patternを付けておくのが安全(foldやscanの中、fixの中、手で書いた再帰関数等)(bang patternにより普通のコードが速くなることはないが、不要なサンクにより無意味に遅いコードは改善される) タプルは中の要素が遅延されるので、タプルを評価するときは全ての要素を個別に評価すること リストも中の要素が遅延されるが、中の要素を個別に評価するのは難しいのでそれが必要なときはUnboxed Vectorで書くのが最も安全 datatypeのフィールドも正格にしておくこと コピーを取らない値の計算は爆速になるのでなるべくコピーは取らない   パフォーマンス:  実行時間はC++やRustの2-5倍程度が目安(10倍以上遅いときは書き方が悪い) メモリ使用量も目安に(消費メモリ量を改善できれば自然に速くなることも)    入力  上にも書いたようにByteStringで読み込む 「n個の数値の読み出し」とかはVectorでササッと書く  例 例: a1 .</description>
      </item>
    
      <item>
        <title>newtype decoratorパターンとグラフィックスライブラリ</title>
        <link>https://myuon.github.io/posts/minilight-component/</link>
        <pubDate>Thu, 11 Apr 2019 20:30:21 +0900</pubDate>
        <guid>https://myuon.github.io/posts/minilight-component/</guid>
        <description>minilightというSDL2の上で動くグラフィックスライブラリを作っている。
前にも似たようなことをしており、フルスクラッチで作ったくせにそんなに変わらないという代物。
(別にFluxとかを目指しているわけではないので…まぁ偶然の一致というやつだな)
比較的簡単にコンポーネントが作れるようになったので、その紹介も兼ねて。
例: ボタン 例として押した回数が表示されるボタンを作ってみる。
https://github.com/myuon/minilight/blob/master/examples/button-counter.hs
コード自体はせいぜい30行程度で書けるので結構お手軽だと思う。
 以下がButton型の定義と生成関数。まあこれはいいでしょう。ちなみにminilightではライブラリ名に従ってMiniLightモナドが基本のモナドです。
data Button = Button { font :: SDL.Font.Font, counter :: Int } new :: MiniLight Button new = do font &amp;lt;- loadFont (FontDescriptor &amp;#34;IPAGothic&amp;#34; (FontStyle False False)) 22 return $ Button {font = font, counter = 0} 以下がボタンコンポーネントの定義。ComponentUnitのインスタンスを作れば良い。viewはfiguresで、イベントハンドラーはonSignalで、モデルの更新はupdateで、キャッシュの設定はuseCacheでそれぞれ行う。
instance ComponentUnit Button where update = return figures comp = do textTexture &amp;lt;- liftMiniLight $ text (font comp) (Vect.V4 255 255 255 255) $ if counter comp == 0 then &amp;#34;Click me!</description>
      </item>
    
      <item>
        <title>GHCのソースコードのノートを読むやつを作った</title>
        <link>https://myuon.github.io/posts/ghc-compiler-notes/</link>
        <pubDate>Thu, 04 Apr 2019 22:30:29 +0900</pubDate>
        <guid>https://myuon.github.io/posts/ghc-compiler-notes/</guid>
        <description>タイトルがふわっとしてるけど見れば多分わかる。
ghc-compiler-notes
経緯とか 注意: 作ったと書いてるが私の力ではなく主に水無さん(@mizunashi-mana)とわどさん(@waddlaw)のお力添えによるところが大きい。
GHCのソースコードにはNoteと称して有益な(GHCの内部実装等に関する)情報が書いてあることは有名だと思うけど、実際にそれはまとまったりはしてなかったので知る人ぞ知る、みたいな情報であった。こういう他のドキュメントには書いてないような貴重な情報が誰にも読まれることなく眠っているのはもったいないと常々感じていたのでそれを読めるようにしたかった。
このプロジェクトは最近GitLabに移った方のghc/ghcのソースコードに埋められているNotes部分を抜粋しそれを比較的読みやすい形で並べて整理したものである。
現在の仕様一覧(ざっくり)  compiler, libraries, utils以下にあるモジュールを再帰的に読んでドキュメントとして吐くようになっている ghc/ghcはデプロイのたびにクローンしているので、ドキュメントの参照元は比較的最近のmasterであることが期待される 各Noteに元ソースへのリンクあり (Noteのフォーマットがまともなら)箇条書き等にも対応 色々欠陥があるコードブロックの表示  中身(雰囲気) 実装は、checkoutしてきたソースコードの中身を辿ってコメントの該当箇所を抜き出してきて、reST形式てファイルに吐きreadthedocsに突っ込んでいるだけである。
ちなみにNoteの箇所を抜き出す実装は私は完全にノータッチで上に上げたお二人がやってくれたので詳しいことはよくわかりません。
ちなみにこのNoteは書かれている場所によりフォーマットがまちまちで、Noteのタイトル表からコメントの形式や箇条書きの形式、コードブロックの指定の仕方に至るまで全く統一されていないという荒れっぷりなので実装は大変だったと思う。
今後の課題等  コードブロックはfalse positiveとfalse negativeだらけなので流石になんとかしたい(しかしフォーマットが統一されてなさすぎてかなり厳しい) 文章中の他のノートへのリンクをちゃんとリンクとして辿れるようにしたい masterだけでなくて特定のタグがついたghcのバージョン等をスナップショットとして見られるようにしたい  CIについて このプロジェクトで主に私が頑張ったところがCIだったのでCIを少しだけ解説。
CIはCircleCIを使っている。プロジェクト自体のビルドはcabalでもstackでも出来るが、Haskell公式のdocker imageがcabalとghcが入ったやつなのでそれを使っている。多分docker imageは次のいずれかを使うと良い。
 haskell: 7.8, 7.10, 8.0, 8.2, 8.4, 8.6などがある fpco/haskell: GHC8.0.2版のみ。stackなので他のものはインストールすればよいというのは確かにそうだが…  公式のはまだ8.6.4がリリースされてないみたいなので必要であればこれを見ると良い。
また、CircleCIであればhaskell-buildというorbが用意されているので、単にビルドするだけならこれが簡単で良いと思う。
ビルドコマンド キャッシュは、今のところは cabal new-update してからindex.cacheのchecksumをみて ~/.cabal を丸ごとキャッシュしている。よくわかってないんだけどこれで大丈夫なの？
あと、以後のjobでも使うので dist-newstyle もworkspaceに放り込んでる。
何かの参考になれば。</description>
      </item>
    
      <item>
        <title>パストレーシングについて調べてる</title>
        <link>https://myuon.github.io/posts/survey-ray-tracing/</link>
        <pubDate>Sun, 03 Mar 2019 19:33:25 +0900</pubDate>
        <guid>https://myuon.github.io/posts/survey-ray-tracing/</guid>
        <description>前に入門記事を書いてそこから色々調べたりしてたのでその備忘録として
アルゴリズムについて カメラから出たレイをたどりながら光線のシミュレーションを行う単純なアルゴリズムをレイトレーシングと言って、それを確率的な計算によってオブジェクトの数に依らない計算量で計算できるように改良したものをパストレーシングと呼ぶらしい(正確な定義はよくわからなかったがアルゴリズムの差から名前が違うみたい)。
アルゴリズムの詳細については次とかを見るとよさそう。
 memoRANDOM 物理ベースレンダラ edupt解説  パストレーシングアルゴリズムの初出は&amp;quot;The rendering equation (J. Kajiya, 1986)&amp;ldquo;か？
bidirectional, NEE, metropolis light transport, photon mappingあたりは実装してみたいがお勉強が先かも。
NEE (Next Event Estimation) 悩みとして、memoRANDOMさんのサイトに載ってる通りに、3点のレンダリング方程式をベースにしたNEEを実装してみたけど寄与が小さすぎて全然効果がなかった。単に実装を間違えているだけか？
また、調べているとshadow rayを蓄積したあと反射を行い、そっちで同じ光源に向けてexplicitなrayが飛んだとしたら無視するみたいなアルゴリズムでNEEを計算しているサイトも見かけたけど、それは何か違いがあるのだろうかと思った。NEEの正しいアルゴリズムがよくわからない。(というか、本当はちゃんと平均とかを計算してどういうアルゴリズムなら正しい結果が得られるかは手で確認すべきかなと思う)
Stratified Sampling 層化サンプリングによってサンプルの座標がいい感じに均等にばらけるようにとるといいらしい。これってどれくらいの改善になるのだろうか、気になる。
 Stratified Sampling of Spherical Triangles  GPU どうせならGPU使った計算もしたい。GPUでレイトレーシングやるみたいな話は調べると色々出てくる。
疑問としてロシアンルーレットとかの実装だと分岐が入る(というかレイごとの計算回数が見積もれない)わけだけどその辺はどうするのだろうか。調べた感じだと1レイ1スレッドにするのが普通っぽかったのと、ロシアンルーレットのときにどうするかみたいな話は出てこなかったので、計算を打ち切る代わりに寄与を0にするみたいな感じで並列処理を止めないように作っているのかもしれない。
そもそもシェーダー言語とかCUDAとかにパストレーシングアルゴリズムをナイーブに突っ込んでるのとかよく見るんだけど本当にそんなんでいいの？という気持ちになったりならんかったりする。
 Path tracing on GPU  Unity Unity(のComputeShaderなんか)を使うとGPUを使った計算が簡単にできる。要は単にHLSL(これはWindowsだから？)とのintegrationがUnityに用意されているというだけのことだけど、Unityは普通に解説も多いしGPUを使ったレイトレーシングの入門にはいいかもしれない。
 GPU Ray Tracing in Unity – Part 1  例えば次のような画像が割と簡単に出せる。
WebGL 人間に見せるUIとしてWebGLにして吐くのは結構ありかもしれないと思っていた。WebGLはRustを使っても吐けるみたいだった(けど中身は普通にshader言語書いてたのでRustで書けるとは言わない気もする)。
実際にWebGLでやってる例とかもあって面白かったのでなおさら。
 gfx-rs/gfx WebGL+GLSLによる超高速なパストレーシング http://madebyevan.com/webgl-path-tracing/  </description>
      </item>
    
      <item>
        <title>DynamoDB LocalをTerraformから使う</title>
        <link>https://myuon.github.io/posts/dynanmodb-local-terraform/</link>
        <pubDate>Mon, 11 Feb 2019 00:22:05 +0900</pubDate>
        <guid>https://myuon.github.io/posts/dynanmodb-local-terraform/</guid>
        <description>タイトルの通り。大体以下のPRの説明読めば分かる。
https://github.com/hashicorp/terraform/pull/2825
Terraform側の設定 local envで環境を作ってDynamoDB Localをテスト用途で動かすという前提。以下がproject structure。
&amp;lt;project root&amp;gt; - infrastructure - local/ - main.tf ここにDynamoDB Localの設定を入れる - modules/ - dynamodb/table.tf ここにテーブルの設定など infrastructure/local/main.tfでは、endpointsを指定することができる。(デプロイ時にこのendpointを参照してテーブルを作ったりする)
provider &amp;quot;aws&amp;quot; { region = &amp;quot;ap-northeast-1&amp;quot; endpoints { dynamodb = &amp;quot;http://localhost:8000&amp;quot; } } DynamoDB Localは普通に動かせばよい。
port:8000で起動させたら、いつも通りterraform -e dev applyでDynamoDB Localにテーブルができる。
スクリプト テストで使おうと思ったら、このDynamoDB Localを立ち上げる→terraform apply→テスト実行→DynamoDB Localを落とすを何度も繰り返すことになって面倒なので、私はMakefileを書いている。
install: mkdir -p ./infrastructure/local/.dynamodb cd ./infrastructure/local/.dynamodb; \ 	wget https://s3-ap-northeast-1.amazonaws.com/dynamodb-local-tokyo/dynamodb_local_latest.tar.gz; \ 	tar -xf ./dynamodb_local_latest.tar.gz test: $(MAKE) startTest # ここでテスト export ...; \ 	go test .</description>
      </item>
    
      <item>
        <title>定理証明リンク集</title>
        <link>https://myuon.github.io/posts/start-learning-proof-assistant/</link>
        <pubDate>Sun, 06 Jan 2019 15:46:06 +0900</pubDate>
        <guid>https://myuon.github.io/posts/start-learning-proof-assistant/</guid>
        <description>定理証明、特に定理証明支援系(Proof Assistant)はその存在こそ少しずつ浸透しつつあるような気がしないでもないけれど資料とか全然まとまってないのが不便だなと前々から思っていたのでリソースをまとめておきます。
これも追加してほしいみたいなのあったら教えてください。
Proof Assistants 始めるなら次の中から選ぶのがよいと思います。
 Coq  Calculus of constructionsベースの型システムとリッチなコマンドを備えた言語 このリストの中では最もコミュニティが大きい、入門書等も豊富 型システムと項を書くためのGallina, コンパイラへの命令を記述するためのVernacular, タクティクスの定義に使うLtacなどの言語が混ざって出てくるのが初心者には混乱必至 結構複雑な言語なので使いこなすのはそれなりに大変   Agda  Martin-Löf type theoryベースの言語 Coqと違ってコマンド等はとても貧弱だが言語が薄いので中の仕組みが分かりやすい、依存型の勉強にはもってこい 実践的に使おうとするとパフォーマンスが悪いのがネック モジュール分割や証明のスキップみたいな面白くないところに時間を取られる可能性あり   Idris  Agdaに似た感じの言語 この中では唯一純粋なプログラミング言語として使用可能(runtimeがあって実行可能コードを吐ける)だが実際に動かして使うにはまだまだという感じ Agdaよりはサポートが多く証明が書きやすいはず(未検証なので嘘かも)   Lean  この中では後発、CoqやAgdaに似ており、Agdaよりは書きやすくリッチでCoqよりは薄くて簡単 数年前にメジャーバージョンが2から3に上がりそこで多少の断絶があるらしい 機能網羅的なリファレンスがまだ用意されてないらしいのでCoqやAgdaの知識がないと使いこなすのは難しいかもしれない   Isabelle  この中では唯一Curry-Howardをベースとしない形式証明(依存型もない) 豊富なライブラリと強力なproverによる自動証明が魅力 「普通の」数学をやりたいならこれがおすすめ 公式のリファレンスはあるが機能は膨大、非公式ドキュメントも少ないので習得は骨が折れるかも    入門書等 出版されていてもドラフト版のpdfが無料で読めるものが多い
 Software Foundations: Coqを使用しプログラム意味論的な話題が中心。Coqの説明ばかりというわけではないので他言語ユーザーでも読めると思われる。 Software Foundations in Idris: Software FoundationsのIdris版 Concrete Semantics: Isabelle/HOLを使用しこちらもプログラム意味論系の証明を行う本。前半はIsabelleの説明で後半はコンピューターサイエンスという構成。 Certified Programming with Dependent Types: Coqで依存型を学べる本。Coqに限らず定理証明で幅広く使える話が書いてあるので非Coqユーザーでもおすすめ。 Verified Functional Programming in Agda: Agdaの本、読んでないので詳細知らず Coq&#39;Art: Coqの定評のある入門書、詳細は知らない Coq/SSReflect/MathCompによる定理証明: 日本語(！)で書かれたCoqの入門書  入門記事等 読み物もあり</description>
      </item>
    
      <item>
        <title>レイトレーシングに入門した</title>
        <link>https://myuon.github.io/posts/start-ray-tracing/</link>
        <pubDate>Sun, 06 Jan 2019 13:34:10 +0900</pubDate>
        <guid>https://myuon.github.io/posts/start-ray-tracing/</guid>
        <description>レイトレ自体は前から興味あったんだけど年末年始でいよいよ真面目に入門し始めました(今後も続けるかは不明)。
Ray tracing in one weekendシリーズを読んでこの3冊分の実装をRustで書きました。 本に沿って実装したのでレイトレーサーとして使えるような感じにはなってない(再利用性がなさすぎるところがちょいちょいある)。
 Ray Tracing Minibooks (3 Book Series) リポジトリ  スクショ 個人的にお気に入りのやつをいくつか貼っておきます
今後やりたいこととか 本では純粋なCPU実装で最適化とかもそこまで(3冊目の後半はやるけど)だったので、まぁその辺かなー。SIMDとか使って高速化するのはできそうなのと、GPUを使ったちゃんとした高速レイトレみたいなのもちょっとやってみたい(そこまでそっちに傾倒する気はないしガリガリチューニングしたり最適化テク実装というよりは、もっと綺麗な絵を高速にレンダリングしたい)。
レイトレにも色々なテクがあるようで(bidirectionalなんとかとかmetropolisなんとかとか)、その辺によっても得意なシチュエーションが変わってくるみたいなので色々実装して遊べたりしたら面白そうだなーと思う。
アルゴリズムの詳細については以下のスライドが詳しくてしかも超面白かった。</description>
      </item>
    
      <item>
        <title>2018年を振り返って</title>
        <link>https://myuon.github.io/posts/sumup-2018/</link>
        <pubDate>Sat, 29 Dec 2018 19:06:59 +0900</pubDate>
        <guid>https://myuon.github.io/posts/sumup-2018/</guid>
        <description>2018年総括記事です。
まだ29日で年内やろうと思ってることがそれなりにある状態で書くのもどうなんだと思いつつ書く。
GitHubの草カレンダー  1020 contributionsだったようです。それなりに頑張っている感じは出てますね。あと2-3月と11-12月くらいにプログラミングをいっぱいしてたっぽい。
1月 ｼｭﾛﾝで忙しかったので正直進捗どころではなかった。まぁなんとかなってよかった。
2-3月 手を付けたもの
 madder: 動画編集ソフト nott: type theoryについてのまとめ Semantics of Programming Language(SoPL)セミナー  動画編集ソフトやろうと思ってRustを始めGTK+とGstreamerのことを調べ始めた。のちにGTK+はElectronに変更される。Gstreamerが意味不明すぎて動画とか音声は結構闇が深いと思った。なお今でもよくわからないことが多すぎる。
nottはｼｭﾛﾝの名残でなんかしたかったのだと思う。結局SoPLを読むことになってそれから半年くらいはテキスト読む方に集中しててあんまり計算機科学の勉強とかできてないので進んでない。またやらなきゃ。
SoPLセミナーも3月くらいに人を集めて4月から本格始動みたいな感じだった。12月現在でおよそ7割くらいのところまでセミナーが進んでおり、割とかったるいdomain theoryとかの話も合ってそこそこ重い内容の割にはちゃんと進んでて偉いなと思ったりした。
あと引っ越しというか一人暮らしを始めた。
4-5月 手を付けたもの
 dockerとか触ってたような ｳｪｯﾌﾞ技術の勉強とかしてた  4月からなんとｼｬｶｲｼﾞﾝになり働き始めた。夏くらいまでは研修やってて研修はまぁ虚無だったんだけど比較的自由な時間もあったのでJavaの話を調べたりdockerについて調べたりDBについて調べたりMDNをおもむろに読んだりしていた。
6月-7月 手を付けたもの
 refluxive fantia登録も確かこの辺 夕暮寝子プロジェクト (juniQ, Live2D)  refluxiveというFluxベースのHaskellグラフィックスフレームワークを作ってた記憶。なんか型がごちゃっとしてきてアレだなと思って放置されてるけどもうちょっとスッキリするようにちゃんと書き直してみようかな。
それとこの辺で人格が一つ増えて夕暮寝子プロジェクトが発足したりした。受肉システムを作ったりLive2Dのモデルを必死に作ったりした気がする。ていうか早くコンテンツを作れって感じですねわかる～。
8月 お仕事でAWSを使うので、ということで8月くらいから本格的にAWSの勉強を始めた気がする。まだ4ヵ月くらいしか触ってないけどかなり色んな事も身に付いたと思うし、何よりやっぱAWSのマネージドサービス本当にすごいなと思うことばかりだった。関係ないけど来年はNeptuneとかAppSyncとかLightSailとかFirehoseあたりのサービスも使ってみたいなーとか。
9-10月 Haskellでなんかしようと思って久々にAtCoderの過去問を解いたりProject Eulerの過去問を解いたりブログ記事らしきものを作ったり色々してた気がする。あまり記憶がない。
あとこういうのは短い期間でどうにかなるようなものではない。じっくりコツコツやることの大切さよという感じ。
11-12月 AWSでちょっと色々サービスを作ってみようということで色々やっていってる。まだリリースには程遠いので紹介はしない。DynamoDBとCognitoが特に分かりにくくて触ってみないとマジで身につかないなこれって思ったりしていた。
あとお絵描きもこの2ヵ月くらいはちょっと多めにしてたような。
総括 コツコツやることの大切さ(というか偉大さ)を身に染みて感じる1年だった。自分はバフスキルかけるより敵を殴る方が好きなんだけどバフスキルの偉大さを知った感じだった。
今年はイレギュラーな(環境が変わったり)ことが多くて趣味の作業とかにも支障が出そうと思っていたけど特にそんなことはなく例年通り好き放題やってたと思う。来年もペースを落とさず進捗しまくるぞい。
そういえば去年の振り返り記事で、「もっとブログ書きたい」みたいなことを言ってるけど今年は結構書いてたんじゃないかな。ブログメンテナンスがあったり移行作業に手間取ったりで運用がつらくて書けなかった時期とかもあったけど思ったことはちゃんと文章化できてると思う。多分ね。
来年の抱負 最強になること。これ今年の抱負と一緒だな。</description>
      </item>
    
      <item>
        <title>バーチャル美少女定理証明士を支える技術</title>
        <link>https://myuon.github.io/posts/juniq/</link>
        <pubDate>Tue, 25 Dec 2018 20:25:54 +0900</pubDate>
        <guid>https://myuon.github.io/posts/juniq/</guid>
        <description>この記事とは特に関係ないのですがVTuber Techアドベントカレンダー(その1 その2)があるらしいので興味がある人は覗いてみるといいんじゃないでしょうか。
バーチャル引きこもり病弱定理証明士 夕暮寝子というのがいて、その子の裏側のシステムを作ったので(作ったのはだいぶ前)その解説をします。なお問題は山積みの模様(そもそも私以外の人が使う想定じゃないので自分でいじるなりなんなりしてください)。
技術スタック: Docker, Python, TypeScript, dlib (Python bindings), OpenCVちょこっと, Live2D SDK
リポジトリ コードは全部公開しています。
https://github.com/myuon/juniQ
免責事項
このプログラム群はMITライセンスで公開しています(リポジトリにsubmoduleとして含まれるcubism-jsには当たり前ですがこのライセンスは適用されません)。
このソフトウェアはLive2D SDK for webを利用しており、ソースコードの公開及びブログにおけるコードの解説はLive2Dから許可を得て行っています。
このソフトウェアを利用して作られたものを出版(コードの一部または全部を公開することも含まれるようです)する場合にはLive2Dとの契約が必要になる場合があるのでその辺はちゃんと問い合わせてください。
Live2D SDKリリースライセンス: https://www.live2d.com/ja/products/releaselicense
(これ読む限りだとソースコードの一部を公開するだけでも出版にあたるかもみたいな書き方だったけど問い合わせたらソースコードの公開だけなら契約不要って言われたので割とLive2D側に判断の裁量がありそうです。まぁなんかやりたくなったらとりあえず聞いてみるのがよさそうな感じだった。)
アーキテクチャ 次のような仕組みで動きます
 ブラウザからカメラ映像を取得、websocketサーバーに画像を30fpsで投げる サーバーが画像を受け取って顔の検出等を行いパラメータを計算する 計算されたパラメータがブラウザのviewerに再度投げ返される viewerはLive2Dモデルを描画  なんでやねん なんやねんこれと思うと思うんですがこれはホストPCがWindowsでありWindowsで開発はできないことと、VirtualBoxではUSBの映像出力等を直接受け取れない等の技術的制約により悲しくも厳しい設計になっています。
やーまじ全部Unityかなんかで作ればよかったーって後になって後悔したんですがしかしdlibとかのライブラリがUnityのアセットストアだとまともそうなやつはすごく高くていやいやみたいな気持ちになったりしたのはある。Unityネイティブプラグインで頑張って作り直したいけどつらそう。
あとクライアントからサーバーに直接映像を投げるのって意外と難しくて(browser to browserだとそれっぽい技術は意外とあるんだけど…)あんま選択肢がないし、そもそも検出とかの関係で絶対画像を切り出す必要があるのでまぁブラウザで切って送ればいいんじゃないかみたいになっておる。当然この処理は割と負荷かかるのでうんまぁみたいな感じ。
あとCORSの設定がこれを作ったときはよくわかってなかったのでFirefoxでしか多分動かないです。そのうちFirefoxでも動かなくなる可能性がある。
映像取得部分 映像と音声を取得する。getUserMediaとかを使うとできる。映像は30fpsくらいに落としてwebsocketサーバーにjpeg画像として投げつける。音声はリップシンクのために使う。
リップシンク作るところだけ載せます。
// https://github.com/myuon/juniQ/blob/master/viewer/src/index.ts#L42 class AudioVolume { processor: ScriptProcessorNode; volume: number; clipLevel: number; averaging: number; clipping: boolean; lastClip: number; clipLag: number; constructor(audioContext: AudioContext, clipLevel = 0.</description>
      </item>
    
      <item>
        <title>実装詳細テスト要るのか問題(反語)</title>
        <link>https://myuon.github.io/posts/goodbye-to-impl-tests/</link>
        <pubDate>Mon, 24 Dec 2018 14:25:05 +0900</pubDate>
        <guid>https://myuon.github.io/posts/goodbye-to-impl-tests/</guid>
        <description>備忘録です。
テストとは書きたいけど書きたくないという大変アンビバレントな状態に人間を置く深淵の魔物。
テストの分け方についても色々な指標があるけどここでは便宜上「実装詳細テスト」「サービステスト」「E2Eテスト」の3つにわけて説明をします。
テストとは 実装詳細テスト: 書いた実装に依存するテスト。ある関数にこういう入力をしたらこういう出力が返ってきますよ～みたいなやつ。アプリケーションの他の部分に依存せずその関数とテストを別の場所にもっていっても動くが、実装を変更するとテストも変更が必要になる。
E2Eテスト: エンドユーザーが行う操作と同じ操作を行い期待した入力に対して期待した出力が返るかを調べるテスト。本番または本番と同じに作られたデプロイされた環境を使うもの。
サービステスト: それ以外(雑)。もっと言うと、「書いた実装になるべく依存せず、実装を変えても動き続ける」「他のサービスやシステムに依存しない、基本的にインターネットへのアクセスも行わない(ローカルサーバーは可)」の2つを備えたテスト。
実際にはエンドユーザーと同じ操作を行うテストなんだけど裏側がスタブになってて本番環境にアクセスしないみたいな中途半端なやつもあると思うけど一応こういう分け方にしてみる。
実装詳細テスト要るのか E2Eテストがつらく厳しく基本的に誰も書きたくないというところはまぁ人類の合意なのではと思っている。当然書かないわけにはいかなくてしょうがなく書いてる人はいっぱいいると思うけど。
問題は実装詳細テストの方でこれが要るのかという話。これはアプリケーションの性質とかにもよるので一概には言えないけど通常のアプリケーションやサービスなら不要なのではと思う。そもそも「常にsemanticsを考えよ」という設計の金科玉条(これは私が勝手に言ってることだけど)からすると、アプリケーションの中で定義された関数のふるまいはアプリケーションのsemanticsなどでは決してないのでそんなものをテストする必要はないでしょという感じ。あるいは実装詳細テストを書きすぎると機能追加や修正でテストの変更が必要になって逆にテストが開発を妨げてしまったりして逆効果になることさえある。そもそも我々はサービス開発等で忙しくちまちまテストを書いている余裕などないので実装詳細をチェックする必要などないのだ(逃げ)。
サービステストはもちろん書く。というかこれがすべて。そこまで難しくない世のほとんどのプログラムならサービステストをsemanticsに乗っ取って書くだけでカバレッジ100%にできると思う。
実装詳細テスト要らないのか じゃあ実装詳細テスト書いちゃだめかというとそうではないです。普通に必要になることもある。
 ライブラリとして切り出す場合: ライブラリはそこでexportされる関数がsemanticsになるので今度そのテストはむしろ書いてくださいとなる。同じプログラムでも使われ方によって意味が変わってくるのでしょうがない。 スタブとかの都合: サービステストは通常複数のモジュールをまたがるのでローカルサーバーとかでテストできるのが一番良いのだけど使ってるSDKの都合とかでそういうテストが書きにくいのでこの画面のテストだけは実装詳細でやりますみたいなのはアリだと思う(というかしょうがない) 実装が非自明な場合: 何かの方程式を超多ステップで解くとか複雑なアルゴリズムを手書きするとか まぁ実装が非自明な場合はやった方がいいですね 当たり前や  ｳｪｯﾌﾞｻｰﾋﾞｽの構成 今こういう感じでやっておる
 サーバーサイド  SDK: サーバーサイドが提供するAPIをたたくだけのSDKを用意する; クライアントサイドで読み込んで使う サーバーサイドのコード サービステスト: SDKに対するテストをがりがり書く (必要があればモジュールごとに)実装詳細テスト   クライアントサイド  (必要があればコンポーネント/画面ごとに)Viewの詳細テスト    ひとまず困ってない。あとテストはやっぱり書きたくない。
semantics、意識していこうな</description>
      </item>
    
      <item>
        <title>OGP画像の埋め込みを実装したい(しない)</title>
        <link>https://myuon.github.io/posts/implement-ogp-expansion/</link>
        <pubDate>Fri, 14 Dec 2018 23:51:25 +0900</pubDate>
        <guid>https://myuon.github.io/posts/implement-ogp-expansion/</guid>
        <description>OGP画像というのがあって、ついったーとかﾌｪｰｽﾌﾞｯｸとかでURLを貼るとリンク先のページの説明文と画像が表示されるみたいなやつがあると思うんだけどそういうアレ。
URLを貼ると自分のサイトにアレを動的に埋め込めるようにしたいというのが目標。
まぁあんなん「クライアントサイドでちょちょっとやったらできるやろ～ｗ」と思ってたんだけどどうもそんな簡単ではないことに最近気が付いたので記事に書いてみた。
(なお実装はしてない、めんどすぎる)
(知ってる人にはすごい当たり前の話だと思うけど調べてもあんまりヒットしなかったので)
なぜクライアントサイドだけでは無理か OGP画像は各サイトのmetaタグの該当箇所を引っ張ってくることにより得られるが、そもそもJavaScriptで別のサイトにアクセスしてその結果で何かをしようとすると確実にCORS(Cross-Origin Resource Sharing)にひっかかる。ひっかからないブラウザもあるかもしれないけどモダンなブラウザならほぼ間違いなくひっかかる。
もしかしたらHTML自体にAllow-Origin: *みたいなことをしているサーバーも世の中にはあるかもしれないけど普通はやる意味がないのでまぁしょうがないね。
サーバーサイドレンダリング ということでサーバーサイドにAPIを1つ用意してURLを投げるとその先のHTMLをとってきてmetaタグからCORS画像と説明文を引っ張ってくる処理を行うことにする。
これで実装終わりかと思いきやこれをそのままページに埋め込むと、ページの画像ソースURLがよそ様のものになる。いわゆる直リンクという古のインターネッツで超嫌われたアレに該当し、まぁ嫌われるだけならまだしも、自分のサイトがそれなりに人気サイトになったりするとそこから大量のリクエストが埋め込み先のサーバーに飛ぶので量によってはBANされたりしそうだなという感じになる。
TwitterにせよFacebookにせよ、URLを投稿するとタイムラインを開いているフォロワーが一斉にそのURLにリクエストを飛ばすのは当然良くないでしょう。そういうわけで画像はキャッシュしましょうという話になってくる。
キャッシュクリア さてキャッシュサーバーを用意して画像はいったん自前のところでキャッシュしてそれを参照するようにした。これでめでたしかと思いきやまだめんどい問題があって、キャッシュはあくまでキャッシュなのでクリアするという仕組みを用意しなければ、OGP画像をサイト管理者が変えても古い画像が残り続けたり前の説明文が残り続けたりする。これはあまりよいことではないだろう。
FacebookでもOGPキャッシュが残り続けるのが問題になってキャッシュクリア用のボタンが実装されたりしてたらしい。Twitterは一定時間でキャッシュがリロードされてたような気がする？(これは嘘かもしれない)
最適化 みんながどうやってるのかは知らないが、上の機能を全部やったとして、でもまぁ冷静に考えてすべてのURLに対して画像をキャッシュするのは少し無駄が多いような気がするだろう。
OGP画像はサイト全体で使いまわされたりすることも多い(ページごとに変えているマメなブログ更新者もいるので全員ではない)ので、OGP画像のURLをキーにキャッシュを使いまわすことで画像をとってくる手間とキャッシュサーバーのリソースを最適化したいような気がする(しかし実際はそこまでする必要があるのかは不明 あんま変わんないような気もするけど)。
みんなどうしてるんだろ みなさんどうやってるんですかね
このサイトは このサイトはトップページのアイコン的なやつを前にOGP画像に設定してたけどテーマ変えた時に設定が飛びました。そのうち対応します(めんどいからやってない)。</description>
      </item>
    
      <item>
        <title>Firebaseを始めてみた</title>
        <link>https://myuon.github.io/posts/get-started-with-firebase/</link>
        <pubDate>Thu, 13 Dec 2018 00:05:37 +0900</pubDate>
        <guid>https://myuon.github.io/posts/get-started-with-firebase/</guid>
        <description>Firebaseがすごい話 今までAWSのサービス(サーバーレス中心・LambdaとかDynamoDBとかAPI Gatewayとか)は結構触ってたけどGCP系はノータッチだったので一時期超流行ってた(少し前になんかやたらブログ記事とかが量産されていた時期があったように思うんだけどあれは何だったんだ…)firebaseをこの際触ってみることにした。
Cloud Firestoreとかいう無敵のDB Cloud Firestoreというまだベータ版だけどFirebaseもイチオシっぽいDBがある。こいつは特にDynamoDBを知ってるとそれに比べても無敵だなと思う。個人的すごいポイント:
 Collection/Documentという分かりやすさ(Partition KeyだのSort Keyだのといった面倒さがない) やたら複雑なベストプラクティスとかもない インデックスが自動でいっぱい貼られる！GSIの制限とかもない！ read/write/deleteの完全リクエスト回数課金という分かりやすさ(あっちもon-demand capacity来ましたが) コンソールから触るのも簡単・分かりやすい rulesによる超細かい権限管理(これはmBaaSだからできないとまぁ困るけど) DynamoDB Stream的な機能もくっついてる Paginationとかにも対応してる emulatorも来た(DynamoDBもdynamodb-localあるよ！)  Firebaseの便利さ Firebaseは認証・FaaS・DB・ストレージあたりが全部オールインワンで全部そろっておりエコシステムがとても強くてよい。どこぞのAmplifyも見習ってほしい(re:Invent2018を見る限り力入れてる感はあった)。クライアントサイドだけですべてを完結させるぞという強さがありやーすごいって感じだった。
GCPもそうだけどGoogleのサービスは分かりやすさと欲しいものが大体そろってる感じが強いと思う。よく考えられてるしサービスの質が本当に高いなと思ったりあれこれ。
Firebaseをやめたいって話 とべた褒めなんですがしばらく書いてFirebaseやめるかーってなった。
 早く東京リージョンに来てくれ (これが一番大きい; Firestoreとかレイテンシが400-500msとかで正直使い物にならない。ページ表示に1秒もかかるサービスを使うほど暇なユーザーもそういないよ！) 地味に高い、というかAWSが安すぎるのでそれに比べるとちょっとお高く感じるのはある。DynamoDBとかおかしいんじゃないかというくらい安いのでまぁね。 あとAppSync使いたかった これは完全な趣味だけど、AppSyncずっと使いたいと思ってたのでせっかくだしこの機会にと思って 正直mBaaSがとてつもなく向いてるようなユースケースではなかったというところが大きい までもFirebaseの勉強になったので良いとしましょう  メインの理由としてはパフォーマンスとコストが大きかった(と言ってもFirebaseは無料枠もあるのでコストはそこまで大きな差はないと思う)。GCPはいい感じのやつを用意しときました！みたいなサービスが多くて、AWSは本当に特定の用途のためだけのサービスを作っといたから設計は自分で考えろやみたいな投げ方してくるのが多いイメージ。AWSの方がめんどいけどちゃんと組むとカリカリにチューニングされたプログラムのごとく本当に安く早くで組めるというイメージはありますね。めんどいけど。
個人でちょこっと使う分にはFirebaseとても良いと思うので、またなんかあったら使いたい。</description>
      </item>
    
      <item>
        <title>Lambda FunctionをReasonで書く</title>
        <link>https://myuon.github.io/posts/serverless-reason/</link>
        <pubDate>Fri, 23 Nov 2018 21:00:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/serverless-reason/</guid>
        <description>Reason ML、やっていこうな 世はまさに大サーバーレス時代なのでLambda Functionやっていきというお気持ち。
AWS Lambdaで現時点(2018年11月)で対応されている言語はNode.js, Python, Go, C#(dotnet), Javaの5つ。このうち後ろ2つはコールドスタートが激遅なので使い物にならない。で前3つのうちではドキュメントの多いNode.jsが安定ですが、Node.jsをランタイムに採用するとしてしかしJSは書きたくない、そういうときにReason MLはいい感じな選択肢なのでは？というのがこの記事の趣旨です。
serverless-reason serverless frameworkというサーバーレスアプリをやるのにとても便利なツールがあって、それのReasonで動くテンプレートを作っておいたので好きに使ってくださいという感じ。
以下このプロジェクトの中身の解説をする。
echo.re Lambda Functionとしてechoというものがsrc/functions/echo.reに定義されている。
/* Sorry I&amp;#39;m a lazy person! */ type event = { . &amp;#34;pathParameters&amp;#34;: Js.Dict.t(string), }; type context = unit; type callback = (. Js.null(string), Js.Json.t) =&amp;gt; Js.Promise.t(unit); type response = { . &amp;#34;statusCode&amp;#34;: int, &amp;#34;body&amp;#34;: string, }; let handler : (event, context, callback) =&amp;gt; Js.Promise.t(response) = (event, _, _) =&amp;gt; { Js.log(&amp;#34;hello&amp;#34;); { &amp;#34;statusCode&amp;#34;: 200, &amp;#34;body&amp;#34;: event##pathParameters |&amp;gt; Js.</description>
      </item>
    
      <item>
        <title>はじめようReason ML</title>
        <link>https://myuon.github.io/posts/start-reasonml/</link>
        <pubDate>Sat, 10 Nov 2018 00:24:20 +0900</pubDate>
        <guid>https://myuon.github.io/posts/start-reasonml/</guid>
        <description>はじめに Reason MLを最近始めました。よき。
Reason MLとは Reason MLとはOCamlにインスパイアされたAltJSの一種。見た目は型の付いたJSみたいな感じだけど実際はJSのsyntaxに寄せたML。
BuckleScriptというコンパイラ(この名前もどうなんという感じだけど)を使ってJSに変える。BuckleScriptはReason MLとOCamlをJSに変換するコンパイラであり、Reason MLとOCamlのいずれのsyntaxも混ぜて使うことができるっぽい。便利～。
実際に使うときはBuckleScriptの方のドキュメントもちゃんと読んでおく必要がある(似たような見た目のページだけど内容は違う)。BuckleScriptにはコンパイラ拡張みたいなものが載っておりそれを上手く使うことで生成されるJSを制御したりJS側の関数を読み込んだりするのでこの辺も割と必須。
 https://reasonml.github.io/en/ Reason MLの言語リファレンス https://bucklescript.github.io/en/ BuckleScriptリファレンス https://bucklescript.github.io/bucklescript/api/index.html BuckleScript標準ライブラリ(Reason MLも同じものがportされてる)  よさ  まともな型が付く(OCamlの型システム、世界で一番分かりやすいみたいなところがある) 生成されるJSがまとも ドキュメントが割とそろってる JSとのブリッジが簡単(基本的に何もしなくてもできる; JS直接埋め込むのもできる) JS風syntax(これは完全な好みだけどブレース・セミコロンsyntaxが結局一番書きやすいみたいなところあるよ) まぁライブラリも意外とある bs-jsonも普通に使いやすいよ JSの標準ライブラリの関数とか型はすべてportされてるのでちゃんと使える  ハマりポイント  BuckleScript拡張最初はよくわからなかった(ドキュメントを100回くらい読むと分かる) 特殊な演算子とかが意外と多くてsyntaxを覚えるのは結構しんどい(Haskellとかだとライブラリ定義の演算子が多いから定義見ればいいけど組み込みの演算子が多いのがつらい) 関数はデフォルトではカリー化されて (a,b) =&amp;gt; ... は a =&amp;gt; b =&amp;gt; ... 相当のJSが生成されるので(これは回避可能)知らないとたまに思った通り動かない ReactはReasonReactというのがあるらしいけどVue.jsはどうしたらいいのかよくわからない(調べてもVue2のやつしか出てこない)  レポート Node.jsで書いていたサーバーサイドをReason MLで書き直したりVue.jsのビジネスロジック部分だけを切り離してReason MLで書き直したりして安寧を得ています。
Rustに引き続き9ヵ月ぶりくらいに良い言語に巡り合えました。ていうか私はML系の言語大体「良い」って言う傾向にあるしまぁML好きなんだなと自分でも思います。
あとはVue.jsでスムーズに使えるようになったらフロントもバックも全部Reason MLでできるのになーって言ってる。 create-vue-app あたりのエコシステムが正式にサポートしてくんないかな～って感じですね。</description>
      </item>
    
      <item>
        <title>Elm: Concurrent FRP for Functional GUIsを読んで</title>
        <link>https://myuon.github.io/posts/elm-functional-gui/</link>
        <pubDate>Sun, 04 Nov 2018 12:32:56 +0900</pubDate>
        <guid>https://myuon.github.io/posts/elm-functional-gui/</guid>
        <description>これ
https://elm-lang.org/assets/papers/concurrent-frp.pdf
はじめに 某所でFRPをeffect systemとみなせないか、という大変示唆的な質問をいただいて、気になったのでFRPについて調べてた流れで教えてもらったElmの作者が書いた論文。 自分はFRPについては「なんかEventとBehaviorがあってArrowになったりMonadになったりするやつ」くらいの感覚しかなかったので論文読んでみることにした。
ところでmarkdownで数式や図を記述するのは大変つらいので記事は適当に日本語で書きます。詳しく知りたい人は論文の方を読んでください。
あと、ElmはFRP捨てたって言ってた気がするので多分今のElmはもう論文にあるような仕組みで動いてないような気がしないでもない。
2章 背景  FRPにはClassical, Real-time (とEvent-driven), Arrowizedの3種類ある Classical:  Behavior a = Time -&amp;gt; a: これが時間の経過とともに変わる値を表現する Event a = [(Time, a)]: これがBehaviorのスナップショットを取ったもの 基本はBehaviorをベースに計算を行うけど、実際のプログラムでは無限に細かい時間で計算はできないので30fpsとか決まったタイミングで再計算するかどうかを考えることになる。そういう離散化のためにEventがあるよみたいな感じ   Real-time:  Event a = Behavior (Maybe a) EventもBehaviorで書いちゃえばいいんちゃうん Event, Behaviorをまとめて Signal a = Time -&amp;gt; a と呼ぶことに 論文で説明されてるElm Coreもこれにinspireされてるっぽい   Arrowized:  SF a b = Signal a -&amp;gt; Signal b signal functionというものをベースにしてこれをArrowにする 論文読んだ限りだと理論が難しくなりそうなのでFRPにおける特にArrowの優位性はよくわからなかった 書きやすいってくらいなのか   Message-Passing Concurrency  Concurrent MLの説明 実装はこれで書いたり書かなかったりする(あとの章でtranslationが与えられる)   既存のFRP GUI frameworks  メモリリークする(Haskellなので)(って何度も書いてあってウケるって思った)    3章 Core Language  Dicreteなsignalを扱う 文法: e ::= () | n \in Z | \x.</description>
      </item>
    
      <item>
        <title>RustとNode.js間通信にgRPCを使う</title>
        <link>https://myuon.github.io/posts/grpc-rust/</link>
        <pubDate>Sun, 28 Oct 2018 16:03:12 +0900</pubDate>
        <guid>https://myuon.github.io/posts/grpc-rust/</guid>
        <description>gRPCしたくなった。具体的にはRustで作ってるデスクトップアプリケーションで、GUIをElectronで書きたいのでNode.jsと通信が発生するのでそれに使えないかなと思って調査した。
gRPC(protocol buffers)とは gRPCはgoogleが作ったRPC(remote procedure call)のフレームワークで、簡単に言うとサーバー/クライアント間の通信が言語を問わずできるよ！みたいなやつ。 RPC自体は見た目は普通の関数呼び出しみたいな感じで書けて、裏ではHTTP/2の通信に乗ってやりとりが行われるようになっている。実際にはRPCを定義してからそれを呼び出すためにはサーバーやクライアントで言語ごとにインターフェイスの定義とかをしなければいけないが、それを自動で生成してくれるのがgRPCコンパイラという感じ。
gRPCを使うには、protocol buffersというプロトコル定義言語(?)を.protoファイルに書いてgRPCコンパイラで言語ごとにコンパイルを行う。2018/10/28現在では公式にサポートされてる言語がC++, Java, Python, Go, Rusy, C#, Node.js, Android Java, Obj-C, PHP, Dartなどなど多岐にわたる。Rustは非公式だけどプラグインがあるので使える。
gRPC/protocol buffersの個人的なポイントをまとめてみる。
長所:
 サポートされてる言語が多い ツール自体はしっかりしてるのであまりその辺で変にハマることはなさそう streaming通信なんかもサポートされてる protocol buffers自体が後方互換性を命を懸けて守るという強い意志のもとに設計されてる まぁこれはそのせいで面倒なこともあるので短所でもあるけど、多くの人にとっては長所になりうるかと思う protoファイルからドキュメント生成するやつもある(proto-gen-doc) protocol buffers自体は普通にプログラミング言語による型定義みたいな感じで普通に書きやすい(少なくともswaggerみたいな地獄のyaml UXとかに比べたら断然楽)  短所:
 公式ドキュメントが死ぬほど分かりにくい(Googleだからしょうがない説もあるが) ツールのインストール方法などが死ぬほど分かりにくい 現状ブラウザによるネイティブサポートがない(grpc-gatewayを使うといいらしいよ) [追記] (grpc-webというので対応されたらしい) [/追記] 生成するコードにユーザー側の自由度がほぼないし自力でプラグインを書くのは多分大変(のでユースケースによっては全く使えないと思う)  最近はマイクロサービス間通信とかで採用されてる事例が多いみたい。実際にブラウザとの通信で使ってる人はそこまで多くない印象だった。
RustでgRPC Rustでサーバー側の処理を書く。
まず、上にも書いたようにprotoをRustコードに変換するgRPCコンパイラのRustプラグインが必要になる。これにはprotobuf-codegenとgrpcio-compilerを使うといいよってあった。
# インストール $ cargo install protobuf-codegen grpcio-compiler # コンパイル $ protoc --rust_out=. --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_rust_plugin` example.proto これによって生成されたRustモジュールを読み込んで使うことになるけど、それにはgrpc-rsを使った(grpc-rustというのもあるけどこっちは触ってない)。
サーバー側のプログラムはこんな感じで書くと良い。
コンパイルすると、protocol buffersのmessageが定義されたexample.rsと、RPC関連が定義されたexample_grpc.rsが生成される。
Node.jsでgRPC Node.</description>
      </item>
    
      <item>
        <title>ブログのテーマ(とGitの管理方法)を変えた</title>
        <link>https://myuon.github.io/posts/blog-simplicity/</link>
        <pubDate>Tue, 23 Oct 2018 22:53:56 +0900</pubDate>
        <guid>https://myuon.github.io/posts/blog-simplicity/</guid>
        <description>Git管理が色々あれなことになっており記事を書くのがとても大変なことになっていたので直したかった、ついでにテーマを変えた。
テーマはもともと自作だったのだけれどまぁ私はデザイナーではないのであるやつに乗っかる方が色々便利だということが分かったりした(自分で書くと、状況によって変な空白が出たりとかしがち)。
テーマを変えた Simplicity: https://github.com/eshlox/simplicity
というテーマにしました。シンプルですっきりだけど普通に見やすいと思う(シンプルで見にくいテーマも多いのでこういうテーマは貴重)
細かいところで前のテーマで便利だったけど失われてしまった機能性とかもあるのでそういうのはおいおい対応していきたい。
Gitの管理方法を変えた こっちがむしろメイン。今使ってる静的サイトジェネレータのHugoはGitHubで公式にサポートされてるわけではないので、自分でHTMLファイルを生成する必要がある。一方で、GitHubはユーザーリポジトリ(myuon.github.ioの形のやつ)はmasterブランチがそのまま表示されてしまうのでソースファイルの管理は別ブランチで行う必要があるなどの問題がありめんどいなーと思っていたのだけど、それを解決する方法が分かった。
結論としては次のサイトに書いてあるようなことをやればいい。
 [http://kohki.hatenablog.jp/entry/hugo-portfolio](Hugo + GitHub Pagesでポートフォリオを作る) [https://qiita.com/kwappa/items/03ffdeb89039a7249619](GitHub PagesのUser Pagesでドキュメントルートを変更するにはmasterを殺す)  masterブランチを殺して、代わりに git subtree push --prefix docs/ origin master とか叩くことで/docsをorigin/masterにpushできる。origin/masterって消せるんですね、知らんかった。
というわけで、よくわからないsubmoduleの管理などせずとも(gitのsubmoduleって結構難しい機能だと思う、いつもいまいちよくわからんって言って使ってたし結構気をつかわないといけなかったりする)、簡単にHTMLの管理ができるしpublishも1コマンドでできるしで便利～になった。
実はこの辺の問題があって最近はブログ記事を書けていなかったのだけれど、環境をえいやと整えたのでまたなんか書いていきたいと思います。
 そういえば私は飽きっぽいので今までいろいろなプロジェクトを始めては途中で飽きてやめたりしてきたが(ここ7年くらいでGitHubリポジトリの数は58になった)、最近は昔やってたやつを引き継いでまた始めたりということもちょくちょくやるようになったりしている気がする。良い傾向だし、そういう感じで過去に挑戦したプロジェクトのサルベージやら供養やらも自然にやっていけたらいいなと思ったり思わなかったり。</description>
      </item>
    
      <item>
        <title>VSCodeでIsabelle2018環境構築</title>
        <link>https://myuon.github.io/posts/isabelle-vscode-2018/</link>
        <pubDate>Sat, 28 Jul 2018 11:46:33 +0900</pubDate>
        <guid>https://myuon.github.io/posts/isabelle-vscode-2018/</guid>
        <description>こうなるよ   スクショ   環境構築   ほぼこれにある通りでOK  https://marketplace.visualstudio.com/items?itemName=makarius.isabelle Isabelleのインストール   http://isabelle.in.tum.de/devel/release_snapshot  から対応するプラットフォームのファイルをダウンロードして展開しとく VSCode pluginのインストール     Isabelle    Prettify Symbols Mode    bibtexLanguage (optional)    を入れる VSCode config   user configを開いて次を追加 &amp;#34;isabelle.home&amp;#34;: [Isabelle2018のルートへのパス],   VSCodeをリロードすると、初回であればビルドが走って、それが終われば&amp;#34;Welcome to Isabelle …&amp;#34;って出る  これで環境構築はOK 対応状況   VSCodeサポートは残念ながら完璧とはいえない    state: VSCodeで Isabelle: Show State しましょう, output panelが出る(白背景に勝手になるんだけどこれは設定できないのだろうか, ダークテーマだとつらい)    syntax highlight: これは問題なし    unicode symbolの入力: \&amp;lt;forall&amp;gt; とかで入力できるが結構カーソル移動の制御とかがキモイ, あと !</description>
      </item>
    
      <item>
        <title>静的解析の限界、現実世界との境界</title>
        <link>https://myuon.github.io/posts/how-far-can-static-analysis-go/</link>
        <pubDate>Wed, 11 Jul 2018 05:49:39 -0700</pubDate>
        <guid>https://myuon.github.io/posts/how-far-can-static-analysis-go/</guid>
        <description>はじめに   2018年に静的解析をとにかく強力につけまくるのは多分あんまりコストに見合わないのでよくない  じゃあ静的解析を窓から投げ捨ててよいかというとそれはただの愚行  (以下、静的解析を普通に使えてる人には自明なことしか言いません) 依存型のつらみ   私が最初に静的解析の限界を感じたのは多分依存型で遊んでいたとき  依存型の力はすごくて、まぁそれもそのはず命題論理から述語論理に進んで元への言及ができるので見かけ上表現力はとんでもなく上がるわけです。例えば「ある方程式を満たす解のみを受け取って何かする」みたいな関数が型として表現できるようになる。  一見すると最強に見えるんだけどこれは実質定理証明をすることなので、制限の強い型をつければつけるほど実装で苦しむ羽目になるということを割とすぐ痛感することになった。  例えば head : Vect (Suc n) a -&amp;gt; a で長さ1以上のvectorの先頭を安全に取り出す関数を表現できる。 これはコンストラクタを見るだけなので実装も簡単ですね。 それでは今度は quick_sort : (xs: Vect n a) -&amp;gt; \exists (ys: Vect n a). Increasing ys /\ Isomorphic xs ys (読み方としては、長さnのvectorを受け取って、「長さnのvectorであって、昇順に並んでおり、適当に順番を入れ替えるとxsに一致するもの」を返す関数と読みます)とかどうかというとまぁこれを見てすぐ実装が思いつく人はいないでしょう。  やってみると分かるがこれに実装を与えるためには相当な定理証明力を要求される。もはや関数型プログラミングですらない、単なる定理証明である。  とか言う話は↓にもよくまとまっているのでよければ読んで    問題を解決するつもりでキッチリ型を付けた先にある高い壁 - ぼくのぬまち 出張版    実世界を扱う依存型プログラミングのたぶん基本～外界から安全な世界までの道 - ぼくのぬまち 出張版   Welcome to 現実   上の記事にも書いてあるんだけど、実は依存型のつらみはこれだけではない(そして今回の記事はむしろこっちの話を書きたい)  例えば先程のquick_sort関数をめでたく実装できたとしよう、すると我々はwell-sortednessが証明されたquick_sortを手にしたことになる。素晴らしい！ではこのquick_sortを使ってみよう！  普通のアプリケーションであればquick_sortにはリストを食わせた後そのまま普通に使ってデータとしては捨てられてしまうかもしれない。quick_sortから返却されたリストが 昇順に並んでいる ことが保証されていなければならないアルゴリズムを書く人がどれだけいるのだろうか？ もちろんソートされていなければ後々まずいことになるということは往々にしてあるが、それが至るところに出現するということはあまりなさそうだ。数百行のプログラム中で1-2ヶ所、たかがその程度だろう。 quick_sortを実装するために支払ったコストは本当にここの嬉しさを上回るのだろうか？  あるいは、もっとひどければ全く利用されないこともある。ソートされたデータを一度DBやファイルに書き出してしまえば、型の保証はなくなってしまう。ファイルに書き込まれる前にソートされたことが型で保証されていたデータは、ファイルから読み出したときにはすでにその保証を失っている。   実際にはシステムレベルでの保証というのがある。ファイルに読み書きされると当然型による保証は失われてしまうが、「そのファイルがこのプログラム以外で読み書きされないことを仮定してよいのなら」ソートされたデータを書き込んだファイルは再び読み込むとソートされているとしてよいはずである。 というわけでプログラムの型レベルでは保証できなくとも、 システム全体がまともに動いているなら ちゃんと制約を満たしてくれているはず、というのがある。  システムレベルでの「保証」とは人間の頭の中にしかなく、通常いくつかの仮定が必要であるので型システムではうまく取り扱うことができず、例えば unsafeCoerce : a -&amp;gt; b のような関数の出番ということになる。 TypeScript、あるいはType Hints   めちゃくちゃ話が変わってTypeScriptの話をする(実はそんなに話は変わらない)。  先に引用をしましょうね    漸進的型付けの未来を考える - yu-i9.</description>
      </item>
    
      <item>
        <title>責務と層の分離</title>
        <link>https://myuon.github.io/posts/architecture-basic-idea/</link>
        <pubDate>Tue, 10 Jul 2018 02:49:04 -0700</pubDate>
        <guid>https://myuon.github.io/posts/architecture-basic-idea/</guid>
        <description> 設計の話   設計の話です。 責務   責務、誰がその仕事を行うかということを考えましょうというのはまぁさんざん言われていることだけど実際大事だと思う。  テクニックとしては委譲だのなんだのとあるけど、結局は「その仕事はその人に任せて本当にいいの？」にYesと答えられる場合にのみその作業をそのモジュールなり関数なりクラスなりに任せましょうという話ですね。 層の分離   プログラムが行う仕事は通常いくつかのオペレーションを組み合わせて実現されるわけだけど、それらの重要度というのは普通は一様ではない。  仕事によってはドメインレベルにしっかり固定されそれ以外のオペレーションがあり得ないものもあるし、今は一旦こうして実装しておくがあとで高確率で置き換える必要があるとかそういうやつ。  例えば今はハードコードしているが設定ファイルから読み込んだ値にしたい、DBを切り替えたい、データの中身が変更したいとかそういう感じのやつ。  そういうときに、それが所属する層を分離するという手法がたまに取られる。 DIが必要になる設計手法とかだとおなじみだけど、後から値を切り替えたいものはより外側の&amp;#34;層&amp;#34;にそれを押し出し、逆に変更が発生しないところに関してはより内側の層にそれを閉じ込めるというやつ。 責務と層の分離   なんでわざわざこういうタイトルをつけたかと言うとこの2つの意識が一番大事かなと最近思うようになったから  責務をはっきりさせることと層を分離するってことをひたすら繰り返すだけで大抵の設計手法はやっていけるような気がするなぁと思ったりした GoFのデザインパターンをチラ見して   本は読んでないのだけど、最近GoFのデザインパターンについてどういうものかを調べたりしていた。  一応目的としてはデザインパターンが解決しようとしている問題を明らかにしてモダンな解決策を探りたいというのが動機としてあった。  感想を正直に書くとまぁ基本的には内容が古い上にまとまってないしこれは名前つけるようなものじゃないだろというのが多い感じで2018年にわざわざ勉強する必要があるようなものではないなと思ったりしたという感じにはなるが、それはおいておいて デザパタのあれこれを調べていくうちに、上のような2つの点の大切さを認識したりした。  デザパタの多くは現代的な言語なら責務と層の分離がちゃんとできてたらほぼ問題にはならない気もする(こういう話も具体的な言語を固定して考えたりしてみる記事を書いてみるべきかもしれない)。 オブジェクト指向/DDDとか   「オブジェクト指向は設計ではない」と繰り返して言っていたら何かの折にDDDに触れる機会があり、「これは良いものだ」と思ったりしたことがあった。  [追記]DDDのlayerに関して適当言ってたので消しました。[/追記]  実際にDDDはドメイン駆動〜みたいなことを言っているが自分はそこで初めて層の分離の概念を得た。 DDDではドメイン層と〜 DDDのことはよく知らないんだけど例えばClean ArchitectureではEntity層, UseCase層, Adapter層, Driver層のように中にあるべきものと外に置くべきものをはっきり区別していたのが、オブジェクト指向でスパゲッティ設計を生み出し続けていた自分にはとても素晴らしいものに見えたというのがあった。  オブジェクト指向がなぜ設計ではないかということは、今にして思えばオブジェクト指向は責務については問題にするものの(あるメソッドをどのクラスに入れるべきかという話はよく問題に上がるが)層の概念がないので縦方向への広がりがないというのが大きな問題としてあったのだろうということが分かったりした。 終わりに   内容がない </description>
      </item>
    
      <item>
        <title>HaskellでDIする</title>
        <link>https://myuon.github.io/posts/haskell-di/</link>
        <pubDate>Fri, 06 Jul 2018 05:51:00 -0700</pubDate>
        <guid>https://myuon.github.io/posts/haskell-di/</guid>
        <description>DI   DIの重要性はここ数年で急速に高まってきている。 依存性が注入されたりとかそういうことはどうでもよくて、設計と実装を分けたい、人類はそれだけのために色々と工夫をこらし最終的にたどり着いたのがDIであったのだろう。  Haskellでも設計と実装を分けるためにDIしたいというのは自然な流れである。  ここでは型も含めて設計が実装に依存してはいけないということを要求する。 例えば設計でMySqlConnection、みたいな型が出現することも分離できていないので禁止とする。 問題点   設計を定義するときには他の言語ではインターフェイスなどの仕組みが使われることが多い。 Haskellには型システムという仕組みがあるのでこれがインターフェイス相当の機能として紹介される場合がある。  しかし型システムはインターフェイスとは違い、型を固定する仕組みがない。型クラス TypeClass a のインスタンスの値が x:TypeClass a =&amp;gt; a と y:TypeClass a =&amp;gt; a のように2つ与えられたとしても、xとyが同じ型である保証はないし、これが同じ型であることを強制するためにはxとyを同時に作って常に同時に運ぶ必要がある。  というわけでインターフェイスを使うと型が固定できないのでDIしようとすると困ったことになる、と私はずっと思っていた。 存在型とreflection   型を固定する仕組みは実はどうにかすることができて、要は存在型を使って data Trapped = forall a. TypeClass a =&amp;gt; Trapped a とやると型を外から見えないように隠蔽することができる。  存在型は中を開いたときにもともと何が入っていたかはわからなくなるが、設計ではそれを意識する必要がないはずなので特に問題がない。  さらに、いわゆるDIコンテナ的な仕組みでは生成したオブジェクトを必要なところに注入してくれるという機能があることが多いが、実はこれと同じこともHaskellではできる。  reflectionというパッケージがあり、これはconfigデータを外から与えるためによく使用される。 Given a =&amp;gt; ... なる型をもつプログラムは given と書くといつでも好きなタイミングで外から挿入されたaの値を取り出すことができる。  同じ型に対しては1つの値しか注入できないが、実際にDIするときは利用する型は1つだけなので問題がない。  というわけでこれでHaskellでもDIできそう！ということが分かる。 Loggerの例   例えばLoggerを作る例を考える。 設計  class Logger a where writeLog :: a -&amp;gt; String -&amp;gt; IO ()   ロガーは文字列を受け取って何かするというインターフェイスを実装した型のことであろう。ここでの a に、具体的なLogger型が挿入される。 data SomeLogger = forall a.</description>
      </item>
    
      <item>
        <title>Fluxを再発明する</title>
        <link>https://myuon.github.io/posts/refluxible-library/</link>
        <pubDate>Sat, 16 Jun 2018 08:00:49 -0700</pubDate>
        <guid>https://myuon.github.io/posts/refluxible-library/</guid>
        <description>Haskellの2D graphics libraryを作った   作った: refluxive  与太話に興味がない人は解説まで飛んでください なにこれ   大体Haskell製Fluxベースの2Dグラフィックスライブラリ on SDLという感じの代物です。 なぜ   大変悲しいことにHaskellではゲーム用に気軽に使えるグラフィックスフレームワークがないことがよく知られているわけです。 候補としては一部のFRP系のやつ、あとDSL系のやつも少々(これは用途がかなり限定されていることが多いけど)、それと今ならElm(!)が下手すると最有力かもしれない。 一応本当に簡単な用途ではglossがそれ系を標榜しているがフレームワークではないし、真面目に使うには多々至らぬ点も多く…という感じなので困った困ったになるわけですね。  —  なぜフレームワークがほしいかというとUIを一から作りたくないというのがある。私はあと何回「ボタン」をrectangleとfillRectangleとtextを組み合わせて一から作らないといけないんだ。 画像を読み込んできて3x3マスに分割して「レイヤー」として表示できるようにするみたいなのも何回も書かされたのでもう散々という気持ちがあった。  グラフィックスライブラリは別にOpenGLでもSDLでもGLFWでもなんでもいいんだけど一からUI部品を作っていると日が暮れてしまうのでそういうUI部品をライブラリとして提供したくて、じゃあUI部品を共通して作って提供できる仕組みをどうにか考えないとなぁという感じになってた。 Flux   JavaScript(クライアントサイド)業界ではこの辺をみんな真面目に考えて色々やっていってるわけですがまぁ最近はFluxの影響を受けたやつが人気なので私もそういうのにのっかる感じにしました。 といっても完全なFluxでもないと思う。ViewがModelの射影になっていること、Viewへの変更がSignalとして送出されてModelの方に伝わるみたいな感じになっているのは大体Fluxだけど、dispatcherではなくSignalの送出はベースのUIモナドが一括で請け負ってるとことかはちょっと違うような気もする(詳しくないからよくわからんけど)。 Haskellとは   HaskellでFluxぽい仕組みがちゃんと乗っかるかは若干不安だったけど特に問題はなかった。そもそもこっちはDOMを操作する必要がない、何もない代わりに何にも縛られないのでまぁ自由は効くよねという感じ。 Haskellらしいコードになったかという意味では、default-extensionsを見てもらえばまぁ察しはつくと思う。今回はExistentialQuantificationとTypeFamiliesとDataFamiliesを使いまくったのでHaskell(GHC)でこそという感じはしてるような気もする。 テクいところ   最近Rustに浮気しっぱなしだったからHaskell真面目に書くの実はそれなりに久々だったけど、ちゃんとRustや他で勉強したりしてたことが活かせたりはしたと思う。 performGCとかunsafeCoerceとか今までどう使っていいかよくわからなくてやってなかったけどちょっと分かってきた感じもありよかった。 refluxive   ライブラリの中身を超簡単に解説します。 「ほーんHaskellではそうやってやってるんだー」くらいで見てもらえればいいと思います。  あと当たり前だけどまだプロトタイプができたてのライブラリなのでAPIは将来変更されるおそれが大いにあります。 構成要素     Component: 1つの部品を表す単位; 中にModelとかそういうのが定義されているが外からは見えない    Model: Componentの内部状態    Signal: Componentから送出されうるメッセージ 他のComponentはSignalを監視して非同期にcallbackを実行したりできる    ComponentView: Componentをインスタンス化したやつ、モデルのデータそのものとかuniqueな名前とかが入ってる    Graphical: Viewの表現    UIモナド: Componentの操作とかを実現するためのモナドで、Componentの管理、送出されたSignalの配信などをやってくれる   例:ボタン   とりあえず例をやろうということでボタン。  https://github.</description>
      </item>
    
      <item>
        <title>私と型システムとポエム</title>
        <link>https://myuon.github.io/posts/type-system-poem/</link>
        <pubDate>Sat, 02 Jun 2018 08:27:31 -0700</pubDate>
        <guid>https://myuon.github.io/posts/type-system-poem/</guid>
        <description>  最近巷では俄に型システムについての言及が増え、型システムポエマーが増えてる気がするので自分もその時流に乗りたい。  完全にポエムだけどなんかあったら随時指摘ください。直します。 TL;DR   言いたいことはまとめると次    型システムは程度問題なのでちょうどいいところを探すべき    型は万能でも強さが正義でもない(だから未だに研究されてる)    よく知りもしないくせに計算機科学を侮辱するのはやめろ 予防線     あくまでポエムですので中身はないです  私は型理論専攻で学位はとったものの研究者ではないのであまり信用しすぎないように 型システムの過去   型システムは大まかに次のような利点があるとされてきた(個人的主観)    「異常」なプログラムを検出する仕組み    静的解析による分かりやすいエラーメッセージ    型そのもののドキュメント性    IDEでのcompletionに貢献    最適化に貢献    (数学に正しく裏打ちされたsemantics)   型システムの分類と主な特徴   当たり前だが型付き言語も一枚岩ではなく、色々違いがあるので少し分類をしておく。下に行くほど強い。 型なし(動的型)言語     言語: untyped lambda calculusやLL系言語など    LL系とは言ったものの例えばPythonは最近type annotationがかけるし、あるいは型のない言語でもIDEが静的解析を行い実質型システム相当のチェックを行う言語があったりするので型の恩恵を一切受けない言語はイマドキそう多くはない。 型システムの人間からは型なしは型なしとして一緒くたにせざるを得ないが、別に型なしを嫌っているわけではない。それも一つの言語の在り方である。まぁ私は死んでも書きたくないけどな。 クソザコ型(データサイズアノテーション)言語     言語: C    かつて非型システムの人間にとって「型」とはこれであった。今でもこれを型システムと思ったまま脳みそがアップデートされていない人間もいると思う。 要は変数にint, floatなどのアノテーションがつき、これは実行時のその値のデータサイズを表す。 大半の型付きの言語はこの機能を内包しているが、これはあくまで現実のコンピュータのアーキテクチャに寄り添ったエンジニアリング的観点により導入されることが多い。 これを型システムと呼んでもいいかは諸説ある。私は呼ばない。 割と単純な型をもつ言語     言語: simply typed lambda calculus、関数型はあるがジェネリクスを入れてないような一部の言語    ジェネリクスを入れると考えることが多くなるのでこの辺で落ち着くという選択肢もある。Goとかはこれかな？(よく知らないで言ってる)。 すごく単純なプログラムしか書かないなら、静的解析も楽でコンパイルも早くそれなりに型の恩恵も受けられてよい落とし所だと思う。ただライブラリを作る人にとっては抽象化への障壁が大きすぎると感じるかもしれない。 頑張れば型推論の決定性を保てる言語     言語: OCaml, Java, C#など    多くの(現場で使われるような)静的型付き言語はここに属することが多い。 (実際はいろいろな事情によりできてない言語が多いが)OCamlに代表されるようにジェネリクスとサブタイピングまで入れても型推論は決定的にできる。 型を人間は書きたくないが抽象化はさせろという人にとっては最も都合の良い着地点になる。現状多くの人に受け入れられているように見えるので成功した型システムの一つと言っていいと思う。 この言語ではオーバーローディングなどの型推論を阻む仕組みに対してどのように対抗するかというのが大きな問題になる。現状では政治力と運用でカバーしていることが多いような気もする。 typeclass/rank n types/higher kind polymorphism言語     言語: Haskell2010, Haskell(GHC), Scala    型推論の決定性を窓から投げ捨てて暗黒面の力を手に入れたやつ。OCamlは職人技のような言語デザインで決定性を保っていたのでそこに少し拡張を入れたり少し条件を緩めたりするだけであっという間に暗黒面に堕ちてしまうので意図せずこっちに転がってる言語もたまにある。 明確に意図してここに足を踏み入れた言語は(実用面でも使える言語となると)限られてくるが、型推論を気にせず理論的に便利な道具をたくさん追加できて気持ちよく型レベルプログラミングとかで遊べるようになる。 しかし暗黒面と称されるようにここから先は地獄である。依存型の誘惑を振り払うのは難しい。 依存型言語     言語: Idrisなど    依存型を持つ言語はAgda, Coqなど色々あるがだいたいは証明用途なのでプログラミング言語とは呼べない。実用で使う人は多分いない。 強けりゃいいってもんじゃない   型システムには色々あるし上の分類も本当はもっと細かくわけられる。が、大事なのは強ければいいというものではない。  強い型システムはだいたい次のような問題との戦いになる    型推論が効かなくなってクソ長い型を書かされる    コンパイル時間が増加する    言語ごとの型システムの限界に阻まれる    コンパイラを制御するために型レベルプログラミングで人間が消耗する    人間が消耗するというのは笑い事ではない。型レベルプログラミングとは型システムの限界との戦いであるし、そこで目的を達成するためには型レベルのエンジニアリングが必要になる。大変不毛なコードを書くことを強いられたりコンパイラの推論能力ギリギリを攻める羽目になったりする。実行時エラーをコンパイルエラーにするために途方もないコストを支払う羽目になる。  それと現実世界との兼ね合いという問題もある。 実際にプログラムを書くためにはどこかで現実世界の仕組みとブリッジする必要があり、現実世界は型がガバガバなのでその境界付近にすべてのしわ寄せが行く。これは型システムというか静的解析の宿命で、HaskellやScalaに限らずRustなんかでも顕著であるというのが私の経験則としてある。 よくある誤解   さて型システムはよく誤解されていて、間違った言説を垂れ流す人間が後を絶えないのでしょうがなくいくつか訂正をここにいれる。ここに上げた誤解を型システムが専門の人間に吹き込み続けると泡を吹いて絶命するのでやめよう。 「型のある言語は型を書く必要がある」   一番良く見るやつ。戦犯度が高い。二度とその口を開くなという気持ちになる。  型推論という仕組みがあるので一般には嘘であるが、一部の言語は言語のデザインとして(理論的限界ではない)型宣言を強制しているのでそのへんからくる誤解だと思う。Javaお前のことやぞ。 「型とか見ればわかるんだからチェックする意味なくない？」   クソザコだとまぁそういう面は多少ある。弱い型システムでも一応次のような利点はあるよって言ってる。    タイポと仕様変更に対する予防: 型が変わったことを検知できるのでAPIを安心して破壊できる    間違った使い方をさせないようにライブラリ作者がユーザーを縛る: あらゆる可能性を想定するのはしんどいので   「IDEが色々教えてくれるから型とかいらん」   そのIDEがやってるのは実質静的解析だぞ 「将来的に型推論が発展したら型を書かなくてよくなる」   これができるかどうかは決定性依存であり、System Fなどそれなりに「強い」型システムは決定的でないことが示されてしまってるのでそのへんは理論が発展しようがどうしようもない。 そして型を書かなくてよい型システムはすでにある。その意味では型推論はすでに十分に発展したとも言える気がする。 「将来的に型から実装を導けるようになる」   なわけない。IntからIntへの関数がいくつあると思ってるんだ。 実際にはparametricityが効いてて型から実装を導ける場合はあるけどそれはそれなりに特殊な状況に限られる。  ただまぁ「満たすべき条件」から実装を導くという研究はそれなりにある。個人的に型システムとして実現されるとは思ってないが、指定した条件を満たす関数をコンパイラが提案してくれるみたいなのはそのうち多分出てくると思う。 「依存型っていうのがいいんでしょ？」   依存型を導入することは定理証明をすることと紙一重である。まじで地獄なのでおすすめしない。 「Javaでは〜」   Javaが静的型付き言語の代表みたいな言い方はやめろ。 「LL言語でも型入れればいいのに」   これは結構微妙な問題も含んでいて、一部のLL言語では動的に色んなことできますみたいなのが売りになってたりするのでそういうところを壊さずにちゃんと型をつけるのは結構難しい。あと技術的にはできても、ライブラリとかとの兼ね合いもあるから実際にそういうのを突っ込むのは難しいのではないかと思ったりする。 そういう意味で、既存の型なしの言語に型を入れるよりも、似たような文法でちゃんと型のつく言語を作って既存のを駆逐するほうが早いと思う。みんな頑張ってくれ。 型システムのこれから   ここからは完全に私の狭い観測範囲からの妄言になるけど、型システムは強くしたり合体させたりするフェーズは終わりつつあると思う。 これからはむしろ特定の状況にマッチした静的解析を乗っけた言語をいっぱい作って属性で特化させるんじゃないかなと。 例えばRustはregion推論をベースに先陣を切ったけど、そういうふうに「こんな静的解析が乗ってますよ」みたいな一芸型システムをMLに突っ込んだみたいな言語が増えてきそう。  自分はモナドとかエフェクトとかやってたからエフェクト関係でそういう言語ほしいな〜と思いつつ、実際は現実のAPIを呼ぶところをどうやって解決するかとか、あとはまともに使えるようにするためには決定性の壁とか色々あって厳しかったりして難しいかなぁって感じ。 おまけ   エンジニアリング業界では、Javaがそれなりに鍵を握ってるような気もする。 一部の人達はJavaが型付き言語の代表格だと思ってるフシがありそのへんから誤解というのが生まれるのだろうけど、逆に言えばJavaが今だんだん変わろうとしているというのはそういう層に正しい型システムと型付き言語によるプログラミングを浸透させるきっかけにもなるだろうし。  あとは型システムに対して適当を言うのは本当にやめよう。私はついったーでそういう発言に対してよくキレているが、そういう適当はこれまでの偉大な計算機科学者たちの生み出してきた素晴らしい業績への冒涜にほかならないからである。 すべての人間が型理論を勉強するべきとは思わないが、多くの人が積み上げてきた理論に反することをなぜそんなにも簡単に口にできるのか不思議でならない。  というようなことをよろしくしたいんだけど、本当によろしくしたい層には届かないんだよこういうのは。 </description>
      </item>
    
      <item>
        <title>Desktop Linux VM環境 on Windows</title>
        <link>https://myuon.github.io/posts/vm-linux-on-windows/</link>
        <pubDate>Sun, 20 May 2018 08:11:42 -0700</pubDate>
        <guid>https://myuon.github.io/posts/vm-linux-on-windows/</guid>
        <description> はじめに   私はプログラミングはすべてLinux環境でやっている。環境構築、フォントレンダリング、まともな端末など理由を挙げればキリがない。 最近までDesktop Linuxを直接インストールしていたが(Windowsを持っていなかったが)、ゲームがしたいなどの理由によりWindows 10を買ってクリーンインストールしたのでLinux環境をVMに移行した。 結論   Vmware Workstation Playerを使え Vmware Player vs VirtualBox vs Hyper-V   仕組みの上ではHyper-Vは他2つに比べてハードウェアに近く、よいパフォーマンスが得られることが期待される。 が、3つを試した上では圧倒的にVmware Player &amp;gt; VirtualBox &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; Hyper-Vという感じだった。  環境    ホスト: Windows 10    ゲスト: Ubuntu 18.04 Gnome/Xfce    ゲストの設定: メモリ4GBくらい 4コア使っていいよぐらいの設定 特に細かくいじったりはしてない    結果    Hyper-V: 入力遅延が大きすぎて使い物にならない、マウスもキーボードも数フレームは遅延してる。あと3つの中では明らかにこれだけ重かった(Gnomeのアニメーションの挙動とかを見ている限り)。Hyper-VのViewerがボロいのかと思ってRDP接続も試したけどVirtualBoxと比べても明らかに重くパフォーマンスが出てなかった。LISはUbuntu 16版のものを使用、BIOSでC-State切るといいよって言われてそれもやったけど効果ほぼなし。    VirtualBox: 比較的サクサク。Gnomeだとちょっと重いがXfceだと普通に快適。VMの起動と終了がちょっと重いかなくらい。    Vmware Workstation Player: 3つの中では最もサクサク。Gnomeのアニメーションもそれなりに反映されていた。Xfceにしたら本当に早い、実機インストールかと錯覚する快適さ。体感ではVMの終了がVirtualBoxより早い。    試すとわかるけど悩むまでもないという感じ。 ただしVmwareのみディスプレイサイズがホストOSのものに勝手に従ってくれなくてxrandrからaddmodeした。  そもそもプログラミングするだけならDEいらないんじゃないですかという話もあるけど今はGUIアプリケーション開発してるからそうも行かないんだよな〜って人の話です。 </description>
      </item>
    
      <item>
        <title>動画編集ソフトを作り始めた</title>
        <link>https://myuon.github.io/posts/madder-start-to-create/</link>
        <pubDate>Sun, 04 Mar 2018 19:21:20 +0900</pubDate>
        <guid>https://myuon.github.io/posts/madder-start-to-create/</guid>
        <description>Rustを使い始めて1ヶ月だぜ体験記みたいなのを書こうとしたけどせっかくなので今やってることも全部まとめて1本の記事にすることにした。  最近日本語をかくのがめんどくさい以外の発言をしていない気がする。  1ヶ月ほど前に動画編集ソフトを作りたくなって、言語はRust メディアフレームワークにGstreamer GUIにGTK+を使うのだけどこの3つをどれも触ったことがない状態で作り始めるという完全に勢いだけのアレというのが前置き。 Rust   前回の記事でも色々言ってたけどその後分かったことなんかを記しておく(本当はWHAT I WISH I KNEW WHEN LEARNING RUSTみたいにしてまとめると良いのだろうなぁ)    とりあえずメモリモデルとしてはスタックとヒープがあるということだけ分かっておけば大丈夫そう    structのフィールドに参照をもたせるとlifetime parameterにコードがまみれるのでやめたほうが良さそう    Rc&amp;lt;RefCell&amp;lt;T&amp;gt;&amp;gt; が便利(これは主にGTKを使う時に必要になったというのもある)    Rc&amp;lt;RefCell&amp;lt;T&amp;gt;&amp;gt; は確かに便利だけど hoge.borrow_mut().call(hoge.borrow()) みたいなことをするとBorrowMutError: already borrowedで実行時エラーになって死ぬので気をつけよう    参照が欲しいときはBorrow, BorrowMut, AsRef, AsMutトレイトの実装があるかを見よう    Derefトレイトは神    Fn, FnMut, FnOnceの意味がようやく分かってきた FnOnce系はちょっと気をつけたほうがいい(Option::unwrapがselfを消費するのとか)    trait, implは飽くまでインターフェイスの提供だけなのでデータの扱いはstructで行う    OOPっぽくコード書きたいときはtrait objectと動的ディスパッチの仕組みを上手く使う(果たしてこれが正しいアレなのかはよく分からん)    マクロは便利    別言語でtrailing commaで怒られると厳しい気持ちになる    if letが意外と便利    言語拡張が結構カジュアルに欲しくなるのでこのままだとnightlyしか使わなくなりそう    文字列リテラルが常に&amp;amp;strなのは意外とパターンマッチの時にめんどくさい マジでViewPatterns拡張が欲しい マジで    大抵の他の言語でもそうなんだけどasって書くのめんどくさい    あと as (i32,i32) って書けないの割と不便    前は「ブロックをclosureや関数として切り出してくると怒られるの理不尽💢」みたいなことを思っていたのだけれど、closureや関数は複数回呼ばれる可能性がある上に呼ばれるタイミングが不明なので所有権をちゃんと考えないといけないということが分かりスッキリした    最近Derefは神だなと思うことがあり、今まで(なんでこれ型が合うんだろう〜)って思ってたところは大体Derefのおかげであることが分かったりした。  例えば hoge: Rc&amp;lt;RefCell&amp;lt;T&amp;gt;&amp;gt; に対して hoge.</description>
      </item>
    
      <item>
        <title>Rustに入門した</title>
        <link>https://myuon.github.io/posts/rust-started/</link>
        <pubDate>Fri, 09 Feb 2018 22:21:42 +0900</pubDate>
        <guid>https://myuon.github.io/posts/rust-started/</guid>
        <description>  Rustに入門して2週間くらい経ったぜ  TL;DR Rustは普通に便利ないい言語 入門した   入門にあたってはプログラミング言語Rustを読んだ。これの翻訳版ぽい。  読んでRustに対して思ったこと:    読んだやつは古いドキュメントの翻訳版だったようで一部記述が古いっぽかった    構文はシンプルだけど必要なものは揃ってる感 ML風でADTもパターンマッチもあるしtraitもあって言うことナシでしょ    所有権とか借用とかそういう聞いたことあるワードは参照という概念に対するアレっぽい    ｽｨｰ言語を気軽に(unsafe)呼べるのはFFIするとき良さそう 強そう    マクロ割と便利そうな雰囲気ある    RcとかArcとかCellとかいう便利なものがあるらしい あとBoxはいつ使うんじゃ    参照わかったようでわからない とりあえずスタックとヒープの違いは覚えたぞ    入門書なのに普通にするする読めてしまったし特に難しいことがなかった、もしかしてRustは簡単なのでは？？？    参照とかいう概念がある言語を長らくやっていなかった(Pythonは基本参照だった気がするけど意識する場面ないしHaskellの参照もあんまり使わないしなぁ)ので 「あー参照だとこういうことも考えないといけないのかぁ」って思ったりした  参照、人類には早すぎるのでは？？？って感じ ちょっと書いたりした   ちょっと書いたりした(してる)  どうせなのでなんか作ってみるかぁと思ってgstreamerとGtkで動画をごにょごにょするアプリケーションを作って遊んでる。 なんで入門していきなりそんな重いもの作ってんだよという感じなのだけどRustの強みはやっぱりCにFFIしやすいことな気がしていて逆にHaskellでは現状まともにビルドできてまともに使えるGUIライブラリがないので、そういう意味で(Rustの強みを活かせるという意味で)GUIアプリケーションぽいものに着手した。  まぁまだそんな書いてないしな〜(と思ったがすでに700行近い。Haskellなら500行超えるだけで相当だけど中括弧でブロック表す上に手続きがデフォルトの言語ってめっちゃ行数かさむよね。)  しばらく書いた感想:    エラーメッセージがカラフルや…なんだこれ…(GHCも最近カラフルになったけど未だに慣れない感ある)    ｽｨｰ言語と違って コンパイラが信用できるーーーﾔｯﾀーーー(踊りだす)    エコシステムが強すぎてビビる(いやHaskellがダメなだけか…？)    Rc Cell RefCellあたりがあまりに便利    所有権意識する場面あんまない    *(スター)はRustが勝手に補ってくれるって書いてあったので一切書いてないんだけどいいのかこれで 結局*が何者なのか未だによくわからない    そもそも自分はHaskell出身だからmutとか使う場面あんまないな そりゃ苦労しないはずですわ    FFIするのはほんとにシームレスで強さしかない    参照、人類には早すぎるのでは？？？？？？    ポインタだとコンパイル時にアドレス分の長さしか食わないがデータによってはコンパイル時にその長さが分からないみたいなエラーを見て、長さがわからないとallocateができない！そういうのもあるのか！になった    lifetimeの存在により自然にステートの管理の意識がブロックに宿るようになるの結構すごい 人類はステート管理に対する新たなやり方を手に入れたのでは？ってちょっと思った    もしかしてRustは簡単なのでは？？？？？？   所感   巷では難しい言語だみたいに言われることがあるような気がするけどめちゃくちゃ簡単やんけ！と思った (自分は特殊な人間である自覚はあるので大方の人には難しいのかもしれない)  というか、たしかに所有権を完全にコントロールして正しい設計を導き出すのは難しいんだけど、それは参照とかいう概念が全て悪いのであってRustはむしろそれを管理するための適切でhuman-friendlyな方法を提供してくれてるしすごいいい言語じゃん！と思ったりした  あとコンパイラを全面的に信用できるのも大きい。雑なことしてもどっかおかしかったらコンパイラが教えてくれるしな！という感じでガシガシ書いていける。  「higher kind typeがない」って言うのは聞いてて自分は今の所なくていいんじゃない？派なんだけどやっぱ場合によっては不便なんだろうか。 HKTって実装のコストと学習コストの肥大化の割に恩恵が大したことないというイメージだし、どうせHKT入れても次はアレをいれてくれコレもいるだろみたいになるのは必至なので(型システムとはそういう宿命なのだ)今の小さくて十分パワフルなRustでいいんじゃないでしょうか。  それでも自分はHaskellの方が圧倒的に慣れてるのもあるので、敢えてRust使うならやっぱGUI方面かな〜(RustはFFI強いし楽だし一方Haskellは全然ライブラリメンテされてないし)と思ってる。 まーでもmakeLensesしないとまともなレコードも使えない某言語を頑張って使い続ける理由はあるのだろうかというアレも。 やっぱRustに比べるとHaskellは難しい言語だなぁと思いますね。  以上 </description>
      </item>
    
      <item>
        <title>Namespace Haskell</title>
        <link>https://myuon.github.io/posts/namespace-haskell/</link>
        <pubDate>Sun, 04 Feb 2018 13:55:38 +0900</pubDate>
        <guid>https://myuon.github.io/posts/namespace-haskell/</guid>
        <description>Haskellにモジュールシステムが欲しすぎたのでNamespace Haskellとして提唱したい。 主な機能  open import   Agdaにもある機能で、importをimport(モジュール読み込み)とopen(現在のコンテキストに名前を公開)に分割する.    import M とすると, M.func によってモジュールMの関数funcにアクセスできる    open M とすると, それを指定したブロックでMの関数を修飾子なしでアクセスできる    open import M とすると, import M; open M の意味になる(現在のHaskellのimport)    openをwhereブロック内で宣言することで、一部でしか使わないimportをあっちこっちで展開するのを防げる。 public export   現在のHaskellではモジュール宣言時に module M(..) where でexportする関数を選べる。  そして module M where は全て公開の意味になるが、これを全て非公開に変更し、モジュール内で export (..) のように宣言したもののみexportすることにする。 associated function   要は「メソッド」機能なんだけどtypeclassの関数のことをメソッドって呼ぶことがあるような気がするので名前の衝突を避けるためにここではassociated functionとよぶ.  次のような、データ型とそれに対する特別な関数定義を行うスコープを用意する。 -- 例 data List a = Nil | Cons a (List a) impl (this :: List a) where { reverse :: List a reverse = .</description>
      </item>
    
      <item>
        <title>プロジェクトマネジメントを始めたい</title>
        <link>https://myuon.github.io/posts/want-to-start-project-management/</link>
        <pubDate>Sun, 14 Jan 2018 23:14:19 +0900</pubDate>
        <guid>https://myuon.github.io/posts/want-to-start-project-management/</guid>
        <description>資料     担当になったら知っておきたい「プロジェクトマネジメント」実践講座: 2ヶ月前くらいに買って読んだ    ゲーム開発 プロジェクトマネジメント講座: スクエニの資料 具体例がゲーム開発だけど内容は業種を問わないと思う   プロジェクトマネジメント実践講座を読んだ   内容は大変丁寧な感じでモチベーションと具体的な例を上げつつPMの重要性、あと必要な各種書類や仕事の詳しい日本語による解説という感じ。 それなりにページ数あるけど圧縮したら15ページ+図表くらいで収まる気がする(チートシートほしい) モチベーションを十分理解している人は安心して読み飛ばしていいと思う。  個人的な感想    PMでは「納期を守る」という感覚が一番大事っぽい    やたらExcelを推してくるのは逆に言えばまともなツールが他にないのだろうなぁ    リスク管理についても書いてあってなるほどと思った(リスクを先に想定しておくのは難しいけど大事っぽい)    モチベーションの説明がわかりやすい    プロジェクトの発足と仕事を作って人に割り振る時のマネージャーの動き方について主に書いてる感じ    読んでる時はもっと色々思ったはずだけど読んでから時間経ちすぎて忘れた 個人的に気になった方法論   「PMの話」っていうと結構マネージャーの動き方とか仕事の仕方的なものを指すこともあるんだけど(サイクルはこまめに回しましょうねとかそういう) 自分が欲しいのは方法論なのでそっちについてちょっとまとめておく WBS &amp;amp; ガントチャート   各node Xに対しXを作るのに必要なもの/作業を子nodeに置いた高さ4のfin. branching treeをWBSと呼ぶ(めちゃくちゃかっこいいなこの説明って思ったけど誰にも伝わらないと思う)。 WBSに実際のスケジューリングを与えるものをガントチャートという。  これらを作るのは自然なことなのだけど、問題は実際の作業の間には依存関係があることで、これを上手く管理するのは結構難しい。  基本は依存関係に沿ってトポロジカルソートして作業を進めればよいがそういうことが簡単にできるツールって意外と少ないよな 本ではExcelって言ってたが果たして 重要度-時間分割   これはスクエニの資料の方にあった話で、各作業に 重要度: 高/中/低 および かかる時間: 大/中/小 をそれぞれ割り振って3x3のボードに配置する。 手を付けるべき作業によい感じに優先順位を割り振るときに便利そう。 スケジューリング   各作業に対して締め切りを(最速見積もりと最遅見積もりの2点見積もりがいいらしい)割り振る。 その上で、要素成果物Yに対して作業X1.</description>
      </item>
    
      <item>
        <title>GHC拡張一覧を眺める</title>
        <link>https://myuon.github.io/posts/ghc-exts/</link>
        <pubDate>Sat, 13 Jan 2018 00:38:01 +0900</pubDate>
        <guid>https://myuon.github.io/posts/ghc-exts/</guid>
        <description>GHC-8.2.2のGHC拡張を眺めます。    10. GHC Language Features User&amp;#39;s Guideの該当セクション    7.6.12. Language options 単に一覧が欲しいだけならここの -X から始まるものを見ると良い    上から順に見ていって後から関連するものとかを再編します。 GHC拡張一覧    AllowAmbiguousTypes    型変数が全て決定していないものを通すようにする (個人的)非推奨1   Arrows    arrow notationを使えるようにする FRPする人なんかは使う   ApplicativeDo    do-notationがApplicativeに対しても使えるようになる 個人的には嫌い   BangPatterns    関数の引数やデータ型のパラメーターをstrictに評価する; Strict拡張で事足りることが多い気がする   BinaryLiterals    バイナリ表現が使えるようになる( 0b11001001 みたいなやつ); 使ったことない   CApiFFI    FFI関連; 使ったことない   ConstrainedClassMethods    型クラスのメソッドに型クラスが受け取る型変数を含む制約が使えるようにするやつ; これHaskell98だとだめってマジ？(そらそうよ)   ConstraintKinds    Constraintというカインドが使えるようになる   CPP    Cプリプロセッサが使えるようになる THの代わりにお手軽マクロとして(大量のinstance宣言とかに)使ってる人をたまにみる   DataKinds    データ型の宣言をカインドの宣言へ昇格する   DefaultSignatures    型クラスのメソッドのデフォルト宣言が書けるようになる; Genericsを使った定義みたいな、汎用的な型に対して定義できるけど具体的な型についてはspecializeした方がいいみたいな場面で使われる   DeriveAnyClass    defaultで宣言したメソッドのみをもつ型クラス、あるいはminimal definitionがない型クラスのinstanceをderivingで導出できるようにするっぽい 詳細色々ありそう   DeriveDataTypeable    deriving Data ってかける   DeriveFunctor    deriving Functor ってかける   DeriveFoldable    deriving Foldable ってかける   DeriveGeneric    deriving Generic ってかける   DeriveLift    deriving Lift ってかける LiftはTHのこれで、値をsyntactic expressionに変換できるようにするやつ   DeriveTraversable    deriving Traversable ってかける   DerivingStrategies    derivingって書いた時に適用されるストラテジーが衝突する場合にそれらをexplicitにかけるようにするやつ？ ナニコレ   DisambiguateRecordFields    \k -&amp;gt; k {hoge = x} におけるkのような、推論可能だが曖昧なレコード名を許す   EmptyCase    case x of {} ってかける Void型を扱う時なんかに使える   EmptyDataDecls    data Empty のようなコンストラクタを持たない型の宣言を許す   ExistentialQuantification    exist型が使えるようになる 非推奨とまでは言わないけど使いどころはよく考えたほうがいい   ExplicitForall    型宣言のimplicitな全称量化をexplicitにかけるようにする id : forall a.</description>
      </item>
    
      <item>
        <title>V.S. Hask圏</title>
        <link>https://myuon.github.io/posts/versus-hask-category/</link>
        <pubDate>Fri, 05 Jan 2018 22:52:56 +0900</pubDate>
        <guid>https://myuon.github.io/posts/versus-hask-category/</guid>
        <description>Hask圏   Haskellをラムダ計算とみなした時のsyntactic categoryをHask圏というのがよく言われる定義である(と思う)。 Haskellのtypeをobject, hom(A,B) をjudgement x:A |- M:B 全体(を適当な同値関係で割ったもの)とみなして圏を作る(このときしばしばjudgementとこのjudgementから作ったfunction λx.M を区別しない)。  さて基本的な結果として次のことが知られている。    Hask#Is Hask even a category?    Hask is not a category    というわけでHask圏は圏にならないのでそのようなものは存在しない。 Why not?   これはundefinedというヤバイ元の存在とcall-by-needの悪魔的評価規則が合わさりこのような現象が生み出される。 主にこの2つが悪さをしているので、この辺をどうにかできればHask categoryが作れる可能性がある。 undefinedを抜く   undefinedは「評価ができない(プログラムが正しい値を返さない)」ことを表す元で、普通は(多分)domainのbottomに対応させ、無限ループするプログラムの解釈なんかに使う。 undefinedを抜くためにはプログラムが常に停止して値を返す必要があるので無限ループができないようにする必要がある。  とまぁ言うのは簡単でfixpointを抜けばいいだけなんだけどfixpointもないcalculusがプログラミング言語を名乗るのは片腹痛いのでこれはちょっとナシかなという気持ちになったりする。 call-by-needを捨てる   call-by-needを捨てて、call-by-valueとかcall-by-nameとかそういうやつに行くというのも1つだと思う。 GHCのStrict拡張を入れてライブラリもStrict付けて全てビルドしなおせばそれはもうcall-by-valueになる(よね？)はずだったり、まぁcall-by-nameもcall-by-needみたいなもんやろという乱暴な考え方によりcall-by-needを捨てるのは現実的な案だと個人的には思う。  しかしcall-by-needではないHaskellはそれはもうHaskellなんですか(反語)ということもあるのでアイデンティティを捨てる勇気が必要かもしれない。 ここからポエム   いずれにせよHaskellという純粋関数型プログラミング言語でHask圏を考えるというのは無理があるということが分かるのだけれど、じゃあHask圏についてcomputer science的に意味がないかというと個人的にはそんなことはないと言いたかった。  個人的に、CSとは「計算機で観測可能な現象に説明をつける」学問であると思うので、実際にHaskellという言語で観測可能な現象について圏論で説明をつけようとする営み自体が否定されることはないと思う。 計算機が発明されて間もないからなのか人類が遅れてるのかはわからないけれど今は計算機の説明を付けるために用意した圏論的なモデルが上手くモデルとして機能していない(モデルが現象の構造を反映する力が弱い)のかもしれないけれど、とりあえず数学的にわかりやすいモデルを取ってきていくつかの技術的な難しさ(categoryにならないとかね)を無視した上で似たような現象をシミュレーション出来ないかを調べている段階だと思えばいいんじゃないかなと。  実際にHaskellに限らず色々なプログラミング言語で観測可能な現象について圏論の方からそれっぽいモデルを提供するぜ的研究はあちこちで見られるので、call-by-needとかにも上手い説明を付けられる直観的で構成が大変じゃないモデルを誰か思いついてくれればよいのだけど。 data &amp;amp; codata   HaskellのListがListかつColistであるというのは有名な話だけれど、こういうdatatypeかつcodatatypeがとれるような圏を考えるきっかけは(歴史的なことには私は詳しくないのだけれど)こういうプログラミング言語からの現象が先にあったのかな？と想像してる。 ちなみにこのようなcategoryはalgebraically boundedと呼ばれたりします。 enrichmentの隠蔽   関係ないのだけどHask categoryで圏論やろうとするとenrichmentが色々効いてきて困る、みたいな話をよく聞くし自分もそう思うのだけれど、実はenrichmentは結構避けられる(隠蔽できる)のかもと書いていてちょっと思った。  例えばFunctorのfmap methodは fmap: (Functor F) =&amp;gt; (A -&amp;gt; B) -&amp;gt; FA -&amp;gt; FB という形で書かれる。 これはHaskからHask(の適当なsubcategory)へのfunctorのfmapの型になっているが、圏論的には実際は次のような形をしているはずである: fmap: Hask(A,B) -&amp;gt; Hask(FA,FB) .</description>
      </item>
    
      <item>
        <title>2017年振り返り</title>
        <link>https://myuon.github.io/posts/end-of-2017/</link>
        <pubDate>Sun, 31 Dec 2017 20:24:14 +0900</pubDate>
        <guid>https://myuon.github.io/posts/end-of-2017/</guid>
        <description>2017年が終わりそうなので(去年の記事)。 アウトプット  プログラミング&amp;amp;定理証明   github見たら意外と色々やってた。 古い順に    DOTO: todoリストをアレするwebアプリ。これは就活用に作ったような気がする。TypescriptとReactを使ってやっぱクライアントサイドはつらいって思った記憶。今ならElmとかで作ると思う。    CatQ: Coqによる圏論の形式化。Setoidベースでやったけど、圏論側で仮定したくなる公理の妥当性がCoqの上でも妥当なのかとかが無限に気になりやっぱ真面目にやるなら依存型使うのはダメだなと悟って放棄。    dan: やったことリストを登録してgithubの草みたいに表示したりするやつ。最近使ってない    bwitterkuchen: CUI Twitterクライアント。nyantreamを作ることにしたのでメンテはしてないけどしばらく使ってた。    avix: AviUtlという動画編集ソフトのexoファイルを生成するためのHaskellライブラリ。動画編集のときに使おうと思って作ってから一度も使ってない。    sdlight/widx: sdlightはSDLのラッパーライブラリ(ゲームを作ろうとしてついでに作った)。widxはsdlightからwidgetだけを切り離してインターフェイスだけ提供するライブラリ、だったけどBackpackのバグが直らないので開発ができない状態になってる。    nott: Type Theoryに関するまとめノート的なものを置くところ(プログラミング関係ない)。今のバタバタが終わったらまた再開したい。    typed: 型付きラムダ計算の実装(TaPLみながら)と定理証明を雑に投げ込む場所。    claire: LKベースのproof assistant。今年の一人アドベントカレンダーでやったやつ。    myuon.github.io: このブログ。今年入ってからはてなブログからgithub pagesでホスティングすることにし、今はhugoを使うのに落ち着いてる。    nyantream: CUIストリームクライアント(絶賛開発中)。時報/Twitter/Gmail/Slackに対応。GUI版も作りたい。    あと開発中のゲーム(最近開発してないけど)もあった。sdlight/widxが真面目に動くようになれば再開したいけどどうだろう。 絵   自分の中で二次創作という行為への折り合いが付き、二次創作を行えるようになったおかげか特に10月以降はかなり積極的に絵を描くようになった。 多分今年が一番絵が上手くなった(画力向上よりも魅せ方・道具の使い方的な意味で)1年だった気がする。  あとブログ漁ってたら今年の初めに新しいペンタブを買ったようなのでそのおかげもかなりある。 というか、今までラップトップしか持ってなかったのをデスクトップPCを買うのに合わせて21.</description>
      </item>
    
      <item>
        <title>一人CSアドベントカレンダー・最終回</title>
        <link>https://myuon.github.io/posts/2017-csadv-finish/</link>
        <pubDate>Mon, 25 Dec 2017 00:11:02 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017-csadv-finish/</guid>
        <description>  これは一人Computer Scienceアドベントカレンダー 25日目の記事です。 くぅ疲   くぅ〜疲れましたw これにて完結です！  実は、一人アドベントカレンダーを一度くらいやってみたいなと思ったのが始まりでした  本当は話のネタなかったのですが←  ご厚意を無駄にするわけには行かないので自分の中の流行りのネタで挑んでみた所存ですw  以下、各テーマ達のみんなへのメッセジをどぞ(ここだけ原作無視)    Isabelle基礎編(チュートリアル): 初心者に伝わる内容になってたらいいですね prog-prove読んでたら完全に知らないことが書いてあったりしたのでみなさん読みましょうね    Isabelle実践編(IMP): IMPはネタとしては面白いんだけどbig-stepのdeterministicくらいだと内容的には面白みにかけるなという感想    Isabelle応用編(ラムダ計算): SNまで示せたらドヤ顔できたんだけどね(CRも割としんどいけど)    Haskell小ネタ: 本当に小ネタだった Isabelle編が当初の予定より長引いたせいで日数的には全然必要なかった    Proof Assistant理論編: まとまりのない文章になった感すごい(いつものことや)    Proof Assistant実践編: 実装はまぁ別にそんな面白いものでもないなって解説書いてて思った   感想   さて完走した感想(爆笑)ですが、まぁ事前に準備しとくのは大事だねと思いました。 今回はIsabelleの途中までは記事かきためてましたが、結局最後は前日の23時から描き始めるみたいなのが普通だったので書き溜めは大事だなみたいな。  それでも1日も落とさなかった(常に当日0時半までには投稿してた気がする)のはめっちゃ偉いと思います。  あと今年のAdCにもいくつかお誘いを頂いていたんですがまぁこっちがあったのとこっちの記事はシリーズものばかりだったので登録は見送りました。  来年は……ネタがあれば何か書きたいなと思います。一人アドベントカレンダーはしばらく大丈夫です。 おわりに   こんな記事読む人いるんかってずっと思いながら書いてましたがもし読んでくれる人がいたならありがとうございました。  本当の本当に終わり1 1  ってなんで俺くんが！？のところをやろうとしたら精神が持たなかったって言ったら「くぅ疲をやる覚悟が足りない」って言われました。そのとおりだと思います。     </description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・発展編 その7</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-7/</link>
        <pubDate>Sun, 24 Dec 2017 00:04:51 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-7/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 24日目の記事です。   Proof Assistant 「Claire」の実装の説明は前回までで終わったので、よりProof Assistantとして発展させていくには、という話をします。 実装すべき機能など  prover   さていきなりめちゃくちゃ重い話ですが、今回はproverを実装しませんでしたがこれは是非とも欲しい機能ではあります。  Isabelleでは色々なproverが提供されていますが、First-order logicのproverの実装は色々なやり方が知られているようなので(※やったことないのでよく知らない)実装できるとよさそうです。 unifier   一旦示した定理は、自由変数を全部メタ変数に変えてから環境に追加されます。 この定理を後から使う場合はこのメタ変数に何か適当なものを代入する必要があり、今回のClaireの実装ではこれは全てユーザーが決定する必要がありました。  各変数ごとに代入を行うのではなく適当な論理式を与えるとそれとunifyしたものを返すような感じにしてくれるコマンドを例えば追加すると多分便利です。  あくまで一例ですが、 goal: |- P(a) /\ P(b) ==&amp;gt; P(a) かつ thm: ?X /\ ?Y ==&amp;gt; ?Z のとき、 このゴールを解消する exact thm を use thm; unify; assumption みたいに定義できるとよさそうです。 HOLの実装   大変なだけです。技術的な難しさは特に無いです(IsabelleのHOLとか参考にするといいかも)。  ところで、Claireには組み込みのequalityがないので、equalityはそれ用のpredicateを後から定義して、公理(reflexivitiyとsubst rule)を追加して使うことになります。  それに関連するrefl, substなどのコマンドを定義しておくと便利です。 マクロ記述言語   前回も説明しましたがhintでGHCをインタープリターとして使うのは起動に時間がかかりすぎるので、まともな言語を定義したほうが便利でしょう。 Isabelleとの関連   ここは実装に関わる話ではないのですが、IsabelleとClaireを比較していくつか気がついたことがあるので紹介しておきます。 prop?</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・マクロ編 その6</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-6/</link>
        <pubDate>Sat, 23 Dec 2017 00:04:55 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-6/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 23日目の記事です。   Proof Assistant 「Claire」の実装について説明していきます。  リポジトリはこちら: myuon/claire  今回はClaireのマクロ機能について説明します。 マクロ記述言語   Proof Assistantでは、コマンドが組み込みのものしか使えないと何かと不便なので(特にライブラリで定義されたデータに対する便利コマンドなんかは組み込みようがないので)、コマンドを定義するためのマクロ記述ができるようにするのが普通です。  Coqでは専用の言語としてLtacがあります。IsabelleではSMLが(直接？この辺よく知らないけど実装側からインタープリター呼ぶみたいなことしてるのだろうか)呼べます。  Claireにもそういう機能を乗っけたいわけですが、言語を新たに定義するのは面倒なのでHaskellで書いたものを直接インタープリターを呼ぶことにします。  マクロはCommandを定義するものと、Declを定義するものと(これはまぁ今回の話とはちょっと違うのですが、あったほうが便利なので用意しておきました)あります。 マクロの実装   マクロ自体は、適当な引数を受け取ってCommand, Declの列を返すような関数です。これはClaire言語やその証明の構文木を返しているわけです。 マクロ定義モジュール   定義は適当なHaskellのモジュールとして記述します。 export_command, export_declに定義したマクロを列挙します。 module Commands where import Claire macro :: Env -&amp;gt; Argument -&amp;gt; [Judgement] -&amp;gt; [Command] macro = ... export_command :: [(String, Env -&amp;gt; Argument -&amp;gt; [Judgement] -&amp;gt; [Command])] export_command = [ (&amp;#34;name&amp;#34;, macro) ] declmacro :: [Argument] -&amp;gt; [Decl] declmacro = .</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その5</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-5/</link>
        <pubDate>Fri, 22 Dec 2017 00:02:50 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-5/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 22日目の記事です。   Proof Assistant 「Claire」の実装について説明していきます。  リポジトリはこちら: myuon/claire  機能まででproofcheckerのコア機能については説明しました。 今日は雑にtype systemの話をして、Claireを実際に動かして証明を書いてみます。 Environment   proofcheckerは環境とよばれる状態をもっていて、ここに証明した定理などを格納しています。 説明していませんでしたが一応紹介しておきます。  Claire.Env data Env = Env { thms :: M.Map ThmIndex Formula , types :: M.Map Ident Type , proof :: [(Command, String)] , newcommands :: M.Map Ident (Env -&amp;gt; Argument -&amp;gt; [Judgement] -&amp;gt; [Command]) , newdecls :: M.Map Ident ([Argument] -&amp;gt; [Decl]) }   上から順に、「すでに示した定理」「宣言された型つきの項」「直前の定理の証明」「マクロで定義されたコマンド」「マクロで定義された宣言」です。  また、実は定理を示した時に(ThmD節による命題の宣言と証明がcheckされ、環境に定理を追加する時に)定理の自由変数をメタ変数としてgeneralizeする機構が挟んであります(Isabelleでもやっています)。  具体的には、 theorem id: a ==&amp;gt; a proof .</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その4</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-4/</link>
        <pubDate>Thu, 21 Dec 2017 00:20:35 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-4/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 21日目の記事です。   Proof Assistant 「Claire」の実装について説明していきます。  リポジトリはこちら: myuon/claire  昨日に引き続いてClaireの宣言(Decl)について説明していきます。 Declarations   まずはtoplevelMの定義から。 toplevelM :: (Monad m, MonadIO m) =&amp;gt; Coroutine DeclSuspender (StateT Env m) () toplevelM = forever $ do let typecheck fml u k = do { env &amp;lt;- lift get; utyp &amp;lt;- liftIO $ try $ infer env fml; case utyp of Left err -&amp;gt; suspend $ DeclError &amp;#34;typecheck&amp;#34; (toException $ TypeError fml err) (return ()) Right typ | u == typ -&amp;gt; k Right typ -&amp;gt; suspend $ DeclError &amp;#34;typecheck&amp;#34; (toException $ TypeError fml (toException $ UnificationFailed u typ)) (return ()) } decl &amp;lt;- suspend (DeclAwait return) env &amp;lt;- lift get case decl of ここに実装を書く   Claireは実は(貧弱ながら)型システムを備えていて、型チェックを一応行います。 とりあえずそれは今はおいておいて、toplevelMはDeclを受け取って実行するのを繰り返すだけの単純なステートマシンです。 ThmD thmindex formula proof   定理と証明を宣言します。 ThmD idx fml (Proof coms) -&amp;gt; typecheck fml Prop $ do lift $ modify $ \env -&amp;gt; env { proof = [] } runThmD idx fml coms where runThmD :: (Monad m, MonadIO m) =&amp;gt; ThmIndex -&amp;gt; Formula -&amp;gt; [Command] -&amp;gt; Coroutine DeclSuspender (StateT Env m) () runThmD idx fml coms = do env &amp;lt;- lift get go (commandM env) (newGoal fml) coms lift $ modify $ insertThm idx fml where go :: (Monad m) =&amp;gt; Coroutine ComSuspender (StateT [Judgement] m) () -&amp;gt; [Judgement] -&amp;gt; [Command] -&amp;gt; Coroutine DeclSuspender (StateT Env m) () go machine js coms = do env &amp;lt;- lift get (result,js&amp;#39;) &amp;lt;- lift $ lift $ runStateT (resume machine) js case result of Right () -&amp;gt; return () Left (ComAwait cont) -&amp;gt; do case coms of [] -&amp;gt; do com&amp;#39; &amp;lt;- suspend $ ProofNotFinished js&amp;#39; return go (suspend $ ComAwait cont) js&amp;#39; [com&amp;#39;] (c:cs) -&amp;gt; do go (cont c) js&amp;#39; cs Left (z@(CommandError idt err cont)) -&amp;gt; do suspend $ RunCommandError idt err (return ()) go cont js coms   ThmDは中でcommandMを走らせ、その結果によって挙動を決めます。  commandMが問題なく終了した時(=与えられたProofが与えられた命題の証明を完成させた時)、示した論理式を環境に追加して終了します。 commandMがコマンドを要求するComAwaitで終了したとき、toplevelM全体をProofNotFinishedという証明が完了していないことを表すsuspenderでsuspendします。 commandMがエラーになった時toplevelM全体をRunCommandErrorで返します。  syntaxは次のような感じです。 theorem hoge: a ==&amp;gt; a proof apply ImpR apply I qed  AxiomD thmindex formula   公理として指定された論理式を追加します。 AxiomD idx fml -&amp;gt; typecheck fml Prop $ do lift $ modify $ insertThm idx fml   環境に定理として追加するだけ。 ImportD path   他の証明ファイルをインポートします。 ImportD path -&amp;gt; do env &amp;lt;- lift get env&amp;#39; &amp;lt;- liftIO $ claire env .</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その3</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-3/</link>
        <pubDate>Wed, 20 Dec 2017 00:12:26 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-3/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 20日目の記事です。   Proof Assistant 「Claire」の実装について説明していきます。  リポジトリはこちら: myuon/claire Proofchecker state machine   さてClaireのproofcheckerを作っていきます。  前回にもちょこっと話しましたが、proofcheckerをステートマシンとして捉えます。 これは、インタラクティブシェルを実装しなければいけない関係で、proofcheckerを1ステップずつ(証明ファイル1行ずつ)進むという処理をさせたいからです。 proof state   初めに仕様を固めます。   (state:toplevel)    Declを読む; Theoremが来たらstate:commandに移行; 全ての入力を消費するか途中でエラーになったら停止する   (state:command)    Comを読む; 途中で失敗したらエラーを吐いてstate:toplevelに戻る    注意が必要なのは、state:commandでエラーが出たら、state:toplevelに戻ってエラーが出るところです。 このエラーというのはcheckerを走らせるときは普通のなんでもよいですが、インタラクティブシェルの場合はユーザーにエラー内容を表示しつつ再入力を促す必要があるのであとでcatchする必要があることも念頭に置いておきます。 Coroutine monad   さてこういうステートマシンを作りたいときはどうするのがいいでしょうか？ 察しの良い方ならわかるとおりこのアドベントカレンダー14日目の記事 Coroutineモナドとステートマシン でも説明したとおり、Coroutine monadを使います1。  Claire.Checker Command Machine Suspender   簡単な方から行きます。 data ComSuspender y = ComAwait (Command -&amp;gt; y) | CommandError Ident SomeException y deriving (Functor) commandM :: (Monad m, MonadIO m) =&amp;gt; Env -&amp;gt; Coroutine ComSuspender (StateT [Judgement] m) () commandM = .</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その2</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-2/</link>
        <pubDate>Tue, 19 Dec 2017 00:00:24 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 19日目の記事です。   Proof Assistant 「Claire」の実装について説明していきます。  リポジトリはこちら: myuon/claire LK proofchecker  ルールの適用   LKのproofcheckerを作ります。これは、LKのルールの列を受け取って、それを現在のJudgementに適用した結果を返すような関数です。  例として次のルールを考えます。 Γ,A |- Δ ----------- (AndL1) Γ,A∧B |- Δ   このようなルールは下から上に向かって適用します。ので、 Γ,A∧B |- Δ のJudgementを Γ,A |- Δ に変換します。  LKのルールはほとんどintro ruleなのでルールの名前を指定するだけでいいのですが、例えば次のルールCutは新たな(ゴールには出現しない)論理式Aを導入するので、これもルールに合わせて指定する必要があります。 Γ |- Δ,A A,Γ |- Δ -------------------- (Cut) Γ |- Δ   このようなことを鑑みて、前回も説明したとおりLKのRule型は次のような定義にしていました。 data Rule = I | Cut Formula -- CutはFormulaを引数に取る ...  チェッカー   Claire.</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その1</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-1/</link>
        <pubDate>Mon, 18 Dec 2017 00:01:47 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 18日目の記事です。   Proof Assistant 「Claire」の実装について説明していきます。  リポジトリはこちら: myuon/claire Syntax: FOL, LK, Claire   初めにSyntaxの定義をしてからパーサーを用意します。 これがないと何も出来ないので。 FOL   Claire.Syntax.FOL data Term = Var Ident | Abs [Ident] Term | App Term [Term] deriving (Eq, Show) data Formula = Pred Ident [Term] | Top | Bottom | Formula :/\: Formula | Formula :\/: Formula | Formula :==&amp;gt;: Formula | Forall Ident Formula | Exist Ident Formula deriving (Eq, Show)   それぞれfirst-order logicの項と論理式の定義です。  項は変数記号であるか関数記号に項を適用したもの、なのですがどうせ関数への代入操作とかするときにラムダ抽象みたいなのが必要になるので最初から割り切ってラムダ計算にしています。 論理式は命題記号に項を適用したもの、あるいはいくつかの論理結合子からなります。  さていきなり大切な話をしますが、これを見てもらうと分かる通りFormulaの方は定義がすでに決まっていて、後から新たな命題結合子を定義することはできません。 例えばiffの記号を fml1 :&amp;lt;==&amp;gt;: fml2 = (fml1 :==&amp;gt;: fml2) :/\: (fml2 :==&amp;gt;: fml1) と定義したいところですがそれは上の定義だと出来ません。 :&amp;lt;==&amp;gt;: をエイリアスとして定め、ユーザーがこの記号を入力したら全て本来の定義を展開したものに差し替えるみたいな方法もありですが、それだとやはり不便なこともあります。  そもそもこのFormulaはProof Assistantのメタロジックを表すもので、Proof Assistantにおいてメタロジックが正しい(おかしなことがおこらない)ことは絶対に必要なことですがこのことはProof Assistantによって直接検証することは出来ません。 Proof Assistantはメタロジックを用いて現在考えているロジックの上で証明を書く道具なので、メタロジックとしてのFormulaを変えるような操作はしてはいけません。  これがわざわざIsabelleやこのClaireでも標準ライブラリでロジックを再定義する理由で、このメタロジックとロジックの区別は今後も大変重要になるので覚えておいてください。 LK   Claire.</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・理論編 その2</title>
        <link>https://myuon.github.io/posts/proof-assistant-theory-2/</link>
        <pubDate>Sun, 17 Dec 2017 00:17:12 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-theory-2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 17日目の記事です。   昨日に引き続き、Proof Assistantを作る話をしていきます。  今日は実際にこの後作っていくProof Assistant固有の話をしていきます。 Claire言語とその設計   唐突ですがこれから作るProof Assistantを「Claire1」と呼ぶことにします。  リポジトリ: myuon/claire  Claireは実際には複数の言語の組み合わせでできています:    FOL: Pure logicとしてはfirst-order logicを採用します。    LK: Proof SystemとしてはLK(Sequent Calculus)を採用します    Claire: Proof Assistant Claireの証明記述用の言語の名前です    コマンド記述言語(コマンド定義マクロ): コマンド記述言語はコマンド名からLKの規則の列を生成するものです。今回はHaskellで記述できるようにします。    HOLライブラリ: Isabelleと同じく、HOLをライブラリとして実装することが出来ます。することができるというだけでかなり大変なのでしませんが。 LKについて     Proof Systemとして、Sequent Calculus LKを採用します。定義はwikipediaのページでも見るといいんじゃないでしょうか。  The system LK - Wikipedia  今回LKを採用した理由として、natural deductionに比べると推論規則を適用した時のゴールの変形の選択肢が少ない(規則を適用する時に必要な情報が少ない)ことがあります。 というか、natural deductionは命題変数の数を減らすelimination ruleを多く含みますがelimination ruleはゴールに対して適用する、つまり下から上に読むと新たな変数を導入することになるので曖昧さが出やすいです。  それに比べるとSequent Calculusは(仮定とゴールを上手く用意することで)ruleが基本的にintro ruleばかりなので曖昧さが出にくいので、コマンドを適用して証明を書くのには便利かなと思って採用しました。  あとLK触れたことないのでちょっと触ってみたかった的なアレもあります(こっちの理由のほうが大きいかもしれない)。  LKについてそこまで説明をするつもりはありませんが、次のようなことをおさえておいてください。    judgementは Pn,P(n-1).</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・理論編 その1</title>
        <link>https://myuon.github.io/posts/proof-assistant-theory-1/</link>
        <pubDate>Sat, 16 Dec 2017 00:04:42 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-theory-1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 16日目の記事です。   さてCSアドベントカレンダーも後半戦ということで、Proof Assistantを作ります。  Proof Assistantを作ったことがある人は少ないと思うのでまずどういう風に言語を設計していくかという話をしてから、今回実際に作る言語の説明に入ります。 Proof Assistantとは   Proof Assistantは大体次のいずれかの方式をとるものが多いです。    適当なロジックの適当な公理系の証明を解釈するもの: 数学がやっている証明の形式化をそのままやるやり方です。IsabelleやHOLなど。    Curry-Howard対応を用いるもの: 要は型付きラムダ計算を直接実装するやり方です。CoqやAgdaなど。    どっちでも構いませんがどっちを選ぶかによって実装は割と変わってきます。今回はIsabelleと同じく前者の方法をとります。  ところで、Proof Assistant(言語)には大きく分けると次の2種類の言語を持ちます。    命題記述言語: これは命題を記述する言語というだけでなく、Proof Assistantに組み込まれているロジックそのものを表現するために必要な言語でもあります。    証明記述言語: 証明を記述するためには専用の言語が必要な場合があります。ラムダ計算を直接実装する場合はラムダ項そのものでも別に構いません(Agdaみたいな)が、証明を記述するためにメタ言語を載せている言語も(Coqとか)あります。あるいはproverを実装するならこの言語から呼び出せるようにします。    Isabelleの場合は、前者がPure logicと呼ばれるロジックで、後者はIsarが該当します。 証明の記述について   証明の記述にはいくつかのやり方があります。ラムダ計算を実装する場合はラムダ項を直接書くようにするのが楽ですが、公理系を実装する場合は真面目に作る必要があります。  雰囲気としては、次のような操作で記述できるとよさそうです。 (インタラクティブに書けるならこんな感じという気持ちですが、普通にファイルに記述してチェッカーを走らせる場合も裏ではこういう感じになっています)    Proof Assistantを起動する    証明したい命題を入力 (例: a -&amp;gt; a)    現在のゴールが a -&amp;gt; a になる    証明を記述する (例: \x.</description>
      </item>
    
      <item>
        <title>Haskellプロジェクトを始めるにあたって</title>
        <link>https://myuon.github.io/posts/haskell-project-setup/</link>
        <pubDate>Fri, 15 Dec 2017 00:04:21 +0900</pubDate>
        <guid>https://myuon.github.io/posts/haskell-project-setup/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 15日目の記事です。   Computer Science何も関係ないけど大丈夫か？(まぁ一応Haskellはテーマの1つであったというアレはあるけど)  今回はHaskellで開発を始める時にいつもやってるセットアップの作業とかの説明をします。 どうも、Haskellerによるstackみたいな周辺ツールの情報の発信が足りてないんじゃないかみたいな噂が流れてきたのでじゃあまぁなんか記事にするかという流れです。  ところでstackの説明はググれば日本語の記事がそれなりにヒットするようになったと思うのでここではあんまり説明しません。 開発環境構築   このセクションは初回のみです。 Haskellのインストール   stackはプロジェクトを管理するツールっていうのかな？まぁビルドツールになったりパッケージマネージャーになったりghcを管理するのに使ったりなんかまぁそういうツールです(なんて言えばいいんだろう)。  linux系なら公式ドキュメントを見ながら次のようにするといいと思います。 $ curl -sSL https://get.haskellstack.org/ | sh # stackのinstall $ stack setup # GHC(コンパイラ)を入れる   stackを入れてから stack setup でコンパイラが入るのでのんびり待ちます。 ~/.local/bin/ にパスを通しておきます。 エディタ     emacsの人: intero    spacemacsの人: haskell layer    IntelliJ IDEAの人: intellij-haskell    を使いましょう。その他のエディタは知らない(emacs/intellijのプラグインが特に優秀みたいなので可能ならどっちかを使うのがいいんじゃないでしょうか)。 プロジェクトセットアップ  stack new   [2017/12/16追記]  どうやらstackのデフォルトテンプレートであるnew-templateがいつの間にやらhpackを使うように変わったようです。なので、以下のsimple-hpackは不要で普通に stack new [プロジェクトの名前] とすれば同じものが得られます1。 configuration   stack newが終わると必要なファイル群と stack.</description>
      </item>
    
      <item>
        <title>Coroutineモナドとステートマシン</title>
        <link>https://myuon.github.io/posts/coroutine-monad-as-state-machine/</link>
        <pubDate>Thu, 14 Dec 2017 00:03:01 +0900</pubDate>
        <guid>https://myuon.github.io/posts/coroutine-monad-as-state-machine/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 14日目の記事です。   今回は小ネタです。  monad-coroutineというライブラリを使って状態遷移してそうなプログラムを書こうみたいな話をします。 Coroutine-monad  example: coroutine   名前の通りmonad-coroutineはコルーチン(つまりプログラムを一旦停止して値を返し、再び停止したところから再開できるような仕組み)を提供します。  サンプルとしては次のような感じ: countup :: Coroutine (Yield Int) IO () countup = do lift $ print &amp;#34;counting...&amp;#34; yield 1 lift $ print &amp;#34;counting...&amp;#34; yield 2 return () printProduce :: Show x =&amp;gt; Coroutine (Yield x) IO r -&amp;gt; IO r printProduce producer = pogoStick (\(Yield x cont) -&amp;gt; lift (print x) &amp;gt;&amp;gt; cont) producer {-&amp;gt; printProduce countup counting.</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その4</title>
        <link>https://myuon.github.io/posts/nominal-lambda-4/</link>
        <pubDate>Wed, 13 Dec 2017 00:04:03 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-4/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 13日目の記事です。   さて、前回はChurch-Rosserを示しました。今回は型付きラムダ計算もやっとかないとだめかなと思ったのでsimply-typedのtype soundnessです。 流石にラムダ計算の話題ばっかりで疲れてきたと思いますが今回は1日ですべて終わらせます。  まぁCRに比べればずっと簡単なのでいけるでしょ(適当)  今回解説するコードは以下にあります:  myuon:typed/theory/Simply.thy Simply-typed  nominal_datatype simply = TVar string | TArr simply simply (infixr &amp;#34;→&amp;#34; 90)   simply-typedな型はtype variableとfunction typeからなる。 typeの定義自体は特にbinderを含まないが、後に型を含むnominal_inductiveの宣言をしたりする都合上nominal_datatypeにしてある。 valid context   さて型付けに必要になるcontext(変数とその型を組にしたもの)は同じ変数を複数含んではいけないという制約があるので、それを表すvalidという述語を定義する。 inductive valid :: &amp;#34;(name × simply) list ⇒ bool&amp;#34; where valid_nil: &amp;#34;valid []&amp;#34; | valid_cons: &amp;#34;⟦ valid Γ; x ♯ Γ ⟧ ⟹ valid ((x,T)#Γ)&amp;#34; equivariance valid lemma elim_valid_cons: &amp;#34;valid ((x,T)#Γ) ⟹ valid Γ ∧ x ♯ Γ&amp;#34; by (cases rule: valid.</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その3</title>
        <link>https://myuon.github.io/posts/nominal-lambda-3/</link>
        <pubDate>Tue, 12 Dec 2017 00:05:37 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-3/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 12日目の記事です。   前回はCRの証明の途中までやったので続きです。 内容多めですが今回で頑張って終わらせます。 confluenceへ (cont.)  coherent lemmas   parallel betaのcoherent lemmaを示す。 証明は基本的に場合分けやるだけなので省略するとして、まぁ常識的なことが成り立つよねという補題である。(説明の放棄) lemma elim_pb_var: &amp;#34;Var x ⇒β N ⟹ N = Var x&amp;#34; lemma elim_pb_abs: assumes &amp;#34;lam [x]. M ⇒β N&amp;#39;&amp;#34; &amp;#34;x ♯ N&amp;#39;&amp;#34; obtains N where &amp;#34;M ⇒β N&amp;#34; &amp;#34;N&amp;#39; = lam [x]. N&amp;#34; lemma elim_pb_app: assumes &amp;#34;M1 $ M2 ⇒β N&amp;#34; obtains N1 N2 where &amp;#34;N = N1 $ N2&amp;#34; &amp;#34;M1 ⇒β N1&amp;#34; &amp;#34;M2 ⇒β N2&amp;#34; | x P P&amp;#39; L where &amp;#34;M1 = lam[x].</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その2</title>
        <link>https://myuon.github.io/posts/nominal-lambda-2/</link>
        <pubDate>Mon, 11 Dec 2017 00:13:11 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 11日目の記事です。   前回はNominal Isabelleの説明と証明を少しだけしました。 今回から徐々に証明したいことの内容(ラムダ計算そのもの)の話もしていきます。 equivarianceとnominal_inductive  補題   さて2つの補題を示しておく。 lemma subst_eqvt[eqvt]: fixes π :: &amp;#34;var prm&amp;#34; shows &amp;#34;π∙(t[x ::= s]) = (π∙t)[(π∙x) ::= (π∙s)]&amp;#34; apply (nominal_induct t avoiding: x s rule: strong_induct) apply (simp add: perm_bij) apply (simp) apply (simp add: fresh_bij) done lemma subst_rename: assumes &amp;#34;x ♯ t&amp;#34; shows &amp;#34;([(x,y)]∙t) [x ::= s] = t [y ::= s]&amp;#34; using assms apply (nominal_induct t avoiding: x y s rule: lambda.</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その1</title>
        <link>https://myuon.github.io/posts/nominal-lambda-1/</link>
        <pubDate>Sun, 10 Dec 2017 00:13:17 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 10日目の記事です。   前回、4日分に分けてIMPのoperational semanticsの証明の解説をしてみました。 今回はより発展的な話題として、Nominal Isabelleを用いてChurch-Rosser性やSimply-typedのsoundnessなどを示してみようと思います。  定理証明に詳しい人ならもうこれだけでつらさが伝わるかと思うのですが、実際証明はかなり大変なので今回は発展編(応用編)としてこの話題を選んでみました。  今回解説するコードは以下に置いてあります。  myuon/CR.thy 前置き  ラムダ計算   この記事をわざわざ読む人はラムダ計算についてはある程度知っている人が多いと思うのですが、簡単に説明をしておきます。  ラムダ計算は計算のモデルとなるべく作られた言語で、「関数を作る・作った関数を呼び出す(関数を適用すること)」の2つの操作を基本とします。 ここでの「計算」とは数を与えたら数を返す、のような、電卓で行われるような最も我々がイメージしやすい計算のことです。ラムダ計算ではこの「計算」を、項を別の項に変換するような操作によって実現します。 これは単に 1+2 という項があったらそれを 3 へと変換する、あるいは f(x)=x+2 という項があるときに、 f(10) を 12 へと変換する、そういう操作を計算と呼びますというだけなので難しいことはありません。  さてラムダ計算の項(何がラムダ計算の項かはまだちゃんと説明していないけど)は通常変数の付け替えを同一視します。具体的には f(x)=x と f(y)=y を区別しないのですが、この同値をα同値と呼びます。  ラムダ計算の定理証明で最も厄介なのはこのα同値性の扱いで、というか定理証明による形式化ではそもそも「同一視」とか「同値関係で割る」みたいな操作を扱うのがめちゃくちゃ苦手です。 これは主に、一般に同一視されているかが計算によって判定可能でないこと1と、同一視された項同士の計算はしばしば(人間は気にしないけど)それらの項の変形の構成に依存するからだと個人的には思っています。  はてさて真面目にラムダ計算の形式化をやると地獄をみますが、そんな時にNominal Isabelleが便利なんですよ〜！っていうのがこの導入です。 Nominal Isabelle   Nominal Isabelleは(ラムダ項だけではなく; ラムダ計算みたい題材が最も威力を発揮することは間違いないが)binderを含むデータ型を扱う際に利用すると便利なライブラリである。 binderは [x]. M のような形をしていて、この束縛変数 x の変数名の付け替えを区別しないような項である。  Nominal Isabelleではこの変数の付け替え、「例えば変数 x を y に付け替える」という操作を「置換 (x,y) を作用させる」という操作とみなす、というところからスタートする。 より厳密には次のようなことである: 無限の変数からなる集合 V が与えられている時、 List (V×V) の元を置換と呼ぶ。このとき置換の作用を ∙ でかくことにし、 ((x,y)::xs)∙M := xs∙(Mに出現する自由変数xをyに、yをxに書き換えた項); []∙M := M のようにして定める。  上の変数の書き換えの部分は当然項 M が属するデータ型がどのように定義されているかに依存するが、この辺のあれこれをいい感じにやってくれるのがNominal Isabelleであり、Nominal Isabelleが提供するコマンドだったりするわけである。  また、以下でも登場するが、ある変数 x が項 M (複数ある場合はタプルとかにする)に(自由)出現しない、ということを x♯M で表す。  (余談だが、こういうbinderの変数のつらみというのはほか言語でも当然あるので、例えば(こちらはde Bruijn indexを使った代入規則の自動化に限定されてはいるが)Coqのautosubstというライブラリもあって、同じくラムダ計算の定理証明などに威力を発揮するようだ。) nominal_datatype  はじめに   Nominal IsabelleはHOLのライブラリ群の中に含まれているはずで、 imports &amp;#34;~~/src/HOL/Nominal/Nominal&amp;#34; とかでインポートできる。(~~ でIsabelleがインストールされているパスを表す) ライブラリのコードはNominal theoryそのものがここ、例がここにあるので見ると良いかもしれない。 (例に今回の目標と同じCRを示しているのがあるけれど、(大まかな流れは同じだけど)これは特に見てないので私の証明とは色々違うと思います)  また、チュートリアルというかマニュアルが以下にあるので必要に応じて参照して欲しい。  nominal_datatype_manual.</description>
      </item>
    
      <item>
        <title>IsabelleについてのQ&amp;A</title>
        <link>https://myuon.github.io/posts/isabelle-qanda/</link>
        <pubDate>Sat, 09 Dec 2017 00:03:23 +0900</pubDate>
        <guid>https://myuon.github.io/posts/isabelle-qanda/</guid>
        <description>  これは一人Computer Scienceアドベントカレンダー 9日目の記事です。   さて、Isabelleの入門編・基礎編が終わったところで、お口直しに(？？)Isabelleで証明していると遭遇するかもしれない疑問に答えたりする記事を用意してみました。  というか、私がIsabelleを学ぶ過程で公式のリファレンス以外に困った時に頼れるものがなかったりして大変苦労したのでせめて後の人のために身についたノウハウは記事に還元していきたいという気持ちからこういうコーナーを挟んでみました。 Syntax関係  矢印がいっぱいあるんだけど何     =&amp;gt; : HOLのfunction type constructor    ==&amp;gt; : Pure logicのimplication    --&amp;gt; : HOLのimplication   Pure logicってなんですか   (この辺の話は後半のところでもやる予定なんですが)Isabelleはライブラリのとは別に組み込みのロジックあって、これがPure logicと呼ばれています。 そもそもIsabelleは本来Pure logic上で証明を行うproof assistantなんですが、このPure logicの上に別のlogicを構成することが出来て、それがHOLやZFCです。  なのでHOLの証明は内部的には全てPure logicの証明図に置き換えてcheckされます。 AgdaやCoqなどの言語ではこういうことはしない(組み込みのものをそのまま使う)ので慣れないと不思議に感じるかもしれません。 依存型とかないんですか   ないよ(無慈悲) 知らないキーワード・コマンド・attributeが出てきた/便利なコマンドについて知りたい     isar-ref.pdfのAppendixにquick referenceあるので眺めるとよいかも？   証明関係  Sledgehammerと仲良くなれない   これは慣れもありますが、 (1) goalを優しくする (2) 証明の選び方 の2点がポイントです。  まずsledgehammerは優秀とはいえそれでも人間の「自明」とはかなり感覚が違います。 そもそも人間が自明だと思っていてもformalizeにはたくさん補題が必要だったりするので、出来る限りsledgehammerに与える命題は分かりやすく、すぐ示せそうなものだけにしたほうがいいです。  あと、余分な仮定が多いと探索が失敗しやすいです。goalが複雑なときは示したい命題を補題として切り出したりしたほうがいいこともあります。  それと、どうしても上手くいかないときは命題を見直しましょう。「簡単なはずなのにsledgehammerが答えを返さないぞ？」ってときはそもそも間違っている(goalが成り立たない)ことがあります。  次に、探索に成功し証明が複数出た場合、可能ならば簡単で応答の早い証明を選んだほうがいいです。 気をつけるべきはmetisで、これは現実的な時間では終わらない場合があるので避けられるならmetisを含まないものにするか、またはmetisに与えられた補題で先に使えるものは使ってしまいましょう。  例えば、 by (metis lemmaA lemmaB lemmaC)   の時に、lemmaAが先に適用されてそれ以後使わないことがはっきりしているなら apply (rule lemmaA) by (metis lemmaB lemmC)   としたほうが応答が早くなります。あるいはapplyの後にもう一度sledehammerをかけてもいいでしょう。 自動証明コマンドって使い分けるもの？   ある程度はね。    simp: 式変形のみ    auto: 便利コマンドに見えるけれどこいつは(今注目していないものも含めて)全てのgoalに対して変形を行うので注意が必要, 代わりに失敗しても(完全にゴールが解消できなくても)ある程度変形した形を保ってくれるのでsimp_allの代わりに使える場合もある    fastforce: autoみたいに使えて現在のgoalに対する変形しかしないので便利 代わりに証明完了or失敗(何もしない)で挙動が極端    blast: 体感では汎用的な証明力が強い。代わりにauto/fastforceと違ってsimp add:できないので打つのがめんどくさい    その他: 自動証明コマンドはいろいろあるけど、これ以外はsledgehammerが返した時に大人しく従うくらいで自分から使う必要は多分ない   一々仮定に名前付けるのめんどい   lemmaやtheoremのassumesに現れる仮定や、Isarで名前を付けられる命題は項をスペースで区切って列挙が出来ます。 具体的に、 &amp;#34;A&amp;#34; &amp;#34;B&amp;#34; みたいに横に並べることが出来て、これには一度に名前を付けられるので、 x: &amp;#34;A&amp;#34; &amp;#34;B&amp;#34; とするとx(1)でAを、x(2)でBを参照できます。 定理の検索がしたい   jEditならQueryパネルにダブルクォートで囲って項を渡すとその項を含む定理を検索できます。ここにはパターンを渡すのでワイルドカードとしてアンダーバーも使えます。 name: hoge とかやると定理の名前にhogeを含むものという意味にもなります。 jEditのマーカーつくやつ何？     紫: コマンド評価中。これが数秒同じ所で止まっているならその証明は重いのでやめたほうがいいかもしれない。    赤下線: エラー    青下線: info的な情報を出してくれます。前の定理から即座に示せる場合はsolve_direct、反例が見つかる場合はquickcheckなどがたまに教えてくれます。    オレンジ下線: 警告。パース関係の警告(この項は〜とも〜ともパースできるよみたいなやつ)は無視しないほうがいいです。   その他  (jEditなどがないと)ソースコードが読めない   Isabelleはユニコード文字をタグみたいにして埋め込むのでソースコード自体は直接読むに耐えないのですが、 例えばgithubとかに公開するとかブラウザが使えるならドキュメントを用意しておくのがおすすめです。  詳しくはドキュメントを見てもらうといいんですが、プロジェクトのルートにROOTというファイルを置いて内容書いてコマンド走らせると公式のソースコード表示しているやつみたいな感じでHTMLが生成されます。 ちなみにpdfにも吐けます。 まとめ   こういうのっていざ書こうとしたら意外と思いつかないものですね。 なんか思いついたら追加したりしようかなと思います。 </description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その4</title>
        <link>https://myuon.github.io/posts/2017csadv-day8/</link>
        <pubDate>Fri, 08 Dec 2017 00:01:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day8/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 8日目の記事です。   前回は、big-stepがdeterministicであることを示した。 9. Small-step long reduction   csmallを複数回適用した、ということを表す関係を &amp;lt;_,_&amp;gt; ⟶* &amp;lt;_,_&amp;gt; でかいて、次のように定める。 subsubsection {* small-step long reduction *} inductive csmall_long (&amp;#34;&amp;lt;_,_&amp;gt; ⟶* &amp;lt;_,_&amp;gt;&amp;#34;) where SL_refl: &amp;#34;&amp;lt;c,st&amp;gt; ⟶* &amp;lt;c,st&amp;gt;&amp;#34; | SL_trans1: &amp;#34;⟦ &amp;lt;c,st&amp;gt; ⟶ &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt;; &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt; ⟧ ⟹ &amp;lt;c,st&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt;&amp;#34; lemma SL_trans: &amp;#34;⟦ &amp;lt;c,st&amp;gt; ⟶* &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt;; &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt; ⟧ ⟹ &amp;lt;c,st&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt;&amp;#34; apply (induction arbitrary: c&amp;#39;&amp;#39; st&amp;#39;&amp;#39; rule: csmall_long.induct) apply simp apply (blast intro: SL_trans1) done lemma SL_SeqStep: &amp;#34;&amp;lt;c1,st&amp;gt; ⟶* &amp;lt;c1&amp;#39;,st&amp;#39;&amp;gt; ⟹ &amp;lt;c1;;c2,st&amp;gt; ⟶* &amp;lt;c1&amp;#39;;;c2,st&amp;#39;&amp;gt;&amp;#34; apply (induction arbitrary: c2 rule: csmall_long.</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その3</title>
        <link>https://myuon.github.io/posts/2017csadv-day7/</link>
        <pubDate>Thu, 07 Dec 2017 00:18:10 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day7/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 7日目の記事です。   前回はcommandとcommandの評価を定義した。 6. Coherent lemmas  SKIP  subsection {* Coherent lemmas *} lemma coh_B_Skip: assumes &amp;#34;&amp;lt;SKIP,st&amp;gt; ⇓ st&amp;#39;&amp;#34; shows &amp;#34;st = st&amp;#39;&amp;#34; using cbig.cases [OF assms] by auto   始めの補題はSKIPについてで、 &amp;lt;SKIP,st&amp;gt; ⇓ st&amp;#39; ならば st = st&amp;#39; というものである。 直観的には明らかであろうし、証明も場合分けをするだけで済む。 Ass  lemma coh_B_Ass: assumes &amp;#34;&amp;lt;x ::= a , st&amp;gt; ⇓ st&amp;#39;&amp;#34; shows &amp;#34;st&amp;#39; = st [x ↦ aeval st a]&amp;#34; using cbig.cases [OF assms] by auto   次は変数への代入。これも簡単なので省略。 Seq  lemma coh_B_Seq: assumes &amp;#34;&amp;lt;c1 ;; c2 , st&amp;gt; ⇓ st&amp;#39;&amp;#34; obtains st&amp;#39;&amp;#39; where &amp;#34;&amp;lt;c1 , st&amp;gt; ⇓ st&amp;#39;&amp;#39;&amp;#34; and &amp;#34;&amp;lt;c2 , st&amp;#39;&amp;#39;&amp;gt; ⇓ st&amp;#39;&amp;#34;   &amp;lt;c1 ;; c2,st&amp;gt; ⇓ st&amp;#39; ならば、 c1 を実行すると評価が停止し、さらにその後 c2 を実行すると st&amp;#39; の状態になって評価が停止するということが言えるはずである。 上では後々の便利さのために obtains .</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その2</title>
        <link>https://myuon.github.io/posts/2017csadv-day6/</link>
        <pubDate>Wed, 06 Dec 2017 00:07:53 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day6/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 6日目の記事です。   前回はaexp/bexpとそのevaluationを定めた。 3. Commands   さて次にcommandを定義する。  これはIMPの「命令」や「文」にあたるもので、変数の代入、If文、While文などが用意されている。 section {* Commands *} subsection {* Syntax *} datatype com = CSkip | CAssign id aexp | CSeq com com | CIf bexp com com | CWhile bexp com notation CSkip (&amp;#34;SKIP&amp;#34;) and CAssign (&amp;#34;_ ::= _&amp;#34; [50,50] 90) and CSeq (infixr &amp;#34;;;&amp;#34; 30) and CIf (&amp;#34;IF _ THEN _ ELSE _&amp;#34; 80) and CWhile (&amp;#34;WHILE _ DO _&amp;#34; 90)   comを定義した後、notationによって各コンストラクタをよりそれらしいnotationで記述できるようにしている。 このように定義しておくと、例えば以下のような記述ができるようになる。 WHILE BLeq (AId &amp;#39;&amp;#39;X&amp;#39;&amp;#39;) (ANum 0) DO IF BTrue THEN &amp;#39;&amp;#39;X&amp;#39;&amp;#39; ::= ANum 1 ;; &amp;#39;&amp;#39;Y&amp;#39;&amp;#39; ::= ANum 10 ELSE SKIP  4.</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その1</title>
        <link>https://myuon.github.io/posts/2017csadv-day5/</link>
        <pubDate>Tue, 05 Dec 2017 00:02:29 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day5/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 5日目の記事です。   今回から実際に実践的な証明をしながらIsabelleの解説をしていこうと思います。 そしてこの記事は一人computer scienceアドベントカレンダーなのでCSらしい話題を、ということで、 IMPのoperational semanticsの話でもしようと思います。 IMPについて   IMPとはimperative languageの頭文字を取ったもので、natとboolを基本型にもつ簡単な手続き型言語です。 CSの教科書とかでよく見かけるやつです。 IMPの定義をし、そのevaluationを定めます。  ただし、IMPはチューリング完全なので評価は一般には停止しません。つまりプログラムを「評価」して結果を返すような関数は全域関数にはなりません。 このような評価を表す部分関数(関係)を定め、実際にこれがいい感じの性質をもつことを示していきます。 0. States   IMPの定義を行う前の準備。IMPは変数を扱うことができるので変数名を処理するための型が必要になるのと、プログラムの実行には実際に各変数の値を記録したもの(環境の一種)が必要になるのでそれらを定義する。 section {* States *} type_synonym id = string type_synonym state = &amp;#34;id ⇒ nat&amp;#34; definition empty :: &amp;#34;state&amp;#34; where &amp;#34;empty _ = 0&amp;#34; no_syntax &amp;#34;_maplet&amp;#34; :: &amp;#34;[&amp;#39;a, &amp;#39;a] ⇒ maplet&amp;#34; (&amp;#34;_ /↦/ _&amp;#34;) fun update :: &amp;#34;state ⇒ id ⇒ nat ⇒ state&amp;#34; (&amp;#34;_[_ ↦ _]&amp;#34; [80,80,80] 80) where &amp;#34;update st x n y = (if x = y then n else st y)&amp;#34;   sectionコマンドは証明には影響を与えないが、Sidekickにsectionとして表示されたりLaTeXに出力すると実際に節として扱われたりするもの。chapter, subsectio, subsubsectionなどもある。  さて、 id で変数名を表すことにし、さらに環境を表す state を定めた。 ここでは id として string を、 state としてidを受け取ってnatを返す関数を使うことにした。(変数に格納される値は常にnatである)  Isabelleで文字列リテラルは &amp;#39;&amp;#39;hoge&amp;#39;&amp;#39; と、シングルクオート2つで囲って表現する1。  さてここではupdateというstateを更新する関数を定義しているが、その前になにやらno_syntaxという箇所がある。 これは、update関数を演算子として st [x ↦ n] のように書きたいのだが、この記法がすでにある _maplet という記法と被ってしまうため既存の記法を解除するためのものである。 このように記法が被った場合、すでにある演算子の定義を調べ(jEditならCtrlを押しながらクリックとかで定義箇所に飛べる)、それをno_syntaxやno_notationで解除することができる。 1.</description>
      </item>
    
      <item>
        <title>Isabelle/HOLの基本 その3</title>
        <link>https://myuon.github.io/posts/2017csadv-day4/</link>
        <pubDate>Mon, 04 Dec 2017 00:39:09 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day4/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 4日目の記事です。   テキスト代わりのチュートリアル: prog-prove.pdf  前回はHOLと自動証明についてやりました。 今回やる4章では、Isarという新しい言語(？)について見ていきます。 4. Isar: A Language for Structured Proofs   IsabelleはIsarという、structured proofを記述するための言語を別に提供している。 これはapplyを繋げて証明をするのとは違い、構造化された証明をキーワードを組み合わせて記述する、より自然言語による証明に近い記述を可能にする言語である。  Isarのsyntaxのコアは次のようになっている(実際はもっと膨大): proof = &amp;#39;by&amp;#39; method | &amp;#39;proof&amp;#39; [method] step* &amp;#39;qed&amp;#39; step = &amp;#39;fix&amp;#39; variables | &amp;#39;assume&amp;#39; proposition | [&amp;#39;from&amp;#39; fact+] (&amp;#39;have&amp;#39; | &amp;#39;show&amp;#39;) proposition proof proposition = [name :] &amp;#34;formula&amp;#34;  4.1 Isar by Example   初めにIsarによる証明を見せるので眺めてみよう。 lemma &amp;#34;¬ surj (f :: &amp;#39;a ⇒ &amp;#39;a set)&amp;#34; proof - assume srjf: &amp;#34;surj f&amp;#34; from srjf have fa: &amp;#34;∀A.</description>
      </item>
    
      <item>
        <title>Isabelle/HOLの基本 その2</title>
        <link>https://myuon.github.io/posts/2017csadv-day3/</link>
        <pubDate>Sun, 03 Dec 2017 00:01:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day3/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 3日目の記事です。   テキスト代わりのチュートリアル: prog-prove.pdf  前回は導入と型・関数・証明について学びました。 今回やる3章では、HOLについてと証明を書く際に知っておくと便利なあれこれについてです。 3. Logic and Proof Beyond Equality  3.1 Formulas   HOLのformulaの定義は次: form ::= True | False | term = term | ¬ form | form ∧ form | form ∨ form | form --&amp;gt; form | ∀x. form | ∃x. form   termはラムダ式とifとかcaseとかletとかそのへん 3.2 Sets   &amp;#39;a のsetを &amp;#39;a set とかく。次のようなnotationが定義されている。    {} , {e1,e2,e3}    e ∈ A , A ⊆ B    A ∪ B , A ∩ B , A − B, − A    {x | P}    HOLのsetはかなり便利なので積極的に使っていこう。 3.</description>
      </item>
    
      <item>
        <title>Isabelle/HOLの基本 その1</title>
        <link>https://myuon.github.io/posts/2017csadv-day2/</link>
        <pubDate>Sat, 02 Dec 2017 00:00:44 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 2日目の記事です。  さて今回よりIsabelle/HOL(HOLはライブラリの名前)の基本の解説をしていきます。 一応極基本的なことを最初に少し説明をしてから、あとは実践形式で実際に証明を書きながら細かい機能などの説明をしていく予定です。 説明に割くページ数とコンテンツの内容と時間的な問題で、定理証明とは何かなどは詳しく話しません。 Isabelle資料   Isabelleのお勉強のための資料をまとめておきます。    prog-prove.pdf: 公式チュートリアルの一番基本のやつ。入門するならこれだけは 必ず読みましょう 。チュートリアルは他にもトピックごとに色々あるよ！    isar-ref: 主にIsarに関するReference Manualだけど慣れてきたら参照する機会が多いと思う。    caeruiroさんのIsabelle Tutorialシリーズ: 大変貴重な日本語の入門記事。Isabelle-2009を使っているらしいのでもしかしたら古い記述もあるかもしれない。    Concrete Semantics: Isabelleでプログラミング言語のセマンティクスとかやるテキスト。前半はIsabelle入門、後半はCSのテキストみたいな構成。    AFP: Archive of Formal Proofs; Isabelleで証明されたあれこれが投稿されてる証明集みたいなサイト    Isabelleの入門の入門: 遥か昔に書いた記事; 何かの役には立つかもしれない   このシリーズの目的   prog-prove.pdfを読んでねでチュートリアルを済ませてしまっても良いのですが、まぁ読んでって言って読んでもらった試しがないので もう少し実際に証明を書きながら解説をすることで、英語が読みたくない人や雰囲気だけ知りたい人にも優しい解説シリーズになればいいかなと思っています。 ひとまずこのIsabelle/HOLの基本シリーズでは上のprog-prove.pdfに沿って話を進めていきます。  内容全部やるなら単なる翻訳になってしまうので適度にぶっ飛ばしつつ要所要所を解説していく感じにします。 定理証明全くしたことないと厳しいこともあるかもぐらいでお願いします。 はじめに. jEditについて   現在Isabelleが公式にサポートしているのはjEditのみです1。 jEditを起動し、エディター画面とアウトプットパネルが表示されていれば問題ありません。アウトプットパネルはなければ Plugins&amp;gt;Isabelle から表示させます。  よく使うパネルを一通り説明しておきます。    Documentation: Isabelleは豊富な公式ドキュメントが用意されています。    Sidekick: 現在開いているファイルのアウトライン的なものが表示されます。    State: なんやねんこれ    Theories: 複数のファイルを開いている場合に、各ファイルのどの辺りまでcheckerが走っているかが一覧で表示されたものです。    Output: ここに情報が表示されます。証明は基本的にこのパネルを見ながら書きます。    Query: 既知の定理の検索などを行います。    Sledgehammer: 現在focusしている証明に対してsledgehammer(後述)を実行することができます。    Symbols: unicode symbolを入力するために使います。   1.</description>
      </item>
    
      <item>
        <title>一人CSアドベントカレンダー開催のお知らせ</title>
        <link>https://myuon.github.io/posts/2017csadv-day1/</link>
        <pubDate>Fri, 01 Dec 2017 00:06:00 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day1/</guid>
        <description>  これは一人Computer Scienceアドベントカレンダー 1日目の記事です。 概要的なもの   「一人アドベントカレンダーって面白そうだな、やってみたい」みたいなノリで登録したんですが、 25日毎日記事を同じテーマで投稿し続けるのどう考えてもめっちゃ大変なのでやはりここは自分が一番得意な分野で行くしかないかなとなりCS関係ということになりました。  上のQiitaのページでも書いてますが、キーワードとして&amp;#34;ラムダ計算・定理証明・Haskell・ML・圏論 とかなんかそのへん&amp;#34;を挙げていますので そのへんのお話になります。今のところは無難に定理証明を中心にテーマをいくつか選んでおいたので多分そのへんの話です。 スケジュール   最終的にはQiitaのカレンダー見ればわかることなんでいいんですが一応今後どういう感じで進めていくのかのスケジュール的なものをまとめておきます。 Isabelle編  Isabelle/HOL入門(3-4日くらい)   最初にIsabelle(ここではHOL系しか扱わない)に入門します。って言ってもチュートリアルの解説をするだけです。 ある程度知ってる人が読む意味はないんですが、Isabelle全く知らん人向けに日本語で読める資料ってあんまりなさそうなので、チュートリアルを適当にやるだけでも実は意味があるんでは的な発想でとりあえずこれをやることにしました。  真面目に入門したくて英語にそこまで抵抗ない人は公式のprog-prove.pdf読みに行く方が早いです。 Isabelleでの定理証明・基礎編(3-4日くらい)   ここでは実際にIsabelle/HOLを使った証明を紹介・解説していきます。今の所IMPの意味論ちょろっとやるみたいな感じです。 Isabelleの解説がメインなので内容は薄いですがIsabelleってこうやって使うんだよ〜証明ってこうやって書くんだよ〜って雰囲気が伝わればいいかなと思っています。 (そういうのが伝わる日本語資料もあんまりない気がしたので) Isabelleでの定理証明・実践編(2-3日+2日？くらい)   せっかくなので個人的にこの前お世話になったりしたNominal Isabelle使ってtyped lambda calculusの簡単な証明とかやってみようかなという内容です。 あとかつてIsabelleで圏論(Yoneda lemma示すくらいまで)もやったことあるのでその解説もやってもいいかもしれないということで2日分くらいは余裕を持たせてあります。  この辺は後で変更あるかも知れないのでそのへんはあしからず。 Haskell編  ライブラリ紹介(1日1ライブラリ, 日数未定)   Haskellで最近使ったり使ってなかったりするライブラリの紹介とか解説とかをします。 ここ以外のコンテンツで25日分埋まらなかった場合に備えて空けてある枠なので日数は未定です。 Haskell編の最初にまとめてやるかも不明ですが一応ってことで。 定理証明支援系を作ろう・理論編(2-3日くらい)   ここからがメインコンテンツで、Haskellを使ってproof assistantを作ります。 (最初に断っておくとproverは作りません。あくまでcheckerとそのassistする部分がメインです。)  多分色々前提になる知識を解説したり、proof assistantを作るには何が必要かとかの説明がいると思うのでそのへんを初めに少し解説します。 定理証明支援系を作ろう・実践編(5-7日くらい)   proof assistantを実際に作っていきます。  最初はステップアップで徐々に拡張して行く感じで作ろうと思っていたんですが、特に参考にできるものもなく始めてだったので自分で手を動かして作ってみた所そうそう前に進めるはずもなく backwardな変更が出過ぎてステップアップするのつらすぎたので普通に現在のproof assistantのコードの解説になります。  checkerのコア機能の解説→assist機能関係の解説→プラグイン・拡張部分の解説 の順になります。 定理証明支援系を作ろう・拡張編(1日)   上で作ったものは当然ですがまともに証明を書こうとすると色々足りないので、今後ちゃんとしたassistantにするにはどういう感じの拡張が欲しいかな〜とかそういう話を、 「開発が間に合わなかったものは全部読者への演習問題にしたらええねん」的な思想により丸投げされるコーナーです。 まとめ   最終日は多分まとめと振り返りに使います。  これでだいたい25日分になるはず。 意気込み的な   開催にあたり内容よりも25日にわたってずっとブログを書き続けるのがつらそう という感情しかないんですが まぁせっかくなので楽しんでいこうと思います。  あと無理はよくないのでしんどくなったら細切れにしていこうというのも気をつけていきたい。  というわけで、読んでくれる人は25日の間どうぞお付き合いください。よろしくお願いします。 </description>
      </item>
    
      <item>
        <title>HakyllからHugoに移行した</title>
        <link>https://myuon.github.io/posts/migrate-to-hugo/</link>
        <pubDate>Fri, 10 Nov 2017 02:37:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/migrate-to-hugo/</guid>
        <description> 移行理由   前はHakyll+pandocでorg-modeで書く→htmlに変換してgithub pagesで公開という手順を踏んでいたのだけれど、pandocのorg-mode対応が中途半端すぎて、対応していない記法があったりcode block(こういうの)の中で特殊な記号を使うと上手くパース出来なかったりして色々厳しくなってきていたというのが理由。 困ってたところにhugoというのを教えてもらったのでそれに移行することにした。 手順諸々  導入   hugoをsnapdから入れて使う。テストサイトを作って挙動を確認してから必要なものをsourceブランチに持ってきて導入はおしまい。 各記事はfront matterを少し書きなおすだけ。ありがたいことにorg-modeでかく場合は大体似たような文法なのでちょこっと書き換えるだけで動く。  hugo serve --watch --buildDrafts でドラフトも見れるようにできるので、ドラフト確認してOKならhugoからpublishするというのが正しいフローっぽい。 テーマ   Hakyllの時からテーマは自作していたのでテンプレートのカスタマイズとcssを持ってくるみたいな作業が必要になったのでやった。 hugo new theme [テーマ名] で必要なファイル群が themes にできるのであとは Templates にテンプレートの公式ドキュメントがあるのでそれとかhugoの実際のテンプレートを見てカスタマイズをした。  まぁ変に汎用性とか気にしなければ簡単、だと思う。 コードのsyntax highlight   config.tomlに pygmentscodefences = true pygmentsstyle = &amp;#34;manni&amp;#34;   と書いた。 pygmentscodefencesはmarkdownで ```lang みたいに書けるようにするやつだけど、org-modeのcode blockもありがたいことに対応してくれてたのでそのまま色がついた。  カラースキームはPygmentsの公式サイトから色々試してしっくり来るやつを探すと良さそう。 syntax highlight関係のデザイン   pandocではsyntax highlight用にcssを用意して色を指定していたんだけどそれが不要になった。 それと、pygmentsstyleで色をつけるとpreの背景の色を強制的に指定されてしまうので今までは色をつけてたんだけどそれを外した(文章中のcodeはそのままにしてる)。 TOC   困ったことにorg-modeだとtocが表示されないバグがあるらしく1、調べたらテンプレートだけでTOCを作る方法があったのでそれをパクった。 リストを作ってCSSでheadingに応じて右にずらしているだけだけど。 semantic-uiの読み込み   このブログではsemantic-uiをcssフレームワークとして使っていて、できればそれらのファイルを自分のリポジトリに含めてcommitするのは避けたかったのでsubmoduleで頑張った。 と言っても git submodule add URL directory とかして管理するだけだけど。 公開するときとローカルビルドするときのどちらも必要になるのでどちらもsubmoduleに追加する必要がある。 それと、URLはgit@…じゃなくてhttps:… じゃないとだめらしい。(一度怒られた) hard line breaks   これはやり方がわからない。 orgで書いた時に、パラグラフ中の改行はHTMLで強制改行に(&amp;lt;br&amp;gt; に)してほしい。 #+OPTIONS: \n:t 相当のやつ。markdownは対応しているみたいだけど…。  一度pandocでhard line breaks入れるフィルターを通すとかすると良いのかもしれないけど強引すぎるからやりたくはない。 hugoが対応してくれるのを待つしかないのかな〜。 1  2017-11-10現在。最近報告されたらしいのでそのうち直ると思う。     </description>
      </item>
    
      <item>
        <title>n番煎じのrecursion-scheme</title>
        <link>https://myuon.github.io/posts/recursion-scheme/</link>
        <pubDate>Fri, 27 Oct 2017 00:59:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/recursion-scheme/</guid>
        <description>前提になりそうなことをちょこっとPreliminariesに書いた. Recursion schemes   以下, C は適当な条件を満たすfunctor F: C -&amp;gt; C がFixをもち, さらにそれがCofixにもなっていることを仮定する1. 以下ではこの適当な条件を満たすfunctorしか考えないものとする. catamorphism   F-algebra p: FA -&amp;gt; A に対し, D のinitialityにより得られる射 cata(p): D -&amp;gt; A を catamorphism とよぶ. これは in; cata(p) = fmap F cata(p); p: FD -&amp;gt; A を満たす. anamorphism   catamorphismの双対. F-coalgebra q: A -&amp;gt; FA に対し, D のterminalityにより得られる射 ana(q): A -&amp;gt; D を anamorphism とよぶ. これは q; fmap F ana(q) = ana(q); out を満たす.</description>
      </item>
    
      <item>
        <title>Overlapping Instancesと戦う</title>
        <link>https://myuon.github.io/posts/overlapping-instances/</link>
        <pubDate>Mon, 21 Aug 2017 00:31:03 +0900</pubDate>
        <guid>https://myuon.github.io/posts/overlapping-instances/</guid>
        <description>Overlapping Instances   Haskellで少し凝ったinstanceをいくつか書いたりしているとoverlapping instancesに悩まされることはよくある。 この辺のまとまった解説があると便利なのではと思ったので書く。 ユーザーガイドにて   実際、overlapping instancesが何故起こるのかについてはGHCユーザーガイドにそれなりに詳しく書いてあるのでそこを読めば良いと思う。  GHCユーザーガイド - Overlapping instances  勝手に抄訳すると次のような感じ 9.8.3.6 Overlapping instances    一般に、Instance resolutionで述べたように、 GHCは、型クラス制約を解決するために使用されるinstance宣言が曖昧ではないことを要求する。 GHCは、 最も具体的な形が存在する時に限って 複数のinstanceにマッチすることを許すという方法で、instanceの解決を緩める方法も提供している。さらに、これはもっと緩くすることもできて、最も具体的な形があるかどうかにかかわらず、複数のinstanceにマッチすることを許すこともできる。この節で詳しく述べる。  instanceの選択をコントロールするには、それぞれのinstanceについてオーバーラップしたときの挙動を指定することができる。 instance キーワードの直後に次のいずれかのプラグマを書けば良い: {-# OVERLAPPING #-}, {-# OVERLAPPABLE #-}, {-# OVERLAPS #-} または {-# INCOHERENT #-}   INCOHERENT はinstanceが自由にoverlapしたりされたりすることを許すが、使わないほうがいいプラグマなので出来る限り避けたほうがいい。 また、後にもあるように OVERLAPS は OVERLAPPING と OVERLAPPABLE のいずれにもなるので OVERLAPS で事足りる場合も多いと思う。  また、いちいちプラグマを書かなくてもいいように、デフォルトの挙動を指定するための拡張 -XIncoherentInstances と -XOverlappingInstances も あるけれど使用は出来る限り避けよう。   さて、あるクライアントモジュールで (C ty1 .</description>
      </item>
    
      <item>
        <title>HakyllでBlogを作る</title>
        <link>https://myuon.github.io/posts/hakyll-blog/</link>
        <pubDate>Wed, 16 Aug 2017 22:39:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/hakyll-blog/</guid>
        <description>Hakyllでこのブログを作ったのでそのあれこれを 概要   やりたいことは以下    orgで文章をかく(大事)    orgから良い感じのHTMLを生成し    github pagesで公開   Hakyllのsetup   次を参考にした    Hakyll Tutorials    Hakyll, stack, Travis CI, Github でブログを管理する    GitHub Pages はじめました    hakyll package    stack でパッケージを入れて、 hakyll-init → stack build → stack exec site watch で動かすところまでは簡単にいけた 2番目のリンクにあるように、 _site をsubmoduleに登録しておいて、これをmasterブランチにpushして公開するようにしておく 文書の変換・Hakyllの設定   プロジェクトの構造は次のようになっている - root - _site できたHTMLファイルが置かれる - _cache - css できたCSSファイルが置かれる(圧縮済) - images 画像ファイルが(ry - posts ここにorg or markdownで書いた記事を入れる - site.</description>
      </item>
    
  </channel>
</rss>
