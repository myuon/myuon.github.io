---
title: ãƒãƒ¼ãƒãƒ£ãƒ«ç¾å°‘å¥³å®šç†è¨¼æ˜å£«ã‚’æ”¯ãˆã‚‹æŠ€è¡“
date: 2018-12-25T20:25:54+09:00
---

ã“ã®è¨˜äº‹ã¨ã¯ç‰¹ã«é–¢ä¿‚ãªã„ã®ã§ã™ãŒVTuber Techã‚¢ãƒ‰ãƒ™ãƒ³ãƒˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼([ãã®1](https://qiita.com/advent-calendar/2018/vtuber) [ãã®2](https://qiita.com/advent-calendar/2018/vtuber2))ãŒã‚ã‚‹ã‚‰ã—ã„ã®ã§èˆˆå‘³ãŒã‚ã‚‹äººã¯è¦—ã„ã¦ã¿ã‚‹ã¨ã„ã„ã‚“ã˜ã‚ƒãªã„ã§ã—ã‚‡ã†ã‹ã€‚

ãƒãƒ¼ãƒãƒ£ãƒ«å¼•ãã“ã‚‚ã‚Šç—…å¼±å®šç†è¨¼æ˜å£« å¤•æš®å¯å­ã¨ã„ã†ã®ãŒã„ã¦ã€ãã®å­ã®è£å´ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ãŸã®ã§(ä½œã£ãŸã®ã¯ã ã„ã¶å‰)ãã®è§£èª¬ã‚’ã—ã¾ã™ã€‚ãªãŠå•é¡Œã¯å±±ç©ã¿ã®æ¨¡æ§˜(ãã‚‚ãã‚‚ç§ä»¥å¤–ã®äººãŒä½¿ã†æƒ³å®šã˜ã‚ƒãªã„ã®ã§è‡ªåˆ†ã§ã„ã˜ã‚‹ãªã‚Šãªã‚“ãªã‚Šã—ã¦ãã ã•ã„)ã€‚

æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: Docker, Python, TypeScript, dlib (Python bindings), OpenCVã¡ã‚‡ã“ã£ã¨, Live2D SDK

<blockquote class="twitter-tweet" data-lang="ja"><p lang="ja" dir="ltr">ğŸ’ã¯ã˜ã‚ã¾ã—ã¦ğŸ’<br>ğŸŠå¤•æš®å¯å­ã¨ã„ã„ã¾ã™ğŸŠ<br>ğŸ˜´é›»è„³ç©ºé–“ã§å¼•ãã“ã‚‚ã‚Šã‚’ã‚„ã£ã¦ã„ã¾ã™ğŸ˜´<br>ğŸ’»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¨ã‹è¨¼æ˜ã¨ã‹ã‚’æ›¸ãã¾ã™ğŸ’»<br><br>ğŸ’ªLive2Då‹•ã‹ã™ã‚„ã¤ä½œã£ã¦ã‚‹ã®ã§ãã‚ŒãŒã§ããŸã‚‰ãƒ‡ãƒ“ãƒ¥ãƒ¼ã—ã¾ã™ğŸ’ª<br>ğŸ‘ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ğŸ‘<a href="https://twitter.com/hashtag/Vtuber%E6%BA%96%E5%82%99%E4%B8%AD?src=hash&amp;ref_src=twsrc%5Etfw">#Vtuberæº–å‚™ä¸­</a><a href="https://twitter.com/hashtag/Vtuber%E5%A7%8B%E3%82%81%E3%81%BE%E3%81%97%E3%81%9F?src=hash&amp;ref_src=twsrc%5Etfw">#Vtuberå§‹ã‚ã¾ã—ãŸ</a><a href="https://twitter.com/hashtag/%E6%96%B0%E4%BA%BAVtuber?src=hash&amp;ref_src=twsrc%5Etfw">#æ–°äººVtuber</a><a href="https://twitter.com/hashtag/Vtuber?src=hash&amp;ref_src=twsrc%5Etfw">#Vtuber</a> <a href="https://t.co/UAM9iTrFLU">pic.twitter.com/UAM9iTrFLU</a></p>&mdash; å¤•æš®å¯å­ (@YugureNeko) <a href="https://twitter.com/YugureNeko/status/1021752401865240576?ref_src=twsrc%5Etfw">2018å¹´7æœˆ24æ—¥</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## ãƒªãƒã‚¸ãƒˆãƒª

ã‚³ãƒ¼ãƒ‰ã¯å…¨éƒ¨å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚

[https://github.com/myuon/juniQ](https://github.com/myuon/juniQ)

**å…è²¬äº‹é …**

ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ç¾¤ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§å…¬é–‹ã—ã¦ã„ã¾ã™(ãƒªãƒã‚¸ãƒˆãƒªã«submoduleã¨ã—ã¦å«ã¾ã‚Œã‚‹cubism-jsã«ã¯å½“ãŸã‚Šå‰ã§ã™ãŒã“ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é©ç”¨ã•ã‚Œã¾ã›ã‚“)ã€‚  
ã“ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯Live2D SDK for webã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹åŠã³ãƒ–ãƒ­ã‚°ã«ãŠã‘ã‚‹ã‚³ãƒ¼ãƒ‰ã®è§£èª¬ã¯Live2Dã‹ã‚‰è¨±å¯ã‚’å¾—ã¦è¡Œã£ã¦ã„ã¾ã™ã€‚

ã“ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’åˆ©ç”¨ã—ã¦ä½œã‚‰ã‚ŒãŸã‚‚ã®ã‚’å‡ºç‰ˆ(ã‚³ãƒ¼ãƒ‰ã®ä¸€éƒ¨ã¾ãŸã¯å…¨éƒ¨ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã‚‚å«ã¾ã‚Œã‚‹ã‚ˆã†ã§ã™)ã™ã‚‹å ´åˆã«ã¯Live2Dã¨ã®å¥‘ç´„ãŒå¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚‹ã®ã§ãã®è¾ºã¯ã¡ã‚ƒã‚“ã¨å•ã„åˆã‚ã›ã¦ãã ã•ã„ã€‚

Live2D SDKãƒªãƒªãƒ¼ã‚¹ãƒ©ã‚¤ã‚»ãƒ³ã‚¹: [https://www.live2d.com/ja/products/releaselicense](https://www.live2d.com/ja/products/releaselicense)

([ã“ã‚Œ](https://www.live2d.com/eula/live2d-open-software-license-agreement_jp.html)èª­ã‚€é™ã‚Šã ã¨ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ä¸€éƒ¨ã‚’å…¬é–‹ã™ã‚‹ã ã‘ã§ã‚‚å‡ºç‰ˆã«ã‚ãŸã‚‹ã‹ã‚‚ã¿ãŸã„ãªæ›¸ãæ–¹ã ã£ãŸã‘ã©å•ã„åˆã‚ã›ãŸã‚‰ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹ã ã‘ãªã‚‰å¥‘ç´„ä¸è¦ã£ã¦è¨€ã‚ã‚ŒãŸã®ã§å‰²ã¨Live2Då´ã«åˆ¤æ–­ã®è£é‡ãŒã‚ã‚Šãã†ã§ã™ã€‚ã¾ããªã‚“ã‹ã‚„ã‚ŠãŸããªã£ãŸã‚‰ã¨ã‚Šã‚ãˆãšèã„ã¦ã¿ã‚‹ã®ãŒã‚ˆã•ãã†ãªæ„Ÿã˜ã ã£ãŸã€‚)

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

æ¬¡ã®ã‚ˆã†ãªä»•çµ„ã¿ã§å‹•ãã¾ã™

- ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’å–å¾—ã€websocketã‚µãƒ¼ãƒãƒ¼ã«ç”»åƒã‚’30fpsã§æŠ•ã’ã‚‹
- ã‚µãƒ¼ãƒãƒ¼ãŒç”»åƒã‚’å—ã‘å–ã£ã¦é¡”ã®æ¤œå‡ºç­‰ã‚’è¡Œã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã™ã‚‹
- è¨ˆç®—ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒ–ãƒ©ã‚¦ã‚¶ã®viewerã«å†åº¦æŠ•ã’è¿”ã•ã‚Œã‚‹
- viewerã¯Live2Dãƒ¢ãƒ‡ãƒ«ã‚’æç”»

### ãªã‚“ã§ã‚„ã­ã‚“

ãªã‚“ã‚„ã­ã‚“ã“ã‚Œã¨æ€ã†ã¨æ€ã†ã‚“ã§ã™ãŒã“ã‚Œã¯ãƒ›ã‚¹ãƒˆPCãŒWindowsã§ã‚ã‚ŠWindowsã§é–‹ç™ºã¯ã§ããªã„ã“ã¨ã¨ã€VirtualBoxã§ã¯USBã®æ˜ åƒå‡ºåŠ›ç­‰ã‚’ç›´æ¥å—ã‘å–ã‚Œãªã„ç­‰ã®æŠ€è¡“çš„åˆ¶ç´„ã«ã‚ˆã‚Šæ‚²ã—ãã‚‚å³ã—ã„è¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚

ã‚„ãƒ¼ã¾ã˜å…¨éƒ¨Unityã‹ãªã‚“ã‹ã§ä½œã‚Œã°ã‚ˆã‹ã£ãŸãƒ¼ã£ã¦å¾Œã«ãªã£ã¦å¾Œæ‚”ã—ãŸã‚“ã§ã™ãŒã—ã‹ã—dlibã¨ã‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒUnityã®ã‚¢ã‚»ãƒƒãƒˆã‚¹ãƒˆã‚¢ã ã¨ã¾ã¨ã‚‚ãã†ãªã‚„ã¤ã¯ã™ã”ãé«˜ãã¦ã„ã‚„ã„ã‚„ã¿ãŸã„ãªæ°—æŒã¡ã«ãªã£ãŸã‚Šã—ãŸã®ã¯ã‚ã‚‹ã€‚Unityãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã§é ‘å¼µã£ã¦ä½œã‚Šç›´ã—ãŸã„ã‘ã©ã¤ã‚‰ãã†ã€‚

ã‚ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ç›´æ¥æ˜ åƒã‚’æŠ•ã’ã‚‹ã®ã£ã¦æ„å¤–ã¨é›£ã—ãã¦(browser to browserã ã¨ãã‚Œã£ã½ã„æŠ€è¡“ã¯æ„å¤–ã¨ã‚ã‚‹ã‚“ã ã‘ã©â€¦)ã‚ã‚“ã¾é¸æŠè‚¢ãŒãªã„ã—ã€ãã‚‚ãã‚‚æ¤œå‡ºã¨ã‹ã®é–¢ä¿‚ã§çµ¶å¯¾ç”»åƒã‚’åˆ‡ã‚Šå‡ºã™å¿…è¦ãŒã‚ã‚‹ã®ã§ã¾ããƒ–ãƒ©ã‚¦ã‚¶ã§åˆ‡ã£ã¦é€ã‚Œã°ã„ã„ã‚“ã˜ã‚ƒãªã„ã‹ã¿ãŸã„ã«ãªã£ã¦ãŠã‚‹ã€‚å½“ç„¶ã“ã®å‡¦ç†ã¯å‰²ã¨è² è·ã‹ã‹ã‚‹ã®ã§ã†ã‚“ã¾ãã¿ãŸã„ãªæ„Ÿã˜ã€‚

ã‚ã¨CORSã®è¨­å®šãŒã“ã‚Œã‚’ä½œã£ãŸã¨ãã¯ã‚ˆãã‚ã‹ã£ã¦ãªã‹ã£ãŸã®ã§Firefoxã§ã—ã‹å¤šåˆ†å‹•ã‹ãªã„ã§ã™ã€‚ãã®ã†ã¡Firefoxã§ã‚‚å‹•ã‹ãªããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

## æ˜ åƒå–å¾—éƒ¨åˆ†

æ˜ åƒã¨éŸ³å£°ã‚’å–å¾—ã™ã‚‹ã€‚`getUserMedia`ã¨ã‹ã‚’ä½¿ã†ã¨ã§ãã‚‹ã€‚æ˜ åƒã¯30fpsãã‚‰ã„ã«è½ã¨ã—ã¦websocketã‚µãƒ¼ãƒãƒ¼ã«jpegç”»åƒã¨ã—ã¦æŠ•ã’ã¤ã‘ã‚‹ã€‚éŸ³å£°ã¯ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®ãŸã‚ã«ä½¿ã†ã€‚

ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ä½œã‚‹ã¨ã“ã‚ã ã‘è¼‰ã›ã¾ã™ã€‚

```ts
// https://github.com/myuon/juniQ/blob/master/viewer/src/index.ts#L42
class AudioVolume {
  processor: ScriptProcessorNode;
  volume: number;
  clipLevel: number;
  averaging: number;
  clipping: boolean;
  lastClip: number;
  clipLag: number;

  constructor(audioContext: AudioContext, clipLevel = 0.98, averaging = 0.95, clipLag = 750) {
    this.processor = audioContext.createScriptProcessor();
    this.processor.onaudioprocess = this.volumeAudioProcess;
    this.clipping = false;
    this.lastClip = 0;
    this.volume = 0;
    this.clipLevel = clipLevel;
    this.averaging = averaging;
    this.clipLag = clipLag;

    this.processor.connect(audioContext.destination);
  }

  // éŸ³å£°ãŒã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ã‚„ã£ã¦ãã‚‹ã®ã§éŸ³é‡ã‚’å–å¾—ã™ã‚‹
  volumeAudioProcess = (event: AudioProcessingEvent) => {
    let buf = event.inputBuffer.getChannelData(0);
    let sum = 0;
    
    // audio bufferã‹ã‚‰éŸ³é‡ã‚’åˆè¨ˆ
    buf.forEach((x) => {
      if (Math.abs(x) >= this.clipLevel) {
        this.clipping = true;
        this.lastClip = window.performance.now();
      }

      sum += x * x;
    });

    // é•·ã•ã§å‰²ã‚‹
    let rms = Math.sqrt(sum / buf.length);

    // ã‚ã¾ã‚Šæ€¥æ¿€ã«å¤§ãããªã‚‰ãªã„ã‚ˆã†ã«è£œæ­£
    this.volume = Math.max(rms, this.volume * this.averaging / 2);
  };

  checkClipping = () => {
    if (!this.clipping) return false;

    if ((this.lastClip + this.clipLag) < window.performance.now()) {
      this.clipping = false;
    }

    return this.clipping;
  };

  shutdown = () => {
    this.processor.disconnect();
    this.processor.onaudioprocess = null;
  };
}
```

## ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰(é¡”æ¤œå‡º&è¨ˆç®—)

æ¬¡ã®å‡¦ç†ã‚’è¡Œã†

- é¡”æ¤œå‡º(dlib)
- å£ã®è¼ªéƒ­ã¨ã‹ç›®ã®è¼ªéƒ­ã¨ã‹ã®ãƒ‘ãƒ¼ãƒ„ã®æ¤œå‡º(dlib)
- ãƒ‘ãƒ¼ãƒ„ã”ã¨ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨ˆç®—
  - ä½“ã®å·¦å³å‚¾ãå…·åˆ
  - é¡”ã®å‘ãã¨å›è»¢è§’åº¦
  - ç›®ã®é–‹ãå…·åˆ
  - ç›®ã®ä¸­å¿ƒä½ç½®(è¦–ç·šæ¨å®š)
  - å£ã®é–‹ãå…·åˆ(ãªãŠã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å…¥ã‚Œã‚‹ã®ã§ã“ã®æ©Ÿèƒ½ã¯å®Ÿè³ªæ­»ã‚“ã§ã‚‹)
  - æ‰‹ã®ä½ç½®(è‚Œè‰²ã£ã½ã„é ˜åŸŸã®ä¸­å¿ƒä½ç½®ã‚’æ¨å®šã—ã¦æ‰‹ã®ä½ç½®ã‚’å–ã‚ã†ã¨ã—ãŸæ®‹éª¸ãŒã‚ã‚‹ã‘ã©è‚Œè‰²ãŒã‚ã‚Šãµã‚Œã™ãã¦ã¦ç²¾åº¦ãŒã‚ã¾ã‚Šã«æ‚ªã„ã®ã§ãŠè”µå…¥ã‚Š å¤šåˆ†ç·‘è‰²ã®ãƒ†ãƒ¼ãƒ—ã¨ã‹ã‚’æ‰‹ã«ã¾ãã¨ã„ã„æ„Ÿã˜ã«ãªã‚‹ã¨æ€ã†)
- ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã§æ»‘ã‚‰ã‹ã«ã™ã‚‹

#### é¡”æ¤œå‡º

ç”»åƒã‹ã‚‰é¡”ã®é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã™ã€‚

```python
# é¡”ã®é ˜åŸŸã‚’æ¤œå‡ºã™ã‚‹ã‚„ã¤
detector = dlib.get_frontal_face_detector()

# é¡”ã®é ˜åŸŸã‹ã‚‰ãƒ‘ãƒ¼ãƒ„ã®è¼ªéƒ­ã‚’æ¤œå‡ºã™ã‚‹ã‚„ã¤
# æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹ãªã®ã§å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦
# dlibãŒé…ã£ã¦ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã‹ã‚’ã‚‚ã‚‰ã£ã¦ãã‚‹
predictor = dlib.shape_predictor(str(face_landmark_path))

# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L216
  if should_detect == 0:
    # é¡”ã®é ˜åŸŸã‚’ã¨ã£ã¦ãã‚‹(ãƒªã‚¹ãƒˆã§å¸°ã£ã¦ãã‚‹)
    face_rects = detector(frame, 0)
  should_detect = (should_detect + 1) % 3

  if len(face_rects) > 0:
    # æœ€åˆã®ã‚„ã¤(ãã‚‚ãã‚‚1äººã—ã‹æ˜ ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ãªã„)ã®é ˜åŸŸã‚’åˆ‡ã£ã¦ãã‚‹
    face_rect = dlib.rectangle(
      int(face_rects[0].left() * (1 / resize[0])),
      int(face_rects[0].top() * (1 / resize[1])),
      int(face_rects[0].right() * (1 / resize[0])),
      int(face_rects[0].bottom() * (1 / resize[1])),
    )
```

`detector(frame, 0)`ã¨ã‹ã§é¡”ã®é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã›ã‚‹ã€‚ç°¡å˜ã€‚

ã“ã®detectorã®å‡¦ç†ã¯ã‹ãªã‚Šé‡ã„ã‚‰ã—ãã€å®Ÿéš›ã«ä»–ã®å‡¦ç†ã«æ¯”ã¹ã¦æ™‚é–“ãŒã‹ã‹ã‚ŠãŒã¡ãªã®ã§æ¯ãƒ•ãƒ¬ãƒ¼ãƒ ã‚„ã‚‹ã®ã¯ã¤ã‚‰ã„ã€‚ç§ã¯é¡”ã®é ˜åŸŸè‡ªä½“ã¯3ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ã ã‘æ¤œå‡ºã—ã¦ã‚‹ã€‚`predictor`ã¯é‡ããªã„ã®ã§æ¯å›å›ã—ã¦å¤§ä¸ˆå¤«ã€‚

#### ãƒ‘ãƒ¼ãƒ„æ¤œå‡º

```python
    shape = predictor(original, face_rect)
```

ã ã‘ã§ã‚ˆã„ã€‚ç°¡å˜ã€‚

æˆ»ã‚Šå€¤ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ãã‚‹ãŒ[ã“ã“](https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/)ã®ä¸­æ–­ãã‚‰ã„ã«ã‚ã‚‹[ã“ã®ç”»åƒ](https://www.pyimagesearch.com/wp-content/uploads/2017/04/facial_landmarks_68markup.jpg)ã‚’å‚è€ƒã«ã™ã‚‹ã¨ã‚ˆã„ã€‚

ã¡ãªã¿ã«ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ã€‚

```python
# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L89
def create_parts_list(shape):
  return {
    # é¡”ã®è¼ªéƒ­
    'chin': shape[0:17].tolist(),
    # çœ‰
    'left_eyebrow': shape[17:22].tolist(),
    'right_eyebrow': shape[22:27].tolist(),
    # é¼»(ç¸¦æ¨ª)
    'nose_bridge': shape[27:31].tolist(),
    'nose_tip': shape[31:36].tolist(),
    # ç›®
    'right_eye': shape[36:42].tolist(),
    'left_eye': shape[42:48].tolist(),
    # å£
    'outer_lip': shape[48:60].tolist(),
    'inner_lip': shape[60:68].tolist(),
  }
```

#### é¡”ã®æ–¹å‘æ¨å®š

é¡”ã®æ–¹å‘æ¨å®šã¯å‰²ã¨é›£ã—ã„ã®ã ã‘ã©ã€å¤§ä½“æ¬¡ã®ã‚ˆã†ãªæ„Ÿã˜ã§ã‚„ã‚‹ã€‚

- ã‚ã‚‰ã‹ã˜ã‚ã€é¡”ã®ãƒ‘ãƒ¼ãƒ„ã®3Dåº§æ¨™ã‚’èª¿ã¹ã¦ãŠã(ç›®ã®ä¸­å¿ƒã¨ã‹è¼ªéƒ­ã®ä¸­å¿ƒã¨ã‹)
- é¡”ã®ãƒ‘ãƒ¼ãƒ„ã®åº§æ¨™ã‹ã‚‰å¯¾å¿œã™ã‚‹2Dåº§æ¨™ã‚’æŒã£ã¦ãã‚‹
- solvePnPã§è§£ã(2Dã¨3Dã®å¯¾å¿œç‚¹ã‹ã‚‰å›è»¢ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ±‚ã‚ãŸã‚Šã™ã‚‹ã‚„ã¤; OpenCVã«ã‚ã‚‹)

```python
# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L9
K = [6.5308391993466671e+002, 0.0, 3.1950000000000000e+002,
     0.0, 6.5308391993466671e+002, 2.3950000000000000e+002,
     0.0, 0.0, 1.0]
D = [7.0834633684407095e-002, 6.9140193737175351e-002, 0.0, 0.0, -1.3073460323689292e+000]

cam_matrix = np.array(K).reshape(3, 3).astype(np.float32)
dist_coeffs = np.array(D).reshape(5, 1).astype(np.float32)

# é¡”ã®3Dåº§æ¨™ã¨ã‹ãã†ã„ã†ã‚„ã¤
# ã©ã“ã‹ã‹ã‚‰ã‚‚ã‚‰ã£ã¦ããŸã‚„ã¤ã¨è·äººã«ã‚ˆã‚‹æ‰‹ä½œæ¥­ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã‚‹
object_pts = np.float32([
  [6.825897, 6.760612, 4.402142], # 17
  [1.330353, 7.122144, 6.903745], # 21
  [-1.330353, 7.122144, 6.903745], # 22
  [-6.825897, 6.760612, 4.402142], # 26
  [5.311432, 5.485328, 3.987654], # 36
  [1.789930, 5.393625, 4.413414], # 39
  [-1.789930, 5.393625, 4.413414], # 42
  [-5.311432, 5.485328, 3.987654], # 45
  [2.005628, 1.409845, 6.165652], # 31
  [-2.005628, 1.409845, 6.165652], # 35
  [2.774015, -2.080775, 5.048531], # 48
  [-2.774015, -2.080775, 5.048531], # 54
  [0.000000, -3.116408, 6.097667], # 57
  [0.000000, -7.415691, 4.070434] # 8
  ])

reproject_src = np.float32([
  [10.0, 10.0, 10.0],
  [10.0, 10.0, -10.0],
  [10.0, -10.0, -10.0],
  [10.0, -10.0, 10.0],
  [-10.0, 10.0, 10.0],
  [-10.0, 10.0, -10.0],
  [-10.0, -10.0, -10.0],
  [-10.0, -10.0, 10.0]])

# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L89
def decompose(shape):
  image_pts = np.float32([
    shape[17],
    shape[21],
    shape[22],
    shape[26],
    shape[36],
    shape[39],
    shape[42],
    shape[45],
    shape[31],
    shape[35],
    shape[48],
    shape[54],
    shape[57],
    shape[8],
  ])

  _, rotation_vec, translation_vec = cv2.solvePnP(object_pts, image_pts, cam_matrix, dist_coeffs)
  reproject_dst, _ = cv2.projectPoints(reproject_src, rotation_vec, translation_vec, cam_matrix, dist_coeffs)
  reproject_dst = reproject_dst.reshape(8,2).tolist()
  rotation_mat, _ = cv2.Rodrigues(rotation_vec)

  return reproject_dst, rotation_mat, rotation_vec, translation_vec
```

è©³ã—ãã¯OpenCVã®solvePnPã¨ã‹ã§èª¿ã¹ã‚‹ã¨è‰¯ã„ã¨æ€ã†ã€‚

ã“ã‚Œã§å›è»¢è¡Œåˆ—ã¨ã‹ãŒå¾—ã‚‰ã‚Œã‚‹ã®ã§ã€é¡”ã®å›è»¢è§’åº¦ã¯æ¬¡ã§è¨ˆç®—ã™ã‚‹(ã¡ãªã¿ã«ã“ã“ã§å¾—ã‚‰ã‚ŒãŸè¡Œåˆ—ã¯ã€Œã‚«ãƒ¡ãƒ©ã€åŸºæº–ãªã“ã¨ã«æ³¨æ„ã€‚é¡”ã®è¡Œåˆ—ã¯åˆ¥ã«è¨ˆç®—ãŒå¿…è¦)ã€‚

```python
# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L78
def get_head_pose_angles(rotation_mat, rotation_vec, translation_vec):
  new_rotation_mat = -np.matrix(rotation_mat).T * np.matrix(translation_vec)

  rotation_vec = np.array([
    new_rotation_mat[0],
    new_rotation_mat[1],
    rotation_vec[2] * 180 / np.pi,
  ])

  return rotation_vec.squeeze().tolist()
```

#### ç›®ã®é–‹ãå…·åˆ

ç›®ã®é–‹ãå…·åˆã¯ç›®ã®ç¸¦å¹…ã¨ã‹ã‹ã‚‰é©å½“ã«è¨ˆç®—ã—ã¦ã‚‹(å€¤ãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã‚‹ã‘ã©ã‚«ãƒ¡ãƒ©ç”»åƒã®ã‚µã‚¤ã‚ºã¨ã‹ã«ä¾å­˜ã™ã‚‹ã®ã§ã‚¢ãƒ¬ æœ¬å½“ã¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãªã„ã¨ã ã‚ãªã‚“ã ã‘ã©ãã‚Œã‚‚ã—ã¦ãªã„)

ç›®ã¯åŸºæœ¬çš„ã«ã‚ã¾ã‚Šé–‰ã˜ã•ã›ãªã„æ–¹ãŒã‚ˆãã¦ã€ä»Šã®ã‚„ã‚Šæ–¹ã ã¨åŠç›®ã«ãªã‚‹ã“ã¨ãŒã™ã”ãå¤šã„ã®ã§ã“ã‚Œã¯ã©ã†ã«ã‹ã—ãŸæ–¹ãŒã„ã„ã€‚åŸºæœ¬ã¯ãšã£ã¨é–‹ãã£ã±ãªã—ã§ãŸã¾ã«é–‰ã˜ã‚‹ãã‚‰ã„ãŒã„ã„ã¨æ€ã†ã‚“ã ã‘ã©ã€ã©ã†ã™ã‚‹ã®ãŒã„ã„ã‚“ã ã‚ã€‚ç¬ãã‚’è¦³æ¸¬ã—ãŸã‚‰ç¬ãã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç™ºç«ã¨ã‹ã™ã‚‹ã¨ã‚ˆã•ãã†ã ã‘ã©ã‚ã‚“ã©ã„

```python
# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L102
def eye_open_param(eye):
  h1 = np.linalg.norm(np.subtract(eye[1], eye[5]))
  h2 = np.linalg.norm(np.subtract(eye[2], eye[4]))
  h = (h1 + h2) / 2

  return (
    0.0 if h < 3.0 else
    1.0 if h > 8.0 else
    (h - 3) / 5
  )
```

#### ç›®ã®ä¸­å¿ƒæ¨å®š(ç›®ç·šæ¨å®š)

ç›®ã®é ˜åŸŸãŒåˆ†ã‹ã£ã¦ã„ã‚‹ã®ã§äºŒå€¤åŒ–ã—ã¦ç³ã®ä¸­å¿ƒã‚’æ¨å®šã™ã‚‹ã€‚

```python
# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L113
def get_center(gray_img):
  # OpenCV2ã®momentsã¨ã‹ã„ã†ã®ã‚’ä½¿ã†ã¨å††ã‚’æ¨å®šã—ã¦ä¸­å¿ƒã‚’è¨ˆç®—ã—ã¦ãã‚Œã‚‹ã‚‰ã—ã„
  moments = cv2.moments(gray_img, False)
  try:
    return int(moments['m10'] / moments['m00']), int(moments['m01'] / moments['m00'])
  except:
    return None

def detect_eye_center(img, shape):
  # å³ç›®ã€å·¦ç›®ã®é ˜åŸŸã‚’ã‚¢ãƒ¬ã—ã¦ãŠã
  left_eye = [
    shape[36],
    min(shape[37], shape[38], key=lambda x: x[1]),
    max(shape[40], shape[41], key=lambda x: x[1]),
    shape[39],
  ]
  right_eye = [
    shape[42],
    min(shape[43], shape[44], key=lambda x: x[1]),
    max(shape[46], shape[47], key=lambda x: x[1]),
    shape[45],
  ]

  def get_eye_center(eye):
    origin = (eye[0][0], eye[1][1])
    if abs(eye[2][1] - origin[1]) < 2:
      return None

    # ç”»åƒã‹ã‚‰ç›®ã®é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã™
    eye = img[origin[1]:eye[2][1], origin[0]:eye[-1][0]]
    # äºŒå€¤åŒ–
    _, eye = cv2.threshold(eye, 30, 255, cv2.THRESH_BINARY_INV)

    center = get_center(eye)
    if center:
      return int(center[0] + origin[0]), int(center[1] + origin[1])
    
    return center
  
  def normalize_position(value, start, end):
    size = abs(end - start)
    return (value - (start + size / 2)) / (size / 2)

  # ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
  left_pos = get_eye_center(left_eye)
  right_pos = get_eye_center(right_eye)

  # æ­£è¦åŒ–(0.0ã‹ã‚‰1.0ã®é–“ã®å€¤ã«mappingã™ã‚‹)
  if left_pos is None:
    left_normalized_pos = None
  else:
    left_normalized_pos = (
      normalize_position(
        left_pos[0],
        min(shape[37][0], shape[41][0]),
        max(shape[38][0], shape[40][0])
      ),
      normalize_position(
        left_pos[1],
        min(shape[37][1], shape[38][1]),
        min(shape[40][1], shape[41][1])
      )
    )

  return (
    (left_pos, right_pos),
    left_normalized_pos
  )
```

#### å£ã®é–‹ãå…·åˆã®æ¨å®š

ç›®ã¨åŒã˜ã‚ˆã†ã«é©å½“ã«ã‚„ã‚‹(é›‘)

#### ä½“ã®å‚¾ãæ¨å®š

ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä¸­å¿ƒã¨é¡”ã®ä¸­å¿ƒã‹ã‚‰å‚¾ãã‚’é©å½“ã«æ¨å®šã™ã‚‹ã€‚ãªãã¦ã‚‚ã‚ˆã„ã‘ã©è‹¥å¹²Live2Dã®ä½“ã®è»¸ã§å‚¾æ–œã¤ã‘ã‚‹ã¨ãã‚Œã£ã½ããªã‚‹ã®ã§ã„ã‚Œã¦ã‚‹ã€‚

```python
# https://github.com/myuon/juniQ/blob/master/server/src/recognizer.py#L205
def get_body_pose(rect):
  # center_of_window = (160,120)
  center_of_face = (rect.left() + rect.width() / 2, rect.top() + rect.height() / 2)
  return 90 - (np.arctan2(480 - center_of_face[1], center_of_face[0] - 360)) * 180 / np.pi
```

### ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿

ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã‚’å…¥ã‚Œã‚‹ã¨ä½•ã‚‚ã‹ã‚‚ã¬ã‚‹ã¬ã‚‹ã«ãªã‚‹ã€‚ã“ã‚ŒãŒãªã„ã¨çµæ§‹ãŒããŒãã«ãªã‚‹ã®ã§å…¥ã‚ŒãŸæ–¹ãŒã„ã„ã€‚

ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã¯å‰ã®å€¤ã¨æ¬¡ã®å€¤ã‹ã‚‰æ¨å®šå€¤ã‚’å‡ºã™ãŸã‚ã®ã‚‚ã®ãªã®ã§å‰ã®å€¤ã‚‚æ®‹ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã€‚

```python
# https://github.com/myuon/juniQ/blob/master/server/src/main.py#L19
class KalmanCache():
    def __init__(self, keys=[]):
        self.filters = {}
        self.prevs = {}
        self.vels = {}

        for key in keys:
            self.create(key)

    # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã®å®šç¾©
    # è‹¥å¹²ç§˜ä¼ã®ãŸã‚Œå…¥ã‚Šã‹ã‚‚
    @staticmethod
    def newKalmanFilter():
        kalman = cv2.KalmanFilter(3,3)
        kalman.measurementMatrix = np.array([
            [1,1,1],
            [0,0,0],
            [0,0,0]
        ], np.float32)
        kalman.transitionMatrix = np.array([
            [1,0.1,0],
            [0,1,0.5],
            [0,0,1]
        ], np.float32)
        kalman.processNoiseCov = np.array([
            [1,0,0],
            [0,1,0],
            [0,0,1]
        ], np.float32) * 0.1

        return kalman

    def create(self, key):
        self.filters[key] = self.newKalmanFilter()
        self.prevs[key] = 0.0
        self.vels[key] = 0.0

    # æ–°ã—ã„å€¤ã‚’çªã£è¾¼ã‚€
    def correct(self, key, value):
        vel = value - self.prevs[key]
        self.filters[key].correct(np.array([
            value,
            vel,
            vel - self.vels[key]
        ], np.float32))

        self.prevs[key] = value
        self.vels[key] = vel

    # æ¬¡ã®å€¤ã‚’æ¨å®š
    def predict(self, key):
        return float(self.filters[key].predict()[0])
```

## Viewer (live2Dãƒ¢ãƒ‡ãƒ«æç”»)

Live2Dãƒ¢ãƒ‡ãƒ«ã¯äº‹å‰ã«ä½œã£ã¦ãŠãã¾ã™ã€‚

ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‹ã‚’ã¡ã‚ƒã‚“ã¨è¨­å®šã—ã¦ãŠãã®ã¨ã€ãƒ‘ãƒ¼ãƒ„ã®æç”»å„ªå…ˆåº¦ã¯ãã£ã¡ã‚Šé †ç•ªã«ã—ã¦ãŠãã®ãŒå¤§äº‹ã£ã½ã„ã€‚ã‚ã¨ãƒ‘ãƒ¼ãƒ„ã¯æ—¥æœ¬èªã˜ã‚ƒãªãã¦ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®æ–¹ãŒéƒ½åˆãŒã„ã„ã¨æ€ã„ã¾ã™ã€‚

```ts
// https://github.com/myuon/juniQ/blob/master/viewer/src/viewer.ts#L53

class App {
    app: PIXI.Application;
    model: LIVE2DCUBISMPIXI.Model;
    position: [number, number];
    scaler: [number, number];
    size: [number, number];
    empty_animation: LIVE2DCUBISMFRAMEWORK.Animation;

    ...
}

let app = new App({
    size: [1024, 720],
    moc: "assets/yugure_neko_avatar/yugure_neko_export.moc3",
    texture: "assets/yugure_neko_avatar/yugure_neko_export.2048/texture_00.png",
    physics: "assets/yugure_neko_avatar/yugure_neko_export.physics3.json",
    empty_motion: "assets/empty_motion.json",
    position: [512, 720],
    scaler: [1.5, 1.5],
});
```

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“ã¯Appã‚¯ãƒ©ã‚¹ã§è¨˜è¿°ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ã‹è¨­å®šã¨ã‹ã‚’ã—ã¾ã™ã€‚

ãƒ‘ã‚¹ã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ãªã‚“ã‚„ã™ã¾ã‚“ãªã¨ã„ã†æ°—æŒã¡(æ°—æŒã¡ã®ã¿)ã€‚  

ä»¥ä¸‹ã¯constructorã®ä¸­èº«ã§ã™ã€‚(ã“ã®è¾ºã¯SDK for webã®exampleã¨ã‹è¦‹ãŸã‚‰å¤§ä½“åˆ†ã‹ã‚‹ã¨æ€ã†)

```ts
// https://github.com/myuon/juniQ/blob/master/viewer/src/viewer.ts#L72
                this.app = new PIXI.Application(this.size[0], this.size[1], { backgroundColor: 0x00ff00 });
                document.body.appendChild(this.app.view);

                let moc = LIVE2DCUBISMCORE.Moc.fromArrayBuffer(resources['moc'].data);

                this.model = new LIVE2DCUBISMPIXI.ModelBuilder()
                    .setMoc(moc)
                    .setTimeScale(1)
                    // ãƒ†ã‚¯ã‚¹ãƒãƒ£
                    .addTexture(0, resources['texture'].texture)
                    // ç‰©ç†æ¼”ç®—ã®è¨­å®š
                    .setPhysics3Json(resources['physics'].data)
                    // ã“ã‚Œã¯ãªã‚“ã§è¦ã‚‹ã‚“ã ã£ã‘â€¦(ï¾„ï½µï½²ï¾’)
                    .addAnimatorLayer("base", LIVE2DCUBISMFRAMEWORK.BuiltinAnimationBlenders.OVERRIDE, 1)
                    .build();

                this.processModel(); // ãƒ¢ãƒ‡ãƒ«ã‚’ã¡ã‚‡ã£ã¨ã„ã˜ã‚‹(å¾Œè¿°)

                this.app.stage.addChild(this.model);
                this.app.stage.addChild(this.model.masks);

                // ã“ã®è¾ºã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®åˆæœŸåŒ–ã‚’è¡Œã„ã¾ã™ã€‚
                // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã¯å®Ÿéš›ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ•ã’ã‚‰ã‚ŒãŸã‚‰è¨­å®šã—ã¦å‹•ã‹ã™ã¿ãŸã„ã«ãªã‚‹ã®ã§
                // ã“ã“ã§ã¯ç©ºã«ã—ã¦ãŠãã¾ã™
                this.empty_animation = LIVE2DCUBISMFRAMEWORK.Animation.fromMotion3Json(resources['empty_motion'].data);
                this.empty_animation.evaluate = (time: any, weight: any, blend: any, target: any) => {
                };
                this.model.animator.getLayer('base').play(this.empty_animation);

                this.app.ticker.add((deltaTime) => {
                    this.model.update(deltaTime);
                    this.model.masks.update(this.app.renderer);
                });

                this.setStageTransform();
                this.onResize();
                this.sendToParent();
```

`processModel`ã¨ã„ã†ã®ãŒãƒã‚¹ã‚¯ã¨ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã‚’ã—ã¨ã‹ãªã„ã¨ã†ã¾ãç”»é¢ã«è¡¨ç¤ºã•ã‚Œãªã„(è¡¨ç¤ºé †ã¨ã‹è¡¨ç¤ºé ˜åŸŸãŒãŠã‹ã—ããªã‚‹ã£ã½ã„)

```ts
// https://github.com/myuon/juniQ/blob/master/viewer/src/viewer.ts#L126
    processModel = () => {
        // ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¡¨ç¤ºé †ã«æ²¿ã£ã¦ä¸¦ã¹æ›¿ãˆã‚‹
        // å‹æ‰‹ã«ã¯ä¸¦ã¹ã¦ãã‚Œãªã„ã®ã§ã“ã‚Œã‚’ã—ãªã„ã¨è¡¨ç¤ºé †ãŒå¤‰ã«ãªã‚‹
        let orders: [string, number][] = [];
        for (let k in this.model.drawables.ids) {
            orders.push([this.model.drawables.ids[k], this.model.drawables.renderOrders[k]]);
        }
        orders.sort((x:[string, number], y: [string, number]) => x[1] - y[1]);

        // ãƒ¡ãƒƒã‚·ãƒ¥ã‚’æ–°ãŸã«è¿½åŠ ã¿ãŸã„ãªã“ã¨ã‚’ã™ã‚‹
        // ã“ã“ã¯å®Œå…¨ã«è¬ã ã‘ã©ã“ã‚Œã‚’ã—ãªã„ã¨ç›®ã®è¡¨ç¤ºã¨ã‹ä¸Šæ‰‹ãã„ã‹ãªã‹ã£ãŸ
        // è¬ãŒæ·±ã„
        this.model.removeChildren();
        for (let [mesh_name, _] of orders) {
            let mesh = this.model.getModelMeshById(mesh_name);
            this.model.addChild(mesh);
        }
    };
```

å®Ÿéš›ã«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‹ã‚’ã™ã‚‹ã®ã¯æ¬¡ã®å‡¦ç†ã€‚`animateByParams`ã‚’å‘¼ã¶ã¨ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãŒå§‹ã¾ã‚‹ã€‚ã“ã‚Œã‚’1ç§’ã«ä½•å›ã‚‚å‘¼ã¶ã“ã¨ã§æ»‘ã‚‰ã‹ãªã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã«ãªã‚‹ã‘ã©ã€ä¸€æ–¹ã§ã‚ã£ã¡ã‚ƒé‡ããªã‚‹(å½“ãŸã‚Šå‰ã‚„)ã®ã§ã‚‚ã£ã¨å·¥å¤«ã—ãŸæ–¹ãŒã„ã„èª¬ã‚ã‚‹ã€‚

```ts
// https://github.com/myuon/juniQ/blob/master/viewer/src/viewer.ts#L173
    animateByParams = (params: {[key:string]: string}) => {
        if (this.empty_animation === undefined || this.empty_animation === null) return;

        // ã•ã£ãåˆæœŸåŒ–ã—ã¦ãŠã„ãŸempty_animationã‚’ä½¿ã†
        // evaluateã«é–¢æ•°ã‚’ã‚»ãƒƒãƒˆã—ã¦playã™ã‚‹ã¨å‹•ã
        this.empty_animation.evaluate = (time: any, weight: any, blend: any, target: any) => {
            // ã“ã“ã§ã¯paramsã«å‹•ã‹ã—ãŸã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã‚‹
            Object.keys(params).forEach((key) => {
                let parameter_name = target.parameters.ids.indexOf(key);
                // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã¯blendã‚’ä½¿ã£ã¦ã„ã„æ„Ÿã˜ã®å€¤ã‚’ä½œã‚‹ã“ã¨ã§å®Ÿç¾ã™ã‚‹
                // ã¾ãé©å½“ã§ã‚‚ãªã‚“ã¨ã‹ãªã£ã¦ã‚‹(ã»ã‚“ã¾ã‹ï¼Ÿ)
                target.parameters.values[parameter_name] = blend(target.parameters.values[parameter_name], parseFloat(params[key]), 0, weight);
            });
        };
        this.model.animator.getLayer('base').play(this.empty_animation);
    };
```

å¾Œã¯ã¾ããƒã‚¦ã‚¹ãƒ›ã‚¤ãƒ¼ãƒ«ã‚„ã‚¯ãƒªãƒƒã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ‹¡å¤§ç¸®å°ã—ãŸã‚Šå‹•ã‹ã—ãŸã‚Šã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã—ãŸã‚Šã™ã‚‹æ©Ÿèƒ½ãŒã‚ã‚‹ã‘ã©ã©ã†ã§ã‚‚ã„ã„ã®ã§é£›ã°ã™ã€‚

## ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦

è‰²ã€…ã¨å•é¡ŒãŒã‚ã‚Šå€¤ãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ãŸã‚Šã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãŒã‚ã£ã¡ã‚ƒæ±šã‹ã£ãŸã‚Šdockerã®ä½¿ã„æ–¹ãŠã‹ã—ã‹ã£ãŸã‚Š(ã¦ã„ã†ã‹ãƒ“ãƒ«ãƒ‰ã®ä»•çµ„ã¿ã¡ã‚ƒã‚“ã¨ã‚¢ãƒ¬ã—ãŸã„)ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒãªã‹ã£ãŸã‚Šã™ã‚‹ã®ã§ä½¿ã†ã¨ãã¯ãã®è¾ºã‚’ã©ã†ã«ã‹ã—ãŸæ–¹ãŒã„ã„ã¨æ€ã„ã¾ã™ã€‚

ã¾ãã§ã‚‚ä¸€å¿œå‹•ã„ã¦ã„ã¦ãã‚Œã£ã½ãã¯ãªã‚‹ã®ã§éŠã³ãŸã„äººã¯ã©ã†ãã€‚

ã‚ã¨çµæ§‹é‡ã„ã®ã§ãšã£ã¨å‹•ã‹ã—ã£ã±ã«ã™ã‚‹ã¨CPUãªã©ã«ã‚ˆããªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚è»½é‡åŒ–ã‚‚ã—ãŸã„ã‚“ã ã‘ã©ãªãƒ¼ã€‚

Unityã§ä½œã‚Šç›´ãã†ã¨ãšã£ã¨æ€ã£ã¦ã„ã‚‹ã‚“ã§ã™ãŒãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ä½œã‚Šæ–¹ã¨ã‹ãã‚ŒãŒã©ã‚Œãã‚‰ã„ã—ã‚“ã©ã„ã“ã¨ãªã®ã‹ã¨ã‹ãŒçš†ç›®è¦‹å½“ã‚‚ã¤ã‹ãªã„ã®ã§æ‚©ã‚“ã§ã‚‹ã¨ã„ã†æ„Ÿã˜ã§ã™ã€‚

ã¾ãƒ¼ã¨ã«ã‹ãã€Live2D SDKã‚‚OpenCVã‚‚dlibã‚‚ä½¿ã†ã®åˆã‚ã¦ã§é¡”æ¤œå‡ºã¨ã‹ã•ã£ã±ã‚Šã‚ã‹ã‚‰ã¬ã¨ã„ã†çŠ¶æ…‹ã ã£ãŸã‚“ã ã‘ã©ã¨ã‚Šã‚ãˆãšå‹•ãã‚‚ã®ãŒã§ããŸã®ã¯ã‚ˆã‹ã£ãŸã‹ãªã¨æ€ã„ã¾ã™ã€‚

## æœ€å¾Œã«

å¤•æš®å¯å­ã¡ã‚ƒã‚“ã‚’ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™(ã£ã¦è¨€ã£ã¦ã‚‚ãªã‚“ã‚‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãªã„ã‚“ã ã‘ã©)

ã‚ã¨å…¬é–‹ã«å¯¾ã—ã¦è¨±å¯ã‚’ãã‚ŒãŸLive2Dã®æ–¹ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚
