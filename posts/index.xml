<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The curse of λ</title>
    <link>https://myuon.github.io/posts/</link>
    <description>Recent content in Posts on The curse of λ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Sun, 27 Dec 2020 19:49:38 +0900</lastBuildDate>
    
      <atom:link href="https://myuon.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>2020年のお絵描きの進捗を振り返る</title>
        <link>https://myuon.github.io/posts/2020-oekaki/</link>
        <pubDate>Sun, 27 Dec 2020 19:49:38 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2020-oekaki/</guid>
        <description>2020年の絵についてのみ振り返る記事です。
真面目に練習しようと思った 10年以上ラクガキやって2ミリくらいしか上達してない自分に飽きたので真面目に練習しようと思って3月か4月くらいに液タブを買った。またクリスタ使える環境が欲しかったので10月くらいにiMacも買った。
適当に時期とその頃描いたやつ(の中でまあまだマシと思われるもの)をあげながら振り返ります。
成果 https://www.pixiv.net/users/9077699
多分今年で50作品くらいあげてる
掟 自分が三日坊主で根性が足りない性格なため掟を定めました。概ね守れています。(12月は3枚しか描いてないが…？)
 基本的に毎週1枚、ラクガキでなくちゃんとした絵を完成させる 上手く描けないという理由で没にしない。上手く描けてないなと思っても必ず線画・色塗り・仕上げ工程まで行う 描いたものは全てTwitterとPixivに上げる 必ず描きたいものに対して資料を用意する  3-4月  液タブに慣れようねという時期 そもそも自分に何が足りてないのかまだわかってない  途中で飽きた(こいついつも途中で飽きてんな) pic.twitter.com/QVZG4cmYnO
&amp;mdash; みょん (@myuon_myon) April 4, 2020  さっきの絵気に食わなすぎて泣きながらペン入れし直してた pic.twitter.com/KNh4c5AGUE
&amp;mdash; みょん (@myuon_myon) April 13, 2020  5月  好きなイラストをpixivとかで見つけてずっと眺めるみたいなことをするようになった 描く時に資料をちゃんと探して見ながら描くようになってる この辺から自分でも成長を感じるようになる  久々の先輩絵 pic.twitter.com/qAQR73FL8b
&amp;mdash; みょん (@myuon_myon) May 10, 2020  pic.twitter.com/gW50bYogcJ
&amp;mdash; みょん (@myuon_myon) May 13, 2020  この前のやつ塗ってた pic.twitter.com/fp0vpgDBlx
&amp;mdash; みょん (@myuon_myon) May 20, 2020  6月  迷走期 ただし資料をちゃんとみて他の人の絵柄を取り入れようとしたり5月頃に手に入れた描き方にしがみつかなかったのは結果的にはよかった (下書きで満足して雑にTwitterに投げてやった感を出すのをやめろ期)  pic.</description>
      </item>
    
      <item>
        <title>日本語のTypographyの設定</title>
        <link>https://myuon.github.io/posts/typography-japanese/</link>
        <pubDate>Sat, 02 May 2020 01:29:52 +0900</pubDate>
        <guid>https://myuon.github.io/posts/typography-japanese/</guid>
        <description>日本語のTypography、意外と誰もまとめてくれなくて悲しみながら自分で調整したので置いておく用。
これにした:
様子:
気持ち  フォントとか全部Noto Sans JPでいいよ(少なくともLinuxでキレイに見えるなら他の環境のことは知らねえというスタンスでいるので) Material Designだとh5, h6, body2とかあるけどまあ使うことないよ Material Designは全体的にfont-sizeのメリハリが大きすぎなので弱めて、代わりにletter-spacingは強めに設定しました。h1,h2は少し寄りすぎくらいかもしれない…が、カタカナ・ひらがなと密度の高い漢字だとだいぶ変わってきてしまうのでどこを取るのかは難しいところ…(普通の文章でそこまで漢字が連続することもそんなに無い気がするけど…) font-weightは大きい文字だと500くらいがキレイに見えると個人的に思っているのでそのへんで。Material Design氏なぜかh1-h6でfont-weightがバラバラなんだけどあれは一体何なんだ… line-heightは完全にノリでやってるけど適正値が分からない、そもそもheader要素は改行されることあんまないし大概専用のmargin入れるのでそんなに気にしなくてもいいのかもしれない 調整甘いところあるけどデフォルトよりはずっとマシになったのでとりあえずこれで手を打った  material-uiでの設定 createMuiTheme({ typography: { h1: { fontSize: &amp;#34;2rem&amp;#34;, fontWeight: 500, lineHeight: 1.75, letterSpacing: &amp;#34;-0.035em&amp;#34; }, h2: { fontSize: &amp;#34;1.65rem&amp;#34;, fontWeight: 500, lineHeight: 1.6, letterSpacing: &amp;#34;-0.03em&amp;#34; }, h3: { fontSize: &amp;#34;1.5rem&amp;#34;, fontWeight: 500, lineHeight: 1.5, letterSpacing: &amp;#34;-0.025em&amp;#34; }, h4: { fontSize: &amp;#34;1.25rem&amp;#34;, lineHeight: 1.5, letterSpacing: &amp;#34;-0.02em&amp;#34; }, body1: { lineHeight: 1.7, letterSpacing: &amp;#34;0.</description>
      </item>
    
      <item>
        <title>Lightsailでやっていくサービス開発</title>
        <link>https://myuon.github.io/posts/try-lightsail/</link>
        <pubDate>Fri, 03 Apr 2020 01:10:11 +0900</pubDate>
        <guid>https://myuon.github.io/posts/try-lightsail/</guid>
        <description>ジト目王国を始めた ジト目王国というサービスを始めました。ガチャでみょんポイントが引けます。(はい)
ところでこのサービスは現在AWSで維持されていて、固定費としてかかるのは月$3.5程度で済んでる(厳密には通信費とかあるけどGB単位でアレしないとかからないのでまぁ今の位の規模なら無視していいと思う)ので、せっかくなのでAWSでのあれこれを解説していく。
アプリの構成  APIサーバー: Rust製 DB: MySQL ↑の2つをdocker-composeに乗せてサービスとして運用(この構成だと1インスタンスにDBとAPIサーバーが同居しているのでAPIサーバーに負荷がかかるとDBが死ぬ危険性がある。まぁあくまで個人開発の小規模な時期にお金を頑張って節約したいという前提があるということで…) クライアントサイドはNowでホスティング  Lightsail LightsailはEC2をいい感じにパッケージングしたみたいなサービス。AWSとは思えないほど管理画面が使いやすいことと、基本的に全部のせでインスタンスだけでなく監視(CloudWatch)やロードバランサー(ALB)やDNSレコード管理(Route53)などが全部中途半端な状態でついてくるという便利なのかそうでないのかよくわからない感じのサービス。
使い方として(実際AWSも言っているが)最初はLightsailで維持して、規模が大きくなってきたらAMIを吐いてEC2に移行するのが割とおすすめ。
インフラ構成 インスタンスの確保 インスタンスは適当にぽちぽちして確保する。一番安いプランだと$3.5で、512MBと1vCPU(t2.nano程度のスペック)、20GBのEBSボリュームなどがついてくる。AWSでサービス開発してるとなんやかんや色々なサービス使わせられて、覚えるのが大変な上、合計利用料金が慣れないと読みづらいというのが解消されていて割と良いと思う。このプランで、Amazon Linuxを選択する。
一つ注意としては、AMIが現在Amazon Linux 2ではなくAmazon Linuxのせいで、情報を探すときは気をつけたほうがいい。他のディストリビューションでもいいけどAmazon Linux使っておくほうが多分何かと便利。
SSMの設定 LightsailはデフォルトだとHTTPの80番ポートとSSHの22番ポートが空いているが、まぁ22番ポートなんぞ全世界公開したくないし2020年なのでインスタンスへはSSM セッションマネージャー経由でアクセスをする。注意としてLightsailは現状(公式には)セッションマネージャーに対応しておらず、さらにAmazon Linuxだとagentが古いので自力で頑張る必要がある。
 amazon-ssm-agentをアップデートする: https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-manual-agent-install.html 次に、SSMを利用するためアクティベーションコードの発行を行う: https://qiita.com/kooohei/items/35340bd9d36163c33f54  最初にAmazonSSMManagedInstanceCoreをポリシーとしてアタッチされたロールを作成する アクティベーションコードを発行する インスタンスの中に入って、 amazon-ssm-agent コマンドを叩いてアクティベーションを行う あとは22番ポートを閉じてから、SSMのセッションマネージャーからセッションを起動する    アプリを動かす  dockerとdocker-composeをインストール: https://qiita.com/shinespark/items/a8019b7ca99e4a30d286  インスタンスに入って適当に docker-compose up とかする。この辺はAWS関係ないのでまぁ省略。
EIPの付与  アプリが動いたら静的IPでアクセスできることを確認する Elastic IPをLightsailの中で作成して貼り付ける。EIPはアタッチしているインスタンスが動いてると無料だけどインスタンスが停止しているときやどのインスタンスにもアタッチされてないと課金されるので無闇に作らないようにしよう。  SSLターミネーション 2020年なのでHTTPSに対応する必要があるわけだけど、自分で証明書の鍵の管理とかしたくないでござる〜ってことでマネージドサービス使いたいならCloudFrontを使うとできるが、ただ労力に見合ってない感じがあるのでnginxコンテナ生やすほうが早いでしょというのはそうかも…。まぁCloudFront入れておけばSSLターミネーションの他についでにキャッシュとDDoS対策も付いてくるのでお得！(ほんまか)
 まずRoute53でドメインを取得する(example.com など) ACMで証明書を発行する。例えば example.com をwebサイトそのもののために使って、APIサーバーでは api.example.com を使いたい場合はACMで *.example.com の証明書を発行する必要があることと、us-east-1リージョンで発行する必要があることに注意。 Route53でAレコードを登録する。ここで使うゾーンはLightsailインスタンス専用のやつで外には公開しないものなので、 api-lightsail.</description>
      </item>
    
      <item>
        <title>GoとRustの言語比較記事を書くのが流行ってるらしい</title>
        <link>https://myuon.github.io/posts/golang-and-rust/</link>
        <pubDate>Sat, 29 Feb 2020 19:37:36 +0900</pubDate>
        <guid>https://myuon.github.io/posts/golang-and-rust/</guid>
        <description>コンテキスト 私もGoとRustの比較記事書いてバズるやつやりたい
&amp;mdash; みょん (@myuon_myon) February 27, 2020  仕事でGoとRustを書いています。いずれもWebのサーバーサイドです。パフォーマンスとかほとほどって感じなので極限までチューニングしたりしません。という前提で読んでください。
Rust/Goはいずれも習得してから2年くらい書いています。書いてる量も多分そんなに変わりません。
Go なんと言っても習得難度が低いので人を選ばず書けるようになります。現状だと仕事で書くなら一番無難な選択肢だなと思っています。一方言語もエコシステムも何もかもかなりクセが強いので、Go Wayにちゃんと従うことが大事だなと思ったりします。
 ジェネリクスがないことは高速なコンパイルなど利点もありますがmap,filter等を型ごとにfor文書きまくることになるのでとても手が疲れます。スライスに値が入ってるかどうかをチェックする標準関数用意しといてくれ〜〜〜っていつも思う。 基本的に公式がユーザーに不便を強いる感じになっており、あまり便利さを追求しないほうが良いです。あとリポジトリのissueでGoodが100以上ついてるfeature requestを「対応しません」って言って問答無用で閉じたりするの結構趣がありますね。Goに入ってはGoに従えない人には向いてないです。 syntaxの一貫性があまりなく、結構Adhocな構文要素が多いです。特にゼロ値周りはヤバく、適当に書くとかなり気づきにくいバグを埋め込むおそれがあるのでチームで書くときはコード規約は必須です。公式がコード規約を出しているので、こういうのにとりあえず従っておくのが無難かもしれない。(なお結構うげーとなるような規約があるので私は全部は従いたくないです。) コンパイルが速くstatic buildが超カンタンなのはサイコーって感じですね(この辺はruntimeの出来がめちゃくちゃ良いのでそのへんのおかげ)。Dockerとの相性も良いのであんまり何も考えなくてもものが動いてサイコーです。 GoLandやVSCode pluginの出来が普通に良いのでDXはとても良いです。それはそうとVSCodeはなぜかcompletionの反応速度が異常に悪いので最近はもっぱらGoLandになりました。文明的だなあという気持ちになれて良いです。 標準ライブラリがやたら豪華なので結構何でも提供してくれています。大変便利です。言語人口が多いこともあってライブラリも(少なくとも数は)豊富です。 マクロとかそういうのもないので筋力が全てです。コーディングには筋肉をつけましょう。 仕事ではechoとgormを使っています。  Rust 使いこなせるようになればめちゃ便利な言語です。言語機能が強力なのとエコシステムが整っており、個人的な感覚ではライブラリも強力なものが多いので頼もしいです。習得難度が高いことと未だに言語自体が枯れていないため、界隈の趨勢が変わるとそれに振り回されそうな不安もあります。
 とにかくコンパイルが遅いです。キャッシュしないとCIのビルド時間が(releaseビルドなのもあり)30分とかになります。誰か助けてほしい。 LSPが微妙にやる気がないです。なんかあんまり補完してくれないときとかがある。もうちょっとやる気を出してほしい。(VSCode) Goと違ってジェネリクスにADTにマクロもあって文明的です。工夫すればコードの治安を良い感じに保つことが出来ます。 最近はasync runtime周りでの動きが活発です。特にasync/awaitが最近になって安定化されたこともあり、「future0.1にのみ対応した非同期APIのないライブラリ」「future0.3に対応したasync/awaitで書けるライブラリ」が入り乱れています。さらにasync runtimeは現状はtokioが一番強いですが、最近になってasync-stdというのが登場し、これが覇権を握ることになるとtokioに依存するライブラリが一斉に死滅する可能性があります。各種ライブラリはasync-stdが台頭するとtokioと非互換なため動かなくなるという状況に危機感を感じているようですが、現状で非同期に対応しているライブラリはほぼruntimeと密結合しているため、すぐには解決されないと思われます。今年や来年にはasync runtime大戦争が起きる可能性があり、仕事でtokio依存ライブラリを使っている身としてはかなり戦々恐々としています。 ちなみに最近一瞬消滅しかかったことで話題になったWebフレームワークのactix-webは、独自のthreadpoolを持っているためtokioともasync-stdとも互換性がないです。(async/awaitがもう少し浸透したらこのまま消える可能性もあるのではと個人的には思っている) これ直ってるみたいです。コメント参照。 学習コストはかなり高いと思います。Goに比べて言語機能がとにかく多いことと、↑のようにライブラリや言語自体がまだ発展途上であること、Goと違ってあまりeasy方面に振ってないライブラリが多いところなどにその理由があると感じています。ちなみにパフォーマンスを追求するわけでも低レイヤーであれこれするわけでもなく普通にアプリケーションを書くだけなら、巷で言われてるほど所有権とかライフタイムとかで詰まることはないと思います。 仕事ではhyperとdieselを使っています。(diesel辞めたいって毎秒言っている)  終わりに Rustがあまり憎しみの対象にならないのは単に仕事で書いてる人の数が少ないからだよ
&amp;mdash; みょん (@myuon_myon) February 15, 2020  </description>
      </item>
    
      <item>
        <title>2019年を振り返って</title>
        <link>https://myuon.github.io/posts/end-of-2019/</link>
        <pubDate>Mon, 30 Dec 2019 22:18:25 +0900</pubDate>
        <guid>https://myuon.github.io/posts/end-of-2019/</guid>
        <description>2019年も終わりそうなので振り返ります。色々あったような気もするし大していつもと変わらなかったような気もする。
草 GitHubの草
 初めて年間で4000contributionを超えたけど下半期は仕事でこのアカウントを使うようになったこともあり仕事の分が結構入ってしまっている。趣味だけだと3000弱くらい？(たぶん)
仕事など 夏くらいに転職しました。無職期間が3週間くらい(最初の1週間は有給消化期間だったので本当に雇用されてなかったのは2週間くらい)あったが、一生無職でいいなという気持ちになった。今も年末年始で少し長い休みだけど、一生こんな感じがいいなと思っている。人間は労働するようには出来ていない。
仕事ではGoでWebサービス作ったりRustでWebサービス作ったりTypeScriptとReactでWebサービスの画面を作ったりなどしている。仕事のおかげで今年一番伸びたスキルはReactな気がする。あとAWS？
&amp;ldquo;ふつうの&amp;rdquo;(ふつうとは)Webサービスのバックエンドやるならまず間違いなくGoが一番無難な選択肢だと思うけど、様々な罠を乗り越え不便を破壊する強い意志があればRustでもまぁ普通に開発できるなという知見を得られたのは良かった。来年はdieselを破壊する(予告)。
日曜定理証明士 そういえば今年は定理証明士として証明を書くなどしていた。記事も書いた。
https://myuon.github.io/posts/isabelle-cbc-casper-safety-proof/
趣味開発 何か色々やっていた気がするけど記憶があんまない。
 ghc-compiler-notes: GHCのソースコードのコメントを読むやつ。ブログも書いたが結構良い感じの仕上がりになった気がする。たまにGHCについてググるとヒットしたりして笑ってしまう。 debil: Rust製のORM。ある程度ちゃんと仕上げたらdieselを破壊して仕事で使おうかと目論んでいる。 minilight: Haskell製のグラフィックエンジン。ゲームを作るために作ったが、yamlで設定を書くのはつらい+Haskellでコードスワップをやるのは本当にしんどいという(当然の)結論に至る。 quartz: 自作言語のインタープリター。minilightと組み合わせてゲームを記述するスクリプト言語として使う。 あと趣味でWebサービスを作ったりなどしていたが正式リリースすら出来てない。来年気が向いたら続きやろうかと思っているが果たして。  直近ではminilightとquartzの開発を主にやっていた。言語を作るという、ある種憧れにも近いが特にやる意味を感じなくて今までやらなかったことを、いよいよ手を付けるというのはこんな気持ちなんだなと思ったりした。世の言語はよく考えられてるなと振り返って思うことが多かった気がする。
これは自作言語と自作エンジンでゲーム開発をする様子 [1/2] pic.twitter.com/xdqXRuPgTE
&amp;mdash; みょん (@myuon_myon) December 30, 2019  あと早くゲームを作りたい。ゲームエンジンを作ろう/言語を作ろうと思い立った瞬間は「こいつマジでゲームを作る気がないな」と思っていたものだがここにきてゲームを作るためのものが着々と揃いつつあるので来年は本当に作っていきたい所存。
その他 昨年にも増して漫画買ったりゲーム買ったりしていた気がするが、昨年の記憶がないのでヨクワカラナイ。
ブログは11本くらい書いていたらしい。
勉強はそこそこしてたような？通勤時間で本を読めることに気がついてから下半期は本もちょこちょこ読んでいた気がする。
どうでもいいがいい加減ブログを作り直したい。hugoをやめたい。
来年に向けて 今年の抱負は最強になることだったらしい。来年の抱負は魔王になることかな…。</description>
      </item>
    
      <item>
        <title>IsabelleによるCBC CasperのSafetyの証明をしました</title>
        <link>https://myuon.github.io/posts/isabelle-cbc-casper-safety-proof/</link>
        <pubDate>Sun, 27 Oct 2019 15:33:19 +0900</pubDate>
        <guid>https://myuon.github.io/posts/isabelle-cbc-casper-safety-proof/</guid>
        <description>日記です。
リポジトリ: LayerXcom/cbc-casper-proof
概要 (私は LayerX の人ではないですが)LayerX 社の人と色々あって CBC Casper というブロックチェーンのプロトコルの検証作業を行いました。(主に定理証明士としてのお手伝い)
半年くらいかかったけどやりたかった証明についにたどり着いたよという話。
CBC Casper って何 わからん。(無知)
何かブロックチェーンのプロトコルの名前らしい。Ethereum 財団が目をつけてるらしい。いわゆるビットコインとは違ってブロックを頑張ってマシンをぶん回してマイニングしたりしないらしい(ビットコインは PoW で CBC Casper は PoS)。
詳しいことは詳しい人に聞いたほうがいいよ(真理)。
cf: CBC Casper と形式的検証
Isabelle で検証って何するの ブロックチェーンはコンセンサス(分散合意)アルゴリズムの一種で、みんなで合意を取りましょうみたいなやつ。コンセンサスアルゴリズムで言われる正当性というのは主に次の 2 つ。
 Safety: 1 つの round でたかだか 1 つの値にしか合意しないこと Liveness: 必ず 1 つの値にいずれは合意できること(一生合意できないみたいな状態に陥らないこと)  実際のステートメントでは色々条件はあるがそういうのは一旦おいておいて、CBC Casper に対しては Safety は示されていて(論文があり) Liveness はまだ示されていないみたいなステータスだったはず。定理証明はどちらもされていないので、今回は簡単な(というか参考になる論文がすでにある)Safety の方を示した。
実際の証明について 証明は基本的に論文に沿って進めた: https://github.com/cbc-casper/cbc-casper-paper
ただし Safety Oracle の証明について、論文では clique というタイプのグラフについての性質を示すことで証明を行っているが、今回はこれを inspector(finality detector)というやつに一般化して証明を行った。
完走した感想 ドメイン知識がないこともあってめっちゃ大変だったというのが正直なところ。アタリマエであるが、論文に書いてない行間を埋める作業や誤植・足りない仮定を追加するなどの作業はちゃんと理論側の理解がないとやはりつらい。
一方で、今回は「理論側は別の人・定理証明は私」という分担を行ったが、そういう感じでもこういう証明の仕事を行うことは不可能ではないなという手応えを感じることが出来たのも良かった気がする。
証明がめっちゃ汚いのとまだ一般化する余地がそれなりに残っているので(あと Liveness の証明という大仕事も手付かずだし…)、気が向いたらまた続きをやりたいと思います。</description>
      </item>
    
      <item>
        <title>Genericなデータマッパーを書いた</title>
        <link>https://myuon.github.io/posts/database-generic-mapper/</link>
        <pubDate>Sat, 28 Sep 2019 17:15:06 +0900</pubDate>
        <guid>https://myuon.github.io/posts/database-generic-mapper/</guid>
        <description>まだライブラリとしては公開してませんが
背景 Haskell でサーバーサイドを書いてみようと思い立って色々やっていたところ、ORM 的なものが欲しい気持ちになってきた。 業界では persistent がデファクト感あるが、思ったほど細かいところに手が届かない(？)上にドキュメントが全然なくて使う気がなくなったので自分なりに解決策を考えた結果 database-generic-mapper というパッケージを作るに至った。
(実際のところ私は全然 persistent の全容を把握していない、そもそもドキュメントがないので把握のしようがない)
ていうか Generic Programming なるものを初めてやったけど普通に便利だった。TH より簡単で使いやすいのでアイデア次第で色々できそうではある(今更〜〜〜〜)。
database-generic-mapper database と銘打ってるが実体はただの record mapper 的な何かである。
特徴:
 Generic インスタンスなレコードと値の列を mapping してくれるやつ(DB にデータを保存することを考えると mapping するレコードは Generic インスタンスになっていると仮定しても良いだろうという感じで) TH なし 実際のデータのマッピングはライブラリ側の型クラスを使っているので自分で型を定義してインスタンスを書けば挙動はカスタマイズ可能 私は一応 MySQL で使ってるが特に DB 依存はない気がする(ただしマッピングされる先の型はライブラリ側で定義されてるものから選ぶ必要はある) 本当に誰でも思いつきそうな仕組みなので絶対すでに作られてるでしょって思って調べたけど見つからなかった…何でみんな TH するんだ…レコード定義したくないのか…  使い方 適当なデータ型を定義する。制約を書きたいときは幽霊型に載せる(これは attribute として後で文字列のリストとして取得可能)
mapper は (:-) だけは特別扱いしていて、 a :- xs を後で (a,[String]) の型に mapping する(:-ではないときは、 (a,[])に mapping する)
data Sample = Sample { key :: VarChar 20 :- &amp;#39;[&amp;#34;PRIMARY KEY&amp;#34;], -- 制約書きたいときは (:-) を使う name :: BigInt :- &amp;#39;[&amp;#34;NOT NULL&amp;#34;], single :: String } deriving (Eq, Show, Generic) -- レコードのフィールドは全て次の型クラスのインスタンスである必要がある -- SQLValuesはStringやIntなどのunion class SQLField a where fieldType :: a -&amp;gt; String encode :: a -&amp;gt; SQLValue decode :: SQLValue -&amp;gt; a MySQL で使う都合上、 VarChar (s :: Nat) や BigInt を定義しているがこれらはインスタンスを導出するためのただの newtype wrapper である(実体は Text や Int64 など)</description>
      </item>
    
      <item>
        <title>Pipeline Resolverを使ったAppSync Authorizerパターン</title>
        <link>https://myuon.github.io/posts/pipeline-resolver-authorizer/</link>
        <pubDate>Sun, 16 Jun 2019 14:26:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/pipeline-resolver-authorizer/</guid>
        <description>調べたけどあんまり情報がなかったので。
AppSync Pipeline Resolver AppSyncにはPipeline Resolverというリゾルバーがあり、これによって複数のリゾルバーを指定できる、とある。
CFnにはfunctionConfigurationを指定するといいよと書いてある。serverless-appsync-pluginだと次のように書ける。
custom:appSync:mappingTemplates:- type:Queryfield:testPipelineQueryrequest:&amp;#39;./mapping-templates/before.vtl&amp;#39;# the pipeline&amp;#39;s &amp;#34;before&amp;#34; mapping templateresponse:&amp;#39;./mapping-templates/after.vtl&amp;#39;# the pipeline&amp;#39;s &amp;#34;after&amp;#34; mapping templatekind:PIPELINEfunctions:- authorizeFunction- fetchDataFunctionfunctionConfigurations:- dataSource:graphqlLambdaname:&amp;#39;authorizeFunction&amp;#39;request:&amp;#39;./mapping-templates/authorize-request.vtl&amp;#39;response:&amp;#39;./mapping-templates/common-response.vtl&amp;#39;- dataSource:dataTablename:&amp;#39;fetchDataFunction&amp;#39;request:&amp;#39;./mapping-templates/fetchData.vtl&amp;#39;response:&amp;#39;./mapping-templates/common-response.vtl&amp;#39;でこれが意外とわかりにくいのだがドキュメントをよく読むと次のような意味であることがわかる。
 リゾルバーに対して指定できる処理の単位を&amp;quot;function&amp;quot;とここでは呼んでいる functionを複数指定すると、それぞれが順番に実行される functionには(通常のリゾルバー同様)リクエスト・レスポンスマッピングテンプレートを指定する 上記とは別に、pipelineの最初と最後にマッピングテンプレートを指定する DynamoDBリゾルバー、Lambdaリゾルバーも内部では1つの&amp;quot;functionからなる&amp;quot; Pipeline ResolverでLambdaに通してからDynamoDBに送るみたいなことをしたいなら2つのfunctionをlambda dataSource, dynamodb dataSourceを指定して作成する必要がある  で、上のような例だと次のように処理が進む
before mapping template ↓ authorizeFunction request mapping template ↓ authorizeFunction本体 ↓ authorizeFunction response mapping template ↓ fetchDataFunction request mapping template ↓ fetchDataFunction本体 ↓ fetchDataFunction response mapping template ↓ after mapping template functionという概念はpipeline resolverにしか出てこないが他のリゾルバーでも内部的には使われてるとみなして良いと思う。
Authorizer 上の例でもあるように、DyanmoDB Resolverにcustom authorizerを付けたいというようなユースケースではPipeline Resolverを使うのが良い。</description>
      </item>
    
      <item>
        <title>GHC Coreのパーサー書いてたけど諦めた</title>
        <link>https://myuon.github.io/posts/giving-up-core-parser/</link>
        <pubDate>Tue, 21 May 2019 23:25:02 +0900</pubDate>
        <guid>https://myuon.github.io/posts/giving-up-core-parser/</guid>
        <description>-ddump-simpl で出力されるSimplified Coreをいい感じに解析して読めるやつを作ろうかと思ってたけどつらすぎたので(少なくともこの方針では)やめた。
以下愚痴を述べますがこれは私が結構無理なことをやろうとしているだけでGHCに(そこまで)非はないと思うし直してくれという意味で言ってるわけでもない。いや直してくれるならありがたいんだけど。
様子 様子です
Coreに色がつき始めたぞ pic.twitter.com/M1SmAFgPOB
&amp;mdash; みょん (@myuon_myon) 2019年5月16日  CoreSyn CoreSynにCoreのSyntaxがある。ASTが用意されてて便利〜かと思いきや、これがなんとコンストラクタが公開されてないものがある(TypeとかCoercionとか)。
まずこの時点で嫌な予感がするよねという感じ。CoreSynは自作することになる。
PprCore -ddump-simplの出力フォーマットはPprCoreによって制御されている。中を読むとわかるがこれが実はASTとあまり対応がない。
ASTに乗ってない情報が付加されていたり、あるいはASTの情報が一部出力されてなかったりする。
そもそもPprCoreは何かしらの規則やdatatypeに則って書かれたものではなくdumpするという目的を果たすだけのために書かれている感じがありアドホックな処理が大量に入っている。どう考えてもこれに合わせてパーサーを書くとバージョンアップで即死である。
また、面倒な問題の一つにIdInfoがあり、Coreは次のように識別子に関する統計情報をコードに埋め込んで出してくれる。
foobar :: Type [GblId, Str=&amp;lt;S,U&amp;gt;, Unf=Unf{...なんやらかんやら, Guidance=ALWAYS_IF(arity=0,unsat_ok=True,boring_ok=True) Tmpl= piyo `cast` ..}] foobar = ... 当然こんなものを埋め込まれてもHaskellのコードとしてはvalidでないため、ここで専用のパーサーを書かなければいけないこともほぼ確定である。idinfoだけ剥がしてexpressionは組み込みのを使う手もあるがそれも後述の理由により多分上手く行かない。
また、上のCoreコードは実際にあるようなものであるが、他のフィールド間には区切りのカンマがあるのに Tmpl の前にはカンマがないことや Guidance だけなぜかHaskellのレコード構文と全然違う謎の構文になっているなど、不可解な点が多々ある。まぁ細かいことを気にしてはいけないのかもしれない。
識別子 ここまでで、パーサーとASTを自作することになった。Lexerはまぁなんとかなるだろうと期待したいところであるが、実はLexerですらGHC提供のものでは動かないことを見ていく。
(ちなみにGHCはGHC拡張をオンにするとParserどころかLexerもゴリゴリ挙動が変わるので結構すごいと思う。MagicHashとか典型例ですね。あとはCPP入れると複数行文字列リテラルを改行をエスケープすることで書けるようになるとか。変態的すぎると思う。)
識別子は主に $ 問題と # 問題の2つ？ある。
GHC Coreにはworker/wrapper変換という有名な最適化が入っているがこれにより新たに導入されるworkerには識別子の先頭に $w マークが付与される。ユーザー側で識別子に使えない文字を割り振ることで衝突等を回避してるんだろうか(しかしRenamerとかで上手く処理することも可能な気はする。そうでもないんだろうか)。しかしこれによりLexerが正しくtokenizeできなくなる(Module.$wfoobar は qualified operator Module.$ と varid foobar に分解される)。
次に、出現条件はよくわからないがラムダ式で束縛される変数等で、文字の途中に # 記号が付与されるものがある。 n#_a8qS みたいな。おそらく元々の変数 n に対してrenamerでuniqueな名前が振られた結果こういうコトになっているのだと思われる。これもGHCのLexerは(MagicHashを入れた状態で) n# と _a8qS としかtokenizeできない。</description>
      </item>
    
      <item>
        <title>Haskellで解くAtCoder</title>
        <link>https://myuon.github.io/posts/haskell-atcoder/</link>
        <pubDate>Sun, 28 Apr 2019 16:44:29 +0900</pubDate>
        <guid>https://myuon.github.io/posts/haskell-atcoder/</guid>
        <description>最近HaskellでAtCoderの問題を解いたりしているのでごく基本的な知見をまとめておく。
テクニック集 多くは割と色んな人がすでに言っていることではある。また、想定解法を正しく実装すれば以下のようなことを守らなくても時間内に収まるだろうが、GHCは最適化が効かなければ10倍遅くなる言語であるので普段から守っておくに越したことはないと思う。
 環境: AtCoderのGHCは2019.04現在7.10なので注意が必要。そのうち上がるかもしれないけど。  Strict拡張がない BangPatterns拡張はある 環境構築がhaskell-platformらしいのでそれに入ってるライブラリしか使えない   文字列  基本はData.ByteString.Chan8 Stringは死んでも使わない(遅いので) Unicode文字列の扱いが必要(今の所みたことないけど)とかならtextを使うといいかもしれない   リスト  リストは遅延リストをイテレータとして利用するだけに限るようにする(それでも全ての要素を走査するならVectorの方が大体速い(fromListのコストは除く)) 添字アクセスと結合は死んでもしない 遅延リストは作って即畳めば最適化によってコストは消えてなくなるので、そういう使い方ならあまり心配はしなくて良い(畳み込みはiループ目にi番目の要素にのみアクセスするように書くこと) 累積和はscan系を使うといいよ   Vector: 基本はData.Vector.Unboxed  BoxedなVectorを使ってサンクを不必要に消費しないコードを書くのは結構難しいのでUnboxedを使うほうが無難 push_backがないのが致命的 グラフの構築とかは困ると思うので事前に何かしら考えておいたほうがいいかも(2秒制限に引っかかるほどではないのであまり気にしなくても良いが) Vectorにはfusionがあるので、遅延リスト同様作って即畳めば最適化によってデータ生成のコストを消すことが出来る 便利なAPI: create, unfoldrN 注意すべきAPI: generate(Boxed Vectorの方は中の要素が遅延される), modify(呼ぶたびにコピーが取られる)   データ構造  その他のデータ構造にほとんど出番はない(Vectorで書けるならVectorで書いたほうが速いことがほとんど) Data.Set: priority queueの実装が面倒な場合 Data.Graph: グラフの構築やdfsが必要で、問題ごとに実装を考えたくない場合   再帰の実装  単なるループはfoldl&#39;, 早期リターンが必要ならfoldr 雑に再帰したいときはControl.Monad.Fix.fixを使っても良い Data.IORefなどはポインタ経由になるので遅い 関数の引数にするかStateを使うこと   GHC最適化系:  繰り返し適用される関数の引数は全てbang patternを付けておくのが安全(foldやscanの中、fixの中、手で書いた再帰関数等)(bang patternにより普通のコードが速くなることはないが、不要なサンクにより無意味に遅いコードは改善される) タプルは中の要素が遅延されるので、タプルを評価するときは全ての要素を個別に評価すること リストも中の要素が遅延されるが、中の要素を個別に評価するのは難しいのでそれが必要なときはUnboxed Vectorで書くのが最も安全 datatypeのフィールドも正格にしておくこと コピーを取らない値の計算は爆速になるのでなるべくコピーは取らない   パフォーマンス:  実行時間はC++やRustの2-5倍程度が目安(10倍以上遅いときは書き方が悪い) メモリ使用量も目安に(消費メモリ量を改善できれば自然に速くなることも)    入力  上にも書いたようにByteStringで読み込む 「n個の数値の読み出し」とかはVectorでササッと書く  例 例: a1 .</description>
      </item>
    
      <item>
        <title>newtype decoratorパターンとグラフィックスライブラリ</title>
        <link>https://myuon.github.io/posts/minilight-component/</link>
        <pubDate>Thu, 11 Apr 2019 20:30:21 +0900</pubDate>
        <guid>https://myuon.github.io/posts/minilight-component/</guid>
        <description>minilightというSDL2の上で動くグラフィックスライブラリを作っている。
前にも似たようなことをしており、フルスクラッチで作ったくせにそんなに変わらないという代物。
(別にFluxとかを目指しているわけではないので…まぁ偶然の一致というやつだな)
比較的簡単にコンポーネントが作れるようになったので、その紹介も兼ねて。
例: ボタン 例として押した回数が表示されるボタンを作ってみる。
https://github.com/myuon/minilight/blob/master/examples/button-counter.hs
コード自体はせいぜい30行程度で書けるので結構お手軽だと思う。
 以下がButton型の定義と生成関数。まあこれはいいでしょう。ちなみにminilightではライブラリ名に従ってMiniLightモナドが基本のモナドです。
data Button = Button { font :: SDL.Font.Font, counter :: Int } new :: MiniLight Button new = do font &amp;lt;- loadFont (FontDescriptor &amp;#34;IPAGothic&amp;#34; (FontStyle False False)) 22 return $ Button {font = font, counter = 0} 以下がボタンコンポーネントの定義。ComponentUnitのインスタンスを作れば良い。viewはfiguresで、イベントハンドラーはonSignalで、モデルの更新はupdateで、キャッシュの設定はuseCacheでそれぞれ行う。
instance ComponentUnit Button where update = return figures comp = do textTexture &amp;lt;- liftMiniLight $ text (font comp) (Vect.V4 255 255 255 255) $ if counter comp == 0 then &amp;#34;Click me!</description>
      </item>
    
      <item>
        <title>GHCのソースコードのノートを読むやつを作った</title>
        <link>https://myuon.github.io/posts/ghc-compiler-notes/</link>
        <pubDate>Thu, 04 Apr 2019 22:30:29 +0900</pubDate>
        <guid>https://myuon.github.io/posts/ghc-compiler-notes/</guid>
        <description>タイトルがふわっとしてるけど見れば多分わかる。
ghc-compiler-notes
経緯とか 注意: 作ったと書いてるが私の力ではなく主に水無さん(@mizunashi-mana)とわどさん(@waddlaw)のお力添えによるところが大きい。
GHCのソースコードにはNoteと称して有益な(GHCの内部実装等に関する)情報が書いてあることは有名だと思うけど、実際にそれはまとまったりはしてなかったので知る人ぞ知る、みたいな情報であった。こういう他のドキュメントには書いてないような貴重な情報が誰にも読まれることなく眠っているのはもったいないと常々感じていたのでそれを読めるようにしたかった。
このプロジェクトは最近GitLabに移った方のghc/ghcのソースコードに埋められているNotes部分を抜粋しそれを比較的読みやすい形で並べて整理したものである。
現在の仕様一覧(ざっくり)  compiler, libraries, utils以下にあるモジュールを再帰的に読んでドキュメントとして吐くようになっている ghc/ghcはデプロイのたびにクローンしているので、ドキュメントの参照元は比較的最近のmasterであることが期待される 各Noteに元ソースへのリンクあり (Noteのフォーマットがまともなら)箇条書き等にも対応 色々欠陥があるコードブロックの表示  中身(雰囲気) 実装は、checkoutしてきたソースコードの中身を辿ってコメントの該当箇所を抜き出してきて、reST形式てファイルに吐きreadthedocsに突っ込んでいるだけである。
ちなみにNoteの箇所を抜き出す実装は私は完全にノータッチで上に上げたお二人がやってくれたので詳しいことはよくわかりません。
ちなみにこのNoteは書かれている場所によりフォーマットがまちまちで、Noteのタイトル表からコメントの形式や箇条書きの形式、コードブロックの指定の仕方に至るまで全く統一されていないという荒れっぷりなので実装は大変だったと思う。
今後の課題等  コードブロックはfalse positiveとfalse negativeだらけなので流石になんとかしたい(しかしフォーマットが統一されてなさすぎてかなり厳しい) 文章中の他のノートへのリンクをちゃんとリンクとして辿れるようにしたい masterだけでなくて特定のタグがついたghcのバージョン等をスナップショットとして見られるようにしたい  CIについて このプロジェクトで主に私が頑張ったところがCIだったのでCIを少しだけ解説。
CIはCircleCIを使っている。プロジェクト自体のビルドはcabalでもstackでも出来るが、Haskell公式のdocker imageがcabalとghcが入ったやつなのでそれを使っている。多分docker imageは次のいずれかを使うと良い。
 haskell: 7.8, 7.10, 8.0, 8.2, 8.4, 8.6などがある fpco/haskell: GHC8.0.2版のみ。stackなので他のものはインストールすればよいというのは確かにそうだが…  公式のはまだ8.6.4がリリースされてないみたいなので必要であればこれを見ると良い。
また、CircleCIであればhaskell-buildというorbが用意されているので、単にビルドするだけならこれが簡単で良いと思う。
ビルドコマンド キャッシュは、今のところは cabal new-update してからindex.cacheのchecksumをみて ~/.cabal を丸ごとキャッシュしている。よくわかってないんだけどこれで大丈夫なの？
あと、以後のjobでも使うので dist-newstyle もworkspaceに放り込んでる。
何かの参考になれば。
build-test-8_6_3:working_directory:~/workspacedocker:- image:haskell:8.6.3steps:- checkout- run:cabal new-update- restore_cache:keys:- cabal-index-{{ checksum &amp;#34;~/.cabal/packages/hackage.haskell.org/01-index.cache&amp;#34; }}-v1- run:make build- run:make test- save_cache:key:cabal-index-{{ checksum &amp;#34;~/.</description>
      </item>
    
      <item>
        <title>パストレーシングについて調べてる</title>
        <link>https://myuon.github.io/posts/survey-ray-tracing/</link>
        <pubDate>Sun, 03 Mar 2019 19:33:25 +0900</pubDate>
        <guid>https://myuon.github.io/posts/survey-ray-tracing/</guid>
        <description>前に入門記事を書いてそこから色々調べたりしてたのでその備忘録として
アルゴリズムについて カメラから出たレイをたどりながら光線のシミュレーションを行う単純なアルゴリズムをレイトレーシングと言って、それを確率的な計算によってオブジェクトの数に依らない計算量で計算できるように改良したものをパストレーシングと呼ぶらしい(正確な定義はよくわからなかったがアルゴリズムの差から名前が違うみたい)。
アルゴリズムの詳細については次とかを見るとよさそう。
 memoRANDOM 物理ベースレンダラ edupt解説  パストレーシングアルゴリズムの初出は&amp;quot;The rendering equation (J. Kajiya, 1986)&amp;ldquo;か？
bidirectional, NEE, metropolis light transport, photon mappingあたりは実装してみたいがお勉強が先かも。
NEE (Next Event Estimation) 悩みとして、memoRANDOMさんのサイトに載ってる通りに、3点のレンダリング方程式をベースにしたNEEを実装してみたけど寄与が小さすぎて全然効果がなかった。単に実装を間違えているだけか？
また、調べているとshadow rayを蓄積したあと反射を行い、そっちで同じ光源に向けてexplicitなrayが飛んだとしたら無視するみたいなアルゴリズムでNEEを計算しているサイトも見かけたけど、それは何か違いがあるのだろうかと思った。NEEの正しいアルゴリズムがよくわからない。(というか、本当はちゃんと平均とかを計算してどういうアルゴリズムなら正しい結果が得られるかは手で確認すべきかなと思う)
Stratified Sampling 層化サンプリングによってサンプルの座標がいい感じに均等にばらけるようにとるといいらしい。これってどれくらいの改善になるのだろうか、気になる。
 Stratified Sampling of Spherical Triangles  GPU どうせならGPU使った計算もしたい。GPUでレイトレーシングやるみたいな話は調べると色々出てくる。
疑問としてロシアンルーレットとかの実装だと分岐が入る(というかレイごとの計算回数が見積もれない)わけだけどその辺はどうするのだろうか。調べた感じだと1レイ1スレッドにするのが普通っぽかったのと、ロシアンルーレットのときにどうするかみたいな話は出てこなかったので、計算を打ち切る代わりに寄与を0にするみたいな感じで並列処理を止めないように作っているのかもしれない。
そもそもシェーダー言語とかCUDAとかにパストレーシングアルゴリズムをナイーブに突っ込んでるのとかよく見るんだけど本当にそんなんでいいの？という気持ちになったりならんかったりする。
 Path tracing on GPU  Unity Unity(のComputeShaderなんか)を使うとGPUを使った計算が簡単にできる。要は単にHLSL(これはWindowsだから？)とのintegrationがUnityに用意されているというだけのことだけど、Unityは普通に解説も多いしGPUを使ったレイトレーシングの入門にはいいかもしれない。
 GPU Ray Tracing in Unity – Part 1  例えば次のような画像が割と簡単に出せる。
なるほど pic.twitter.com/vgvv8ohDdk
&amp;mdash; みょん (@myuon_myon) 2019年3月3日  WebGL 人間に見せるUIとしてWebGLにして吐くのは結構ありかもしれないと思っていた。WebGLはRustを使っても吐けるみたいだった(けど中身は普通にshader言語書いてたのでRustで書けるとは言わない気もする)。</description>
      </item>
    
      <item>
        <title>DynamoDB LocalをTerraformから使う</title>
        <link>https://myuon.github.io/posts/dynanmodb-local-terraform/</link>
        <pubDate>Mon, 11 Feb 2019 00:22:05 +0900</pubDate>
        <guid>https://myuon.github.io/posts/dynanmodb-local-terraform/</guid>
        <description>タイトルの通り。大体以下のPRの説明読めば分かる。
https://github.com/hashicorp/terraform/pull/2825
Terraform側の設定 local envで環境を作ってDynamoDB Localをテスト用途で動かすという前提。以下がproject structure。
&amp;lt;project root&amp;gt; - infrastructure - local/ - main.tf ここにDynamoDB Localの設定を入れる - modules/ - dynamodb/table.tf ここにテーブルの設定など infrastructure/local/main.tfでは、endpointsを指定することができる。(デプロイ時にこのendpointを参照してテーブルを作ったりする)
provider &amp;quot;aws&amp;quot; { region = &amp;quot;ap-northeast-1&amp;quot; endpoints { dynamodb = &amp;quot;http://localhost:8000&amp;quot; } } DynamoDB Localは普通に動かせばよい。
port:8000で起動させたら、いつも通りterraform -e dev applyでDynamoDB Localにテーブルができる。
スクリプト テストで使おうと思ったら、このDynamoDB Localを立ち上げる→terraform apply→テスト実行→DynamoDB Localを落とすを何度も繰り返すことになって面倒なので、私はMakefileを書いている。
install: mkdir -p ./infrastructure/local/.dynamodb cd ./infrastructure/local/.dynamodb; \ 	wget https://s3-ap-northeast-1.amazonaws.com/dynamodb-local-tokyo/dynamodb_local_latest.tar.gz; \ 	tar -xf ./dynamodb_local_latest.tar.gz test: $(MAKE) startTest # ここでテスト export ...; \ 	go test .</description>
      </item>
    
      <item>
        <title>定理証明リンク集</title>
        <link>https://myuon.github.io/posts/start-learning-proof-assistant/</link>
        <pubDate>Sun, 06 Jan 2019 15:46:06 +0900</pubDate>
        <guid>https://myuon.github.io/posts/start-learning-proof-assistant/</guid>
        <description>定理証明、特に定理証明支援系(Proof Assistant)はその存在こそ少しずつ浸透しつつあるような気がしないでもないけれど資料とか全然まとまってないのが不便だなと前々から思っていたのでリソースをまとめておきます。
これも追加してほしいみたいなのあったら教えてください。
Proof Assistants 始めるなら次の中から選ぶのがよいと思います。
 Coq  Calculus of constructionsベースの型システムとリッチなコマンドを備えた言語 このリストの中では最もコミュニティが大きい、入門書等も豊富 型システムと項を書くためのGallina, コンパイラへの命令を記述するためのVernacular, タクティクスの定義に使うLtacなどの言語が混ざって出てくるのが初心者には混乱必至 結構複雑な言語なので使いこなすのはそれなりに大変   Agda  Martin-Löf type theoryベースの言語 Coqと違ってコマンド等はとても貧弱だが言語が薄いので中の仕組みが分かりやすい、依存型の勉強にはもってこい 実践的に使おうとするとパフォーマンスが悪いのがネック モジュール分割や証明のスキップみたいな面白くないところに時間を取られる可能性あり   Idris  Agdaに似た感じの言語 この中では唯一純粋なプログラミング言語として使用可能(runtimeがあって実行可能コードを吐ける)だが実際に動かして使うにはまだまだという感じ Agdaよりはサポートが多く証明が書きやすいはず(未検証なので嘘かも)   Lean  この中では後発、CoqやAgdaに似ており、Agdaよりは書きやすくリッチでCoqよりは薄くて簡単 数年前にメジャーバージョンが2から3に上がりそこで多少の断絶があるらしい 機能網羅的なリファレンスがまだ用意されてないらしいのでCoqやAgdaの知識がないと使いこなすのは難しいかもしれない   Isabelle  この中では唯一Curry-Howardをベースとしない形式証明(依存型もない) 豊富なライブラリと強力なproverによる自動証明が魅力 「普通の」数学をやりたいならこれがおすすめ 公式のリファレンスはあるが機能は膨大、非公式ドキュメントも少ないので習得は骨が折れるかも    入門書等 出版されていてもドラフト版のpdfが無料で読めるものが多い
 Software Foundations: Coqを使用しプログラム意味論的な話題が中心。Coqの説明ばかりというわけではないので他言語ユーザーでも読めると思われる。 Software Foundations in Idris: Software FoundationsのIdris版 Concrete Semantics: Isabelle/HOLを使用しこちらもプログラム意味論系の証明を行う本。前半はIsabelleの説明で後半はコンピューターサイエンスという構成。 Certified Programming with Dependent Types: Coqで依存型を学べる本。Coqに限らず定理証明で幅広く使える話が書いてあるので非Coqユーザーでもおすすめ。 Verified Functional Programming in Agda: Agdaの本、読んでないので詳細知らず Coq&amp;rsquo;Art: Coqの定評のある入門書、詳細は知らない Coq/SSReflect/MathCompによる定理証明: 日本語(！)で書かれたCoqの入門書  入門記事等 読み物もあり</description>
      </item>
    
      <item>
        <title>レイトレーシングに入門した</title>
        <link>https://myuon.github.io/posts/start-ray-tracing/</link>
        <pubDate>Sun, 06 Jan 2019 13:34:10 +0900</pubDate>
        <guid>https://myuon.github.io/posts/start-ray-tracing/</guid>
        <description>レイトレ自体は前から興味あったんだけど年末年始でいよいよ真面目に入門し始めました(今後も続けるかは不明)。
Ray tracing in one weekendシリーズを読んでこの3冊分の実装をRustで書きました。 本に沿って実装したのでレイトレーサーとして使えるような感じにはなってない(再利用性がなさすぎるところがちょいちょいある)。
 Ray Tracing Minibooks (3 Book Series) リポジトリ  スクショ 個人的にお気に入りのやつをいくつか貼っておきます
今後やりたいこととか 本では純粋なCPU実装で最適化とかもそこまで(3冊目の後半はやるけど)だったので、まぁその辺かなー。SIMDとか使って高速化するのはできそうなのと、GPUを使ったちゃんとした高速レイトレみたいなのもちょっとやってみたい(そこまでそっちに傾倒する気はないしガリガリチューニングしたり最適化テク実装というよりは、もっと綺麗な絵を高速にレンダリングしたい)。
レイトレにも色々なテクがあるようで(bidirectionalなんとかとかmetropolisなんとかとか)、その辺によっても得意なシチュエーションが変わってくるみたいなので色々実装して遊べたりしたら面白そうだなーと思う。
アルゴリズムの詳細については以下のスライドが詳しくてしかも超面白かった。
 </description>
      </item>
    
      <item>
        <title>2018年を振り返って</title>
        <link>https://myuon.github.io/posts/sumup-2018/</link>
        <pubDate>Sat, 29 Dec 2018 19:06:59 +0900</pubDate>
        <guid>https://myuon.github.io/posts/sumup-2018/</guid>
        <description>2018年総括記事です。
まだ29日で年内やろうと思ってることがそれなりにある状態で書くのもどうなんだと思いつつ書く。
GitHubの草カレンダー  1020 contributionsだったようです。それなりに頑張っている感じは出てますね。あと2-3月と11-12月くらいにプログラミングをいっぱいしてたっぽい。
1月 ｼｭﾛﾝで忙しかったので正直進捗どころではなかった。まぁなんとかなってよかった。
2-3月 手を付けたもの
 madder: 動画編集ソフト nott: type theoryについてのまとめ Semantics of Programming Language(SoPL)セミナー  動画編集ソフトやろうと思ってRustを始めGTK+とGstreamerのことを調べ始めた。のちにGTK+はElectronに変更される。Gstreamerが意味不明すぎて動画とか音声は結構闇が深いと思った。なお今でもよくわからないことが多すぎる。
nottはｼｭﾛﾝの名残でなんかしたかったのだと思う。結局SoPLを読むことになってそれから半年くらいはテキスト読む方に集中しててあんまり計算機科学の勉強とかできてないので進んでない。またやらなきゃ。
SoPLセミナーも3月くらいに人を集めて4月から本格始動みたいな感じだった。12月現在でおよそ7割くらいのところまでセミナーが進んでおり、割とかったるいdomain theoryとかの話も合ってそこそこ重い内容の割にはちゃんと進んでて偉いなと思ったりした。
あと引っ越しというか一人暮らしを始めた。
4-5月 手を付けたもの
 dockerとか触ってたような ｳｪｯﾌﾞ技術の勉強とかしてた  4月からなんとｼｬｶｲｼﾞﾝになり働き始めた。夏くらいまでは研修やってて研修はまぁ虚無だったんだけど比較的自由な時間もあったのでJavaの話を調べたりdockerについて調べたりDBについて調べたりMDNをおもむろに読んだりしていた。
6月-7月 手を付けたもの
 refluxive fantia登録も確かこの辺 夕暮寝子プロジェクト (juniQ, Live2D)  refluxiveというFluxベースのHaskellグラフィックスフレームワークを作ってた記憶。なんか型がごちゃっとしてきてアレだなと思って放置されてるけどもうちょっとスッキリするようにちゃんと書き直してみようかな。
それとこの辺で人格が一つ増えて夕暮寝子プロジェクトが発足したりした。受肉システムを作ったりLive2Dのモデルを必死に作ったりした気がする。ていうか早くコンテンツを作れって感じですねわかる～。
8月 お仕事でAWSを使うので、ということで8月くらいから本格的にAWSの勉強を始めた気がする。まだ4ヵ月くらいしか触ってないけどかなり色んな事も身に付いたと思うし、何よりやっぱAWSのマネージドサービス本当にすごいなと思うことばかりだった。関係ないけど来年はNeptuneとかAppSyncとかLightSailとかFirehoseあたりのサービスも使ってみたいなーとか。
9-10月 Haskellでなんかしようと思って久々にAtCoderの過去問を解いたりProject Eulerの過去問を解いたりブログ記事らしきものを作ったり色々してた気がする。あまり記憶がない。
あとこういうのは短い期間でどうにかなるようなものではない。じっくりコツコツやることの大切さよという感じ。
11-12月 AWSでちょっと色々サービスを作ってみようということで色々やっていってる。まだリリースには程遠いので紹介はしない。DynamoDBとCognitoが特に分かりにくくて触ってみないとマジで身につかないなこれって思ったりしていた。
あとお絵描きもこの2ヵ月くらいはちょっと多めにしてたような。
総括 コツコツやることの大切さ(というか偉大さ)を身に染みて感じる1年だった。自分はバフスキルかけるより敵を殴る方が好きなんだけどバフスキルの偉大さを知った感じだった。
今年はイレギュラーな(環境が変わったり)ことが多くて趣味の作業とかにも支障が出そうと思っていたけど特にそんなことはなく例年通り好き放題やってたと思う。来年もペースを落とさず進捗しまくるぞい。
そういえば去年の振り返り記事で、「もっとブログ書きたい」みたいなことを言ってるけど今年は結構書いてたんじゃないかな。ブログメンテナンスがあったり移行作業に手間取ったりで運用がつらくて書けなかった時期とかもあったけど思ったことはちゃんと文章化できてると思う。多分ね。
来年の抱負 最強になること。これ今年の抱負と一緒だな。</description>
      </item>
    
      <item>
        <title>バーチャル美少女定理証明士を支える技術</title>
        <link>https://myuon.github.io/posts/juniq/</link>
        <pubDate>Tue, 25 Dec 2018 20:25:54 +0900</pubDate>
        <guid>https://myuon.github.io/posts/juniq/</guid>
        <description>この記事とは特に関係ないのですがVTuber Techアドベントカレンダー(その1 その2)があるらしいので興味がある人は覗いてみるといいんじゃないでしょうか。
バーチャル引きこもり病弱定理証明士 夕暮寝子というのがいて、その子の裏側のシステムを作ったので(作ったのはだいぶ前)その解説をします。なお問題は山積みの模様(そもそも私以外の人が使う想定じゃないので自分でいじるなりなんなりしてください)。
技術スタック: Docker, Python, TypeScript, dlib (Python bindings), OpenCVちょこっと, Live2D SDK
💞はじめまして💞
🎊夕暮寝子といいます🎊
😴電脳空間で引きこもりをやっています😴
💻プログラムとか証明とかを書きます💻
💪Live2D動かすやつ作ってるのでそれができたらデビューします💪
👏よろしくお願いします👏#Vtuber準備中#Vtuber始めました#新人Vtuber#Vtuber pic.twitter.com/UAM9iTrFLU
&amp;mdash; 夕暮寝子 (@YugureNeko) 2018年7月24日  リポジトリ コードは全部公開しています。
https://github.com/myuon/juniQ
免責事項
このプログラム群はMITライセンスで公開しています(リポジトリにsubmoduleとして含まれるcubism-jsには当たり前ですがこのライセンスは適用されません)。
このソフトウェアはLive2D SDK for webを利用しており、ソースコードの公開及びブログにおけるコードの解説はLive2Dから許可を得て行っています。
このソフトウェアを利用して作られたものを出版(コードの一部または全部を公開することも含まれるようです)する場合にはLive2Dとの契約が必要になる場合があるのでその辺はちゃんと問い合わせてください。
Live2D SDKリリースライセンス: https://www.live2d.com/ja/products/releaselicense
(これ読む限りだとソースコードの一部を公開するだけでも出版にあたるかもみたいな書き方だったけど問い合わせたらソースコードの公開だけなら契約不要って言われたので割とLive2D側に判断の裁量がありそうです。まぁなんかやりたくなったらとりあえず聞いてみるのがよさそうな感じだった。)
アーキテクチャ 次のような仕組みで動きます
 ブラウザからカメラ映像を取得、websocketサーバーに画像を30fpsで投げる サーバーが画像を受け取って顔の検出等を行いパラメータを計算する 計算されたパラメータがブラウザのviewerに再度投げ返される viewerはLive2Dモデルを描画  なんでやねん なんやねんこれと思うと思うんですがこれはホストPCがWindowsでありWindowsで開発はできないことと、VirtualBoxではUSBの映像出力等を直接受け取れない等の技術的制約により悲しくも厳しい設計になっています。
やーまじ全部Unityかなんかで作ればよかったーって後になって後悔したんですがしかしdlibとかのライブラリがUnityのアセットストアだとまともそうなやつはすごく高くていやいやみたいな気持ちになったりしたのはある。Unityネイティブプラグインで頑張って作り直したいけどつらそう。
あとクライアントからサーバーに直接映像を投げるのって意外と難しくて(browser to browserだとそれっぽい技術は意外とあるんだけど…)あんま選択肢がないし、そもそも検出とかの関係で絶対画像を切り出す必要があるのでまぁブラウザで切って送ればいいんじゃないかみたいになっておる。当然この処理は割と負荷かかるのでうんまぁみたいな感じ。
あとCORSの設定がこれを作ったときはよくわかってなかったのでFirefoxでしか多分動かないです。そのうちFirefoxでも動かなくなる可能性がある。
映像取得部分 映像と音声を取得する。getUserMediaとかを使うとできる。映像は30fpsくらいに落としてwebsocketサーバーにjpeg画像として投げつける。音声はリップシンクのために使う。
リップシンク作るところだけ載せます。
// https://github.com/myuon/juniQ/blob/master/viewer/src/index.ts#L42 class AudioVolume { processor: ScriptProcessorNode; volume: number; clipLevel: number; averaging: number; clipping: boolean; lastClip: number; clipLag: number; constructor(audioContext: AudioContext, clipLevel = 0.</description>
      </item>
    
      <item>
        <title>実装詳細テスト要るのか問題(反語)</title>
        <link>https://myuon.github.io/posts/goodbye-to-impl-tests/</link>
        <pubDate>Mon, 24 Dec 2018 14:25:05 +0900</pubDate>
        <guid>https://myuon.github.io/posts/goodbye-to-impl-tests/</guid>
        <description>備忘録です。
テストとは書きたいけど書きたくないという大変アンビバレントな状態に人間を置く深淵の魔物。
テストの分け方についても色々な指標があるけどここでは便宜上「実装詳細テスト」「サービステスト」「E2Eテスト」の3つにわけて説明をします。
テストとは 実装詳細テスト: 書いた実装に依存するテスト。ある関数にこういう入力をしたらこういう出力が返ってきますよ～みたいなやつ。アプリケーションの他の部分に依存せずその関数とテストを別の場所にもっていっても動くが、実装を変更するとテストも変更が必要になる。
E2Eテスト: エンドユーザーが行う操作と同じ操作を行い期待した入力に対して期待した出力が返るかを調べるテスト。本番または本番と同じに作られたデプロイされた環境を使うもの。
サービステスト: それ以外(雑)。もっと言うと、「書いた実装になるべく依存せず、実装を変えても動き続ける」「他のサービスやシステムに依存しない、基本的にインターネットへのアクセスも行わない(ローカルサーバーは可)」の2つを備えたテスト。
実際にはエンドユーザーと同じ操作を行うテストなんだけど裏側がスタブになってて本番環境にアクセスしないみたいな中途半端なやつもあると思うけど一応こういう分け方にしてみる。
実装詳細テスト要るのか E2Eテストがつらく厳しく基本的に誰も書きたくないというところはまぁ人類の合意なのではと思っている。当然書かないわけにはいかなくてしょうがなく書いてる人はいっぱいいると思うけど。
問題は実装詳細テストの方でこれが要るのかという話。これはアプリケーションの性質とかにもよるので一概には言えないけど通常のアプリケーションやサービスなら不要なのではと思う。そもそも「常にsemanticsを考えよ」という設計の金科玉条(これは私が勝手に言ってることだけど)からすると、アプリケーションの中で定義された関数のふるまいはアプリケーションのsemanticsなどでは決してないのでそんなものをテストする必要はないでしょという感じ。あるいは実装詳細テストを書きすぎると機能追加や修正でテストの変更が必要になって逆にテストが開発を妨げてしまったりして逆効果になることさえある。そもそも我々はサービス開発等で忙しくちまちまテストを書いている余裕などないので実装詳細をチェックする必要などないのだ(逃げ)。
サービステストはもちろん書く。というかこれがすべて。そこまで難しくない世のほとんどのプログラムならサービステストをsemanticsに乗っ取って書くだけでカバレッジ100%にできると思う。
実装詳細テスト要らないのか じゃあ実装詳細テスト書いちゃだめかというとそうではないです。普通に必要になることもある。
 ライブラリとして切り出す場合: ライブラリはそこでexportされる関数がsemanticsになるので今度そのテストはむしろ書いてくださいとなる。同じプログラムでも使われ方によって意味が変わってくるのでしょうがない。 スタブとかの都合: サービステストは通常複数のモジュールをまたがるのでローカルサーバーとかでテストできるのが一番良いのだけど使ってるSDKの都合とかでそういうテストが書きにくいのでこの画面のテストだけは実装詳細でやりますみたいなのはアリだと思う(というかしょうがない) 実装が非自明な場合: 何かの方程式を超多ステップで解くとか複雑なアルゴリズムを手書きするとか まぁ実装が非自明な場合はやった方がいいですね 当たり前や  ｳｪｯﾌﾞｻｰﾋﾞｽの構成 今こういう感じでやっておる
 サーバーサイド  SDK: サーバーサイドが提供するAPIをたたくだけのSDKを用意する; クライアントサイドで読み込んで使う サーバーサイドのコード サービステスト: SDKに対するテストをがりがり書く (必要があればモジュールごとに)実装詳細テスト   クライアントサイド  (必要があればコンポーネント/画面ごとに)Viewの詳細テスト    ひとまず困ってない。あとテストはやっぱり書きたくない。
semantics、意識していこうな</description>
      </item>
    
      <item>
        <title>OGP画像の埋め込みを実装したい(しない)</title>
        <link>https://myuon.github.io/posts/implement-ogp-expansion/</link>
        <pubDate>Fri, 14 Dec 2018 23:51:25 +0900</pubDate>
        <guid>https://myuon.github.io/posts/implement-ogp-expansion/</guid>
        <description>OGP画像というのがあって、ついったーとかﾌｪｰｽﾌﾞｯｸとかでURLを貼るとリンク先のページの説明文と画像が表示されるみたいなやつがあると思うんだけどそういうアレ。
URLを貼ると自分のサイトにアレを動的に埋め込めるようにしたいというのが目標。
まぁあんなん「クライアントサイドでちょちょっとやったらできるやろ～ｗ」と思ってたんだけどどうもそんな簡単ではないことに最近気が付いたので記事に書いてみた。
(なお実装はしてない、めんどすぎる)
(知ってる人にはすごい当たり前の話だと思うけど調べてもあんまりヒットしなかったので)
なぜクライアントサイドだけでは無理か OGP画像は各サイトのmetaタグの該当箇所を引っ張ってくることにより得られるが、そもそもJavaScriptで別のサイトにアクセスしてその結果で何かをしようとすると確実にCORS(Cross-Origin Resource Sharing)にひっかかる。ひっかからないブラウザもあるかもしれないけどモダンなブラウザならほぼ間違いなくひっかかる。
もしかしたらHTML自体にAllow-Origin: *みたいなことをしているサーバーも世の中にはあるかもしれないけど普通はやる意味がないのでまぁしょうがないね。
サーバーサイドレンダリング ということでサーバーサイドにAPIを1つ用意してURLを投げるとその先のHTMLをとってきてmetaタグからCORS画像と説明文を引っ張ってくる処理を行うことにする。
これで実装終わりかと思いきやこれをそのままページに埋め込むと、ページの画像ソースURLがよそ様のものになる。いわゆる直リンクという古のインターネッツで超嫌われたアレに該当し、まぁ嫌われるだけならまだしも、自分のサイトがそれなりに人気サイトになったりするとそこから大量のリクエストが埋め込み先のサーバーに飛ぶので量によってはBANされたりしそうだなという感じになる。
TwitterにせよFacebookにせよ、URLを投稿するとタイムラインを開いているフォロワーが一斉にそのURLにリクエストを飛ばすのは当然良くないでしょう。そういうわけで画像はキャッシュしましょうという話になってくる。
キャッシュクリア さてキャッシュサーバーを用意して画像はいったん自前のところでキャッシュしてそれを参照するようにした。これでめでたしかと思いきやまだめんどい問題があって、キャッシュはあくまでキャッシュなのでクリアするという仕組みを用意しなければ、OGP画像をサイト管理者が変えても古い画像が残り続けたり前の説明文が残り続けたりする。これはあまりよいことではないだろう。
FacebookでもOGPキャッシュが残り続けるのが問題になってキャッシュクリア用のボタンが実装されたりしてたらしい。Twitterは一定時間でキャッシュがリロードされてたような気がする？(これは嘘かもしれない)
最適化 みんながどうやってるのかは知らないが、上の機能を全部やったとして、でもまぁ冷静に考えてすべてのURLに対して画像をキャッシュするのは少し無駄が多いような気がするだろう。
OGP画像はサイト全体で使いまわされたりすることも多い(ページごとに変えているマメなブログ更新者もいるので全員ではない)ので、OGP画像のURLをキーにキャッシュを使いまわすことで画像をとってくる手間とキャッシュサーバーのリソースを最適化したいような気がする(しかし実際はそこまでする必要があるのかは不明 あんま変わんないような気もするけど)。
みんなどうしてるんだろ みなさんどうやってるんですかね
このサイトは このサイトはトップページのアイコン的なやつを前にOGP画像に設定してたけどテーマ変えた時に設定が飛びました。そのうち対応します(めんどいからやってない)。</description>
      </item>
    
      <item>
        <title>Firebaseを始めてみた</title>
        <link>https://myuon.github.io/posts/get-started-with-firebase/</link>
        <pubDate>Thu, 13 Dec 2018 00:05:37 +0900</pubDate>
        <guid>https://myuon.github.io/posts/get-started-with-firebase/</guid>
        <description>Firebaseがすごい話 今までAWSのサービス(サーバーレス中心・LambdaとかDynamoDBとかAPI Gatewayとか)は結構触ってたけどGCP系はノータッチだったので一時期超流行ってた(少し前になんかやたらブログ記事とかが量産されていた時期があったように思うんだけどあれは何だったんだ…)firebaseをこの際触ってみることにした。
Cloud Firestoreとかいう無敵のDB Cloud Firestoreというまだベータ版だけどFirebaseもイチオシっぽいDBがある。こいつは特にDynamoDBを知ってるとそれに比べても無敵だなと思う。個人的すごいポイント:
 Collection/Documentという分かりやすさ(Partition KeyだのSort Keyだのといった面倒さがない) やたら複雑なベストプラクティスとかもない インデックスが自動でいっぱい貼られる！GSIの制限とかもない！ read/write/deleteの完全リクエスト回数課金という分かりやすさ(あっちもon-demand capacity来ましたが) コンソールから触るのも簡単・分かりやすい rulesによる超細かい権限管理(これはmBaaSだからできないとまぁ困るけど) DynamoDB Stream的な機能もくっついてる Paginationとかにも対応してる emulatorも来た(DynamoDBもdynamodb-localあるよ！)  Firebaseの便利さ Firebaseは認証・FaaS・DB・ストレージあたりが全部オールインワンで全部そろっておりエコシステムがとても強くてよい。どこぞのAmplifyも見習ってほしい(re:Invent2018を見る限り力入れてる感はあった)。クライアントサイドだけですべてを完結させるぞという強さがありやーすごいって感じだった。
GCPもそうだけどGoogleのサービスは分かりやすさと欲しいものが大体そろってる感じが強いと思う。よく考えられてるしサービスの質が本当に高いなと思ったりあれこれ。
Firebaseをやめたいって話 とべた褒めなんですがしばらく書いてFirebaseやめるかーってなった。
 早く東京リージョンに来てくれ (これが一番大きい; Firestoreとかレイテンシが400-500msとかで正直使い物にならない。ページ表示に1秒もかかるサービスを使うほど暇なユーザーもそういないよ！) 地味に高い、というかAWSが安すぎるのでそれに比べるとちょっとお高く感じるのはある。DynamoDBとかおかしいんじゃないかというくらい安いのでまぁね。 あとAppSync使いたかった これは完全な趣味だけど、AppSyncずっと使いたいと思ってたのでせっかくだしこの機会にと思って 正直mBaaSがとてつもなく向いてるようなユースケースではなかったというところが大きい までもFirebaseの勉強になったので良いとしましょう  メインの理由としてはパフォーマンスとコストが大きかった(と言ってもFirebaseは無料枠もあるのでコストはそこまで大きな差はないと思う)。GCPはいい感じのやつを用意しときました！みたいなサービスが多くて、AWSは本当に特定の用途のためだけのサービスを作っといたから設計は自分で考えろやみたいな投げ方してくるのが多いイメージ。AWSの方がめんどいけどちゃんと組むとカリカリにチューニングされたプログラムのごとく本当に安く早くで組めるというイメージはありますね。めんどいけど。
個人でちょこっと使う分にはFirebaseとても良いと思うので、またなんかあったら使いたい。</description>
      </item>
    
      <item>
        <title>Lambda FunctionをReasonで書く</title>
        <link>https://myuon.github.io/posts/serverless-reason/</link>
        <pubDate>Fri, 23 Nov 2018 21:00:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/serverless-reason/</guid>
        <description>Reason ML、やっていこうな 世はまさに大サーバーレス時代なのでLambda Functionやっていきというお気持ち。
AWS Lambdaで現時点(2018年11月)で対応されている言語はNode.js, Python, Go, C#(dotnet), Javaの5つ。このうち後ろ2つはコールドスタートが激遅なので使い物にならない。で前3つのうちではドキュメントの多いNode.jsが安定ですが、Node.jsをランタイムに採用するとしてしかしJSは書きたくない、そういうときにReason MLはいい感じな選択肢なのでは？というのがこの記事の趣旨です。
serverless-reason serverless frameworkというサーバーレスアプリをやるのにとても便利なツールがあって、それのReasonで動くテンプレートを作っておいたので好きに使ってくださいという感じ。
  以下このプロジェクトの中身の解説をする。
echo.re Lambda Functionとしてechoというものがsrc/functions/echo.reに定義されている。
/* Sorry I&amp;#39;m a lazy person! */ type event = { . &amp;#34;pathParameters&amp;#34;: Js.Dict.t(string), }; type context = unit; type callback = (. Js.null(string), Js.Json.t) =&amp;gt; Js.Promise.t(unit); type response = { . &amp;#34;statusCode&amp;#34;: int, &amp;#34;body&amp;#34;: string, }; let handler : (event, context, callback) =&amp;gt; Js.Promise.t(response) = (event, _, _) =&amp;gt; { Js.</description>
      </item>
    
      <item>
        <title>はじめようReason ML</title>
        <link>https://myuon.github.io/posts/start-reasonml/</link>
        <pubDate>Sat, 10 Nov 2018 00:24:20 +0900</pubDate>
        <guid>https://myuon.github.io/posts/start-reasonml/</guid>
        <description>はじめに Reason MLを最近始めました。よき。
Reason MLとは Reason MLとはOCamlにインスパイアされたAltJSの一種。見た目は型の付いたJSみたいな感じだけど実際はJSのsyntaxに寄せたML。
BuckleScriptというコンパイラ(この名前もどうなんという感じだけど)を使ってJSに変える。BuckleScriptはReason MLとOCamlをJSに変換するコンパイラであり、Reason MLとOCamlのいずれのsyntaxも混ぜて使うことができるっぽい。便利～。
実際に使うときはBuckleScriptの方のドキュメントもちゃんと読んでおく必要がある(似たような見た目のページだけど内容は違う)。BuckleScriptにはコンパイラ拡張みたいなものが載っておりそれを上手く使うことで生成されるJSを制御したりJS側の関数を読み込んだりするのでこの辺も割と必須。
 https://reasonml.github.io/en/ Reason MLの言語リファレンス https://bucklescript.github.io/en/ BuckleScriptリファレンス https://bucklescript.github.io/bucklescript/api/index.html BuckleScript標準ライブラリ(Reason MLも同じものがportされてる)  よさ  まともな型が付く(OCamlの型システム、世界で一番分かりやすいみたいなところがある) 生成されるJSがまとも ドキュメントが割とそろってる JSとのブリッジが簡単(基本的に何もしなくてもできる; JS直接埋め込むのもできる) JS風syntax(これは完全な好みだけどブレース・セミコロンsyntaxが結局一番書きやすいみたいなところあるよ) まぁライブラリも意外とある bs-jsonも普通に使いやすいよ JSの標準ライブラリの関数とか型はすべてportされてるのでちゃんと使える  ハマりポイント  BuckleScript拡張最初はよくわからなかった(ドキュメントを100回くらい読むと分かる) 特殊な演算子とかが意外と多くてsyntaxを覚えるのは結構しんどい(Haskellとかだとライブラリ定義の演算子が多いから定義見ればいいけど組み込みの演算子が多いのがつらい) 関数はデフォルトではカリー化されて (a,b) =&amp;gt; ... は a =&amp;gt; b =&amp;gt; ... 相当のJSが生成されるので(これは回避可能)知らないとたまに思った通り動かない ReactはReasonReactというのがあるらしいけどVue.jsはどうしたらいいのかよくわからない(調べてもVue2のやつしか出てこない)  レポート Node.jsで書いていたサーバーサイドをReason MLで書き直したりVue.jsのビジネスロジック部分だけを切り離してReason MLで書き直したりして安寧を得ています。
Rustに引き続き9ヵ月ぶりくらいに良い言語に巡り合えました。ていうか私はML系の言語大体「良い」って言う傾向にあるしまぁML好きなんだなと自分でも思います。
あとはVue.jsでスムーズに使えるようになったらフロントもバックも全部Reason MLでできるのになーって言ってる。 create-vue-app あたりのエコシステムが正式にサポートしてくんないかな～って感じですね。</description>
      </item>
    
      <item>
        <title>Elm: Concurrent FRP for Functional GUIsを読んで</title>
        <link>https://myuon.github.io/posts/elm-functional-gui/</link>
        <pubDate>Sun, 04 Nov 2018 12:32:56 +0900</pubDate>
        <guid>https://myuon.github.io/posts/elm-functional-gui/</guid>
        <description>これ
https://elm-lang.org/assets/papers/concurrent-frp.pdf
はじめに 某所でFRPをeffect systemとみなせないか、という大変示唆的な質問をいただいて、気になったのでFRPについて調べてた流れで教えてもらったElmの作者が書いた論文。 自分はFRPについては「なんかEventとBehaviorがあってArrowになったりMonadになったりするやつ」くらいの感覚しかなかったので論文読んでみることにした。
ところでmarkdownで数式や図を記述するのは大変つらいので記事は適当に日本語で書きます。詳しく知りたい人は論文の方を読んでください。
あと、ElmはFRP捨てたって言ってた気がするので多分今のElmはもう論文にあるような仕組みで動いてないような気がしないでもない。
2章 背景  FRPにはClassical, Real-time (とEvent-driven), Arrowizedの3種類ある Classical:  Behavior a = Time -&amp;gt; a: これが時間の経過とともに変わる値を表現する Event a = [(Time, a)]: これがBehaviorのスナップショットを取ったもの 基本はBehaviorをベースに計算を行うけど、実際のプログラムでは無限に細かい時間で計算はできないので30fpsとか決まったタイミングで再計算するかどうかを考えることになる。そういう離散化のためにEventがあるよみたいな感じ   Real-time:  Event a = Behavior (Maybe a) EventもBehaviorで書いちゃえばいいんちゃうん Event, Behaviorをまとめて Signal a = Time -&amp;gt; a と呼ぶことに 論文で説明されてるElm Coreもこれにinspireされてるっぽい   Arrowized:  SF a b = Signal a -&amp;gt; Signal b signal functionというものをベースにしてこれをArrowにする 論文読んだ限りだと理論が難しくなりそうなのでFRPにおける特にArrowの優位性はよくわからなかった 書きやすいってくらいなのか   Message-Passing Concurrency  Concurrent MLの説明 実装はこれで書いたり書かなかったりする(あとの章でtranslationが与えられる)   既存のFRP GUI frameworks  メモリリークする(Haskellなので)(って何度も書いてあってウケるって思った)    3章 Core Language  Dicreteなsignalを扱う 文法: e ::= () | n \in Z | \x.</description>
      </item>
    
      <item>
        <title>RustとNode.js間通信にgRPCを使う</title>
        <link>https://myuon.github.io/posts/grpc-rust/</link>
        <pubDate>Sun, 28 Oct 2018 16:03:12 +0900</pubDate>
        <guid>https://myuon.github.io/posts/grpc-rust/</guid>
        <description>gRPCしたくなった。具体的にはRustで作ってるデスクトップアプリケーションで、GUIをElectronで書きたいのでNode.jsと通信が発生するのでそれに使えないかなと思って調査した。
gRPC(protocol buffers)とは gRPCはgoogleが作ったRPC(remote procedure call)のフレームワークで、簡単に言うとサーバー/クライアント間の通信が言語を問わずできるよ！みたいなやつ。 RPC自体は見た目は普通の関数呼び出しみたいな感じで書けて、裏ではHTTP/2の通信に乗ってやりとりが行われるようになっている。実際にはRPCを定義してからそれを呼び出すためにはサーバーやクライアントで言語ごとにインターフェイスの定義とかをしなければいけないが、それを自動で生成してくれるのがgRPCコンパイラという感じ。
gRPCを使うには、protocol buffersというプロトコル定義言語(?)を.protoファイルに書いてgRPCコンパイラで言語ごとにコンパイルを行う。2018/10/28現在では公式にサポートされてる言語がC++, Java, Python, Go, Rusy, C#, Node.js, Android Java, Obj-C, PHP, Dartなどなど多岐にわたる。Rustは非公式だけどプラグインがあるので使える。
gRPC/protocol buffersの個人的なポイントをまとめてみる。
長所:
 サポートされてる言語が多い ツール自体はしっかりしてるのであまりその辺で変にハマることはなさそう streaming通信なんかもサポートされてる protocol buffers自体が後方互換性を命を懸けて守るという強い意志のもとに設計されてる まぁこれはそのせいで面倒なこともあるので短所でもあるけど、多くの人にとっては長所になりうるかと思う protoファイルからドキュメント生成するやつもある(proto-gen-doc) protocol buffers自体は普通にプログラミング言語による型定義みたいな感じで普通に書きやすい(少なくともswaggerみたいな地獄のyaml UXとかに比べたら断然楽)  短所:
 公式ドキュメントが死ぬほど分かりにくい(Googleだからしょうがない説もあるが) ツールのインストール方法などが死ぬほど分かりにくい 現状ブラウザによるネイティブサポートがない(grpc-gatewayを使うといいらしいよ) [追記] (grpc-webというので対応されたらしい) [/追記] 生成するコードにユーザー側の自由度がほぼないし自力でプラグインを書くのは多分大変(のでユースケースによっては全く使えないと思う)  最近はマイクロサービス間通信とかで採用されてる事例が多いみたい。実際にブラウザとの通信で使ってる人はそこまで多くない印象だった。
RustでgRPC Rustでサーバー側の処理を書く。
まず、上にも書いたようにprotoをRustコードに変換するgRPCコンパイラのRustプラグインが必要になる。これにはprotobuf-codegenとgrpcio-compilerを使うといいよってあった。
# インストール $ cargo install protobuf-codegen grpcio-compiler # コンパイル $ protoc --rust_out=. --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_rust_plugin` example.proto これによって生成されたRustモジュールを読み込んで使うことになるけど、それにはgrpc-rsを使った(grpc-rustというのもあるけどこっちは触ってない)。
サーバー側のプログラムはこんな感じで書くと良い。
コンパイルすると、protocol buffersのmessageが定義されたexample.rsと、RPC関連が定義されたexample_grpc.rsが生成される。
Node.jsでgRPC Node.</description>
      </item>
    
      <item>
        <title>ブログのテーマ(とGitの管理方法)を変えた</title>
        <link>https://myuon.github.io/posts/blog-simplicity/</link>
        <pubDate>Tue, 23 Oct 2018 22:53:56 +0900</pubDate>
        <guid>https://myuon.github.io/posts/blog-simplicity/</guid>
        <description>Git管理が色々あれなことになっており記事を書くのがとても大変なことになっていたので直したかった、ついでにテーマを変えた。
テーマはもともと自作だったのだけれどまぁ私はデザイナーではないのであるやつに乗っかる方が色々便利だということが分かったりした(自分で書くと、状況によって変な空白が出たりとかしがち)。
テーマを変えた Simplicity: https://github.com/eshlox/simplicity
というテーマにしました。シンプルですっきりだけど普通に見やすいと思う(シンプルで見にくいテーマも多いのでこういうテーマは貴重)
細かいところで前のテーマで便利だったけど失われてしまった機能性とかもあるのでそういうのはおいおい対応していきたい。
Gitの管理方法を変えた こっちがむしろメイン。今使ってる静的サイトジェネレータのHugoはGitHubで公式にサポートされてるわけではないので、自分でHTMLファイルを生成する必要がある。一方で、GitHubはユーザーリポジトリ(myuon.github.ioの形のやつ)はmasterブランチがそのまま表示されてしまうのでソースファイルの管理は別ブランチで行う必要があるなどの問題がありめんどいなーと思っていたのだけど、それを解決する方法が分かった。
結論としては次のサイトに書いてあるようなことをやればいい。
 [http://kohki.hatenablog.jp/entry/hugo-portfolio](Hugo + GitHub Pagesでポートフォリオを作る) [https://qiita.com/kwappa/items/03ffdeb89039a7249619](GitHub PagesのUser Pagesでドキュメントルートを変更するにはmasterを殺す)  masterブランチを殺して、代わりに git subtree push --prefix docs/ origin master とか叩くことで/docsをorigin/masterにpushできる。origin/masterって消せるんですね、知らんかった。
というわけで、よくわからないsubmoduleの管理などせずとも(gitのsubmoduleって結構難しい機能だと思う、いつもいまいちよくわからんって言って使ってたし結構気をつかわないといけなかったりする)、簡単にHTMLの管理ができるしpublishも1コマンドでできるしで便利～になった。
実はこの辺の問題があって最近はブログ記事を書けていなかったのだけれど、環境をえいやと整えたのでまたなんか書いていきたいと思います。
 そういえば私は飽きっぽいので今までいろいろなプロジェクトを始めては途中で飽きてやめたりしてきたが(ここ7年くらいでGitHubリポジトリの数は58になった)、最近は昔やってたやつを引き継いでまた始めたりということもちょくちょくやるようになったりしている気がする。良い傾向だし、そういう感じで過去に挑戦したプロジェクトのサルベージやら供養やらも自然にやっていけたらいいなと思ったり思わなかったり。</description>
      </item>
    
      <item>
        <title>VSCodeでIsabelle2018環境構築</title>
        <link>https://myuon.github.io/posts/isabelle-vscode-2018/</link>
        <pubDate>Sat, 28 Jul 2018 11:46:33 +0900</pubDate>
        <guid>https://myuon.github.io/posts/isabelle-vscode-2018/</guid>
        <description>こうなるよ   スクショ
    環境構築   ほぼこれにある通りでOK
 https://marketplace.visualstudio.com/items?itemName=makarius.isabelle
Isabelleのインストール   http://isabelle.in.tum.de/devel/release_snapshot
 から対応するプラットフォームのファイルをダウンロードして展開しとく
  VSCode pluginのインストール    Isabelle
  Prettify Symbols Mode
  bibtexLanguage (optional)
  を入れる
  VSCode config   user configを開いて次を追加
&amp;#34;isabelle.home&amp;#34;: [Isabelle2018のルートへのパス],   VSCodeをリロードすると、初回であればビルドが走って、それが終われば&amp;#34;Welcome to Isabelle …&amp;#34;って出る
 これで環境構築はOK
  対応状況   VSCodeサポートは残念ながら完璧とはいえない
  state: VSCodeで Isabelle: Show State しましょう, output panelが出る(白背景に勝手になるんだけどこれは設定できないのだろうか, ダークテーマだとつらい)</description>
      </item>
    
      <item>
        <title>静的解析の限界、現実世界との境界</title>
        <link>https://myuon.github.io/posts/how-far-can-static-analysis-go/</link>
        <pubDate>Wed, 11 Jul 2018 05:49:39 -0700</pubDate>
        <guid>https://myuon.github.io/posts/how-far-can-static-analysis-go/</guid>
        <description>はじめに   2018年に静的解析をとにかく強力につけまくるのは多分あんまりコストに見合わないのでよくない
 じゃあ静的解析を窓から投げ捨ててよいかというとそれはただの愚行
 (以下、静的解析を普通に使えてる人には自明なことしか言いません)
依存型のつらみ   私が最初に静的解析の限界を感じたのは多分依存型で遊んでいたとき
 依存型の力はすごくて、まぁそれもそのはず命題論理から述語論理に進んで元への言及ができるので見かけ上表現力はとんでもなく上がるわけです。例えば「ある方程式を満たす解のみを受け取って何かする」みたいな関数が型として表現できるようになる。
 一見すると最強に見えるんだけどこれは実質定理証明をすることなので、制限の強い型をつければつけるほど実装で苦しむ羽目になるということを割とすぐ痛感することになった。
 例えば head : Vect (Suc n) a -&amp;gt; a で長さ1以上のvectorの先頭を安全に取り出す関数を表現できる。 これはコンストラクタを見るだけなので実装も簡単ですね。 それでは今度は quick_sort : (xs: Vect n a) -&amp;gt; \exists (ys: Vect n a). Increasing ys /\ Isomorphic xs ys (読み方としては、長さnのvectorを受け取って、「長さnのvectorであって、昇順に並んでおり、適当に順番を入れ替えるとxsに一致するもの」を返す関数と読みます)とかどうかというとまぁこれを見てすぐ実装が思いつく人はいないでしょう。
 やってみると分かるがこれに実装を与えるためには相当な定理証明力を要求される。もはや関数型プログラミングですらない、単なる定理証明である。
 とか言う話は↓にもよくまとまっているのでよければ読んで
  問題を解決するつもりでキッチリ型を付けた先にある高い壁 - ぼくのぬまち 出張版
  実世界を扱う依存型プログラミングのたぶん基本～外界から安全な世界までの道 - ぼくのぬまち 出張版
    Welcome to 現実   上の記事にも書いてあるんだけど、実は依存型のつらみはこれだけではない(そして今回の記事はむしろこっちの話を書きたい)</description>
      </item>
    
      <item>
        <title>責務と層の分離</title>
        <link>https://myuon.github.io/posts/architecture-basic-idea/</link>
        <pubDate>Tue, 10 Jul 2018 02:49:04 -0700</pubDate>
        <guid>https://myuon.github.io/posts/architecture-basic-idea/</guid>
        <description>設計の話   設計の話です。
責務   責務、誰がその仕事を行うかということを考えましょうというのはまぁさんざん言われていることだけど実際大事だと思う。
 テクニックとしては委譲だのなんだのとあるけど、結局は「その仕事はその人に任せて本当にいいの？」にYesと答えられる場合にのみその作業をそのモジュールなり関数なりクラスなりに任せましょうという話ですね。
  層の分離   プログラムが行う仕事は通常いくつかのオペレーションを組み合わせて実現されるわけだけど、それらの重要度というのは普通は一様ではない。
 仕事によってはドメインレベルにしっかり固定されそれ以外のオペレーションがあり得ないものもあるし、今は一旦こうして実装しておくがあとで高確率で置き換える必要があるとかそういうやつ。
 例えば今はハードコードしているが設定ファイルから読み込んだ値にしたい、DBを切り替えたい、データの中身が変更したいとかそういう感じのやつ。
 そういうときに、それが所属する層を分離するという手法がたまに取られる。 DIが必要になる設計手法とかだとおなじみだけど、後から値を切り替えたいものはより外側の&amp;#34;層&amp;#34;にそれを押し出し、逆に変更が発生しないところに関してはより内側の層にそれを閉じ込めるというやつ。
  責務と層の分離   なんでわざわざこういうタイトルをつけたかと言うとこの2つの意識が一番大事かなと最近思うようになったから
 責務をはっきりさせることと層を分離するってことをひたすら繰り返すだけで大抵の設計手法はやっていけるような気がするなぁと思ったりした
    GoFのデザインパターンをチラ見して   本は読んでないのだけど、最近GoFのデザインパターンについてどういうものかを調べたりしていた。
 一応目的としてはデザインパターンが解決しようとしている問題を明らかにしてモダンな解決策を探りたいというのが動機としてあった。
 感想を正直に書くとまぁ基本的には内容が古い上にまとまってないしこれは名前つけるようなものじゃないだろというのが多い感じで2018年にわざわざ勉強する必要があるようなものではないなと思ったりしたという感じにはなるが、それはおいておいて デザパタのあれこれを調べていくうちに、上のような2つの点の大切さを認識したりした。
 デザパタの多くは現代的な言語なら責務と層の分離がちゃんとできてたらほぼ問題にはならない気もする(こういう話も具体的な言語を固定して考えたりしてみる記事を書いてみるべきかもしれない)。
  オブジェクト指向/DDDとか   「オブジェクト指向は設計ではない」と繰り返して言っていたら何かの折にDDDに触れる機会があり、「これは良いものだ」と思ったりしたことがあった。
 [追記]DDDのlayerに関して適当言ってたので消しました。[/追記]
 実際にDDDはドメイン駆動〜みたいなことを言っているが自分はそこで初めて層の分離の概念を得た。 DDDではドメイン層と〜 DDDのことはよく知らないんだけど例えばClean ArchitectureではEntity層, UseCase層, Adapter層, Driver層のように中にあるべきものと外に置くべきものをはっきり区別していたのが、オブジェクト指向でスパゲッティ設計を生み出し続けていた自分にはとても素晴らしいものに見えたというのがあった。
 オブジェクト指向がなぜ設計ではないかということは、今にして思えばオブジェクト指向は責務については問題にするものの(あるメソッドをどのクラスに入れるべきかという話はよく問題に上がるが)層の概念がないので縦方向への広がりがないというのが大きな問題としてあったのだろうということが分かったりした。
  終わりに   内容がない</description>
      </item>
    
      <item>
        <title>HaskellでDIする</title>
        <link>https://myuon.github.io/posts/haskell-di/</link>
        <pubDate>Fri, 06 Jul 2018 05:51:00 -0700</pubDate>
        <guid>https://myuon.github.io/posts/haskell-di/</guid>
        <description>DI   DIの重要性はここ数年で急速に高まってきている。 依存性が注入されたりとかそういうことはどうでもよくて、設計と実装を分けたい、人類はそれだけのために色々と工夫をこらし最終的にたどり着いたのがDIであったのだろう。
 Haskellでも設計と実装を分けるためにDIしたいというのは自然な流れである。
 ここでは型も含めて設計が実装に依存してはいけないということを要求する。 例えば設計でMySqlConnection、みたいな型が出現することも分離できていないので禁止とする。
問題点   設計を定義するときには他の言語ではインターフェイスなどの仕組みが使われることが多い。 Haskellには型システムという仕組みがあるのでこれがインターフェイス相当の機能として紹介される場合がある。
 しかし型システムはインターフェイスとは違い、型を固定する仕組みがない。型クラス TypeClass a のインスタンスの値が x:TypeClass a =&amp;gt; a と y:TypeClass a =&amp;gt; a のように2つ与えられたとしても、xとyが同じ型である保証はないし、これが同じ型であることを強制するためにはxとyを同時に作って常に同時に運ぶ必要がある。
 というわけでインターフェイスを使うと型が固定できないのでDIしようとすると困ったことになる、と私はずっと思っていた。
  存在型とreflection   型を固定する仕組みは実はどうにかすることができて、要は存在型を使って data Trapped = forall a. TypeClass a =&amp;gt; Trapped a とやると型を外から見えないように隠蔽することができる。
 存在型は中を開いたときにもともと何が入っていたかはわからなくなるが、設計ではそれを意識する必要がないはずなので特に問題がない。
 さらに、いわゆるDIコンテナ的な仕組みでは生成したオブジェクトを必要なところに注入してくれるという機能があることが多いが、実はこれと同じこともHaskellではできる。
 reflectionというパッケージがあり、これはconfigデータを外から与えるためによく使用される。 Given a =&amp;gt; ... なる型をもつプログラムは given と書くといつでも好きなタイミングで外から挿入されたaの値を取り出すことができる。
 同じ型に対しては1つの値しか注入できないが、実際にDIするときは利用する型は1つだけなので問題がない。
 というわけでこれでHaskellでもDIできそう！ということが分かる。
    Loggerの例   例えばLoggerを作る例を考える。</description>
      </item>
    
      <item>
        <title>Fluxを再発明する</title>
        <link>https://myuon.github.io/posts/refluxible-library/</link>
        <pubDate>Sat, 16 Jun 2018 08:00:49 -0700</pubDate>
        <guid>https://myuon.github.io/posts/refluxible-library/</guid>
        <description>Haskellの2D graphics libraryを作った   作った: refluxive
 与太話に興味がない人は解説まで飛んでください
なにこれ   大体Haskell製Fluxベースの2Dグラフィックスライブラリ on SDLという感じの代物です。
  なぜ   大変悲しいことにHaskellではゲーム用に気軽に使えるグラフィックスフレームワークがないことがよく知られているわけです。 候補としては一部のFRP系のやつ、あとDSL系のやつも少々(これは用途がかなり限定されていることが多いけど)、それと今ならElm(!)が下手すると最有力かもしれない。 一応本当に簡単な用途ではglossがそれ系を標榜しているがフレームワークではないし、真面目に使うには多々至らぬ点も多く…という感じなので困った困ったになるわけですね。
 —
 なぜフレームワークがほしいかというとUIを一から作りたくないというのがある。私はあと何回「ボタン」をrectangleとfillRectangleとtextを組み合わせて一から作らないといけないんだ。 画像を読み込んできて3x3マスに分割して「レイヤー」として表示できるようにするみたいなのも何回も書かされたのでもう散々という気持ちがあった。
 グラフィックスライブラリは別にOpenGLでもSDLでもGLFWでもなんでもいいんだけど一からUI部品を作っていると日が暮れてしまうのでそういうUI部品をライブラリとして提供したくて、じゃあUI部品を共通して作って提供できる仕組みをどうにか考えないとなぁという感じになってた。
  Flux   JavaScript(クライアントサイド)業界ではこの辺をみんな真面目に考えて色々やっていってるわけですがまぁ最近はFluxの影響を受けたやつが人気なので私もそういうのにのっかる感じにしました。 といっても完全なFluxでもないと思う。ViewがModelの射影になっていること、Viewへの変更がSignalとして送出されてModelの方に伝わるみたいな感じになっているのは大体Fluxだけど、dispatcherではなくSignalの送出はベースのUIモナドが一括で請け負ってるとことかはちょっと違うような気もする(詳しくないからよくわからんけど)。
  Haskellとは   HaskellでFluxぽい仕組みがちゃんと乗っかるかは若干不安だったけど特に問題はなかった。そもそもこっちはDOMを操作する必要がない、何もない代わりに何にも縛られないのでまぁ自由は効くよねという感じ。 Haskellらしいコードになったかという意味では、default-extensionsを見てもらえばまぁ察しはつくと思う。今回はExistentialQuantificationとTypeFamiliesとDataFamiliesを使いまくったのでHaskell(GHC)でこそという感じはしてるような気もする。
  テクいところ   最近Rustに浮気しっぱなしだったからHaskell真面目に書くの実はそれなりに久々だったけど、ちゃんとRustや他で勉強したりしてたことが活かせたりはしたと思う。 performGCとかunsafeCoerceとか今までどう使っていいかよくわからなくてやってなかったけどちょっと分かってきた感じもありよかった。
    refluxive   ライブラリの中身を超簡単に解説します。 「ほーんHaskellではそうやってやってるんだー」くらいで見てもらえればいいと思います。
 あと当たり前だけどまだプロトタイプができたてのライブラリなのでAPIは将来変更されるおそれが大いにあります。
構成要素    Component: 1つの部品を表す単位; 中にModelとかそういうのが定義されているが外からは見えない</description>
      </item>
    
      <item>
        <title>私と型システムとポエム</title>
        <link>https://myuon.github.io/posts/type-system-poem/</link>
        <pubDate>Sat, 02 Jun 2018 08:27:31 -0700</pubDate>
        <guid>https://myuon.github.io/posts/type-system-poem/</guid>
        <description>最近巷では俄に型システムについての言及が増え、型システムポエマーが増えてる気がするので自分もその時流に乗りたい。
 完全にポエムだけどなんかあったら随時指摘ください。直します。
TL;DR   言いたいことはまとめると次
  型システムは程度問題なのでちょうどいいところを探すべき
  型は万能でも強さが正義でもない(だから未だに研究されてる)
  よく知りもしないくせに計算機科学を侮辱するのはやめろ
  予防線   あくまでポエムですので中身はないです
 私は型理論専攻で学位はとったものの研究者ではないのであまり信用しすぎないように
  型システムの過去   型システムは大まかに次のような利点があるとされてきた(個人的主観)
  「異常」なプログラムを検出する仕組み
  静的解析による分かりやすいエラーメッセージ
  型そのもののドキュメント性
  IDEでのcompletionに貢献
  最適化に貢献
  (数学に正しく裏打ちされたsemantics)
    型システムの分類と主な特徴   当たり前だが型付き言語も一枚岩ではなく、色々違いがあるので少し分類をしておく。下に行くほど強い。
型なし(動的型)言語    言語: untyped lambda calculusやLL系言語など
  LL系とは言ったものの例えばPythonは最近type annotationがかけるし、あるいは型のない言語でもIDEが静的解析を行い実質型システム相当のチェックを行う言語があったりするので型の恩恵を一切受けない言語はイマドキそう多くはない。 型システムの人間からは型なしは型なしとして一緒くたにせざるを得ないが、別に型なしを嫌っているわけではない。それも一つの言語の在り方である。まぁ私は死んでも書きたくないけどな。</description>
      </item>
    
      <item>
        <title>Desktop Linux VM環境 on Windows</title>
        <link>https://myuon.github.io/posts/vm-linux-on-windows/</link>
        <pubDate>Sun, 20 May 2018 08:11:42 -0700</pubDate>
        <guid>https://myuon.github.io/posts/vm-linux-on-windows/</guid>
        <description>はじめに   私はプログラミングはすべてLinux環境でやっている。環境構築、フォントレンダリング、まともな端末など理由を挙げればキリがない。 最近までDesktop Linuxを直接インストールしていたが(Windowsを持っていなかったが)、ゲームがしたいなどの理由によりWindows 10を買ってクリーンインストールしたのでLinux環境をVMに移行した。
結論   Vmware Workstation Playerを使え
  Vmware Player vs VirtualBox vs Hyper-V   仕組みの上ではHyper-Vは他2つに比べてハードウェアに近く、よいパフォーマンスが得られることが期待される。 が、3つを試した上では圧倒的にVmware Player &amp;gt; VirtualBox &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; Hyper-Vという感じだった。
 環境
  ホスト: Windows 10
  ゲスト: Ubuntu 18.04 Gnome/Xfce
  ゲストの設定: メモリ4GBくらい 4コア使っていいよぐらいの設定 特に細かくいじったりはしてない
  結果
  Hyper-V: 入力遅延が大きすぎて使い物にならない、マウスもキーボードも数フレームは遅延してる。あと3つの中では明らかにこれだけ重かった(Gnomeのアニメーションの挙動とかを見ている限り)。Hyper-VのViewerがボロいのかと思ってRDP接続も試したけどVirtualBoxと比べても明らかに重くパフォーマンスが出てなかった。LISはUbuntu 16版のものを使用、BIOSでC-State切るといいよって言われてそれもやったけど効果ほぼなし。
  VirtualBox: 比較的サクサク。Gnomeだとちょっと重いがXfceだと普通に快適。VMの起動と終了がちょっと重いかなくらい。
  Vmware Workstation Player: 3つの中では最もサクサク。Gnomeのアニメーションもそれなりに反映されていた。Xfceにしたら本当に早い、実機インストールかと錯覚する快適さ。体感ではVMの終了がVirtualBoxより早い。
  試すとわかるけど悩むまでもないという感じ。 ただしVmwareのみディスプレイサイズがホストOSのものに勝手に従ってくれなくてxrandrからaddmodeした。</description>
      </item>
    
      <item>
        <title>動画編集ソフトを作り始めた</title>
        <link>https://myuon.github.io/posts/madder-start-to-create/</link>
        <pubDate>Sun, 04 Mar 2018 19:21:20 +0900</pubDate>
        <guid>https://myuon.github.io/posts/madder-start-to-create/</guid>
        <description>Rustを使い始めて1ヶ月だぜ体験記みたいなのを書こうとしたけどせっかくなので今やってることも全部まとめて1本の記事にすることにした。
 最近日本語をかくのがめんどくさい以外の発言をしていない気がする。
 1ヶ月ほど前に動画編集ソフトを作りたくなって、言語はRust メディアフレームワークにGstreamer GUIにGTK+を使うのだけどこの3つをどれも触ったことがない状態で作り始めるという完全に勢いだけのアレというのが前置き。
Rust   前回の記事でも色々言ってたけどその後分かったことなんかを記しておく(本当はWHAT I WISH I KNEW WHEN LEARNING RUSTみたいにしてまとめると良いのだろうなぁ)
  とりあえずメモリモデルとしてはスタックとヒープがあるということだけ分かっておけば大丈夫そう
  structのフィールドに参照をもたせるとlifetime parameterにコードがまみれるのでやめたほうが良さそう
  Rc&amp;lt;RefCell&amp;lt;T&amp;gt;&amp;gt; が便利(これは主にGTKを使う時に必要になったというのもある)
  Rc&amp;lt;RefCell&amp;lt;T&amp;gt;&amp;gt; は確かに便利だけど hoge.borrow_mut().call(hoge.borrow()) みたいなことをするとBorrowMutError: already borrowedで実行時エラーになって死ぬので気をつけよう
  参照が欲しいときはBorrow, BorrowMut, AsRef, AsMutトレイトの実装があるかを見よう
  Derefトレイトは神
  Fn, FnMut, FnOnceの意味がようやく分かってきた FnOnce系はちょっと気をつけたほうがいい(Option::unwrapがselfを消費するのとか)
  trait, implは飽くまでインターフェイスの提供だけなのでデータの扱いはstructで行う
  OOPっぽくコード書きたいときはtrait objectと動的ディスパッチの仕組みを上手く使う(果たしてこれが正しいアレなのかはよく分からん)
  マクロは便利
  別言語でtrailing commaで怒られると厳しい気持ちになる
  if letが意外と便利</description>
      </item>
    
      <item>
        <title>Rustに入門した</title>
        <link>https://myuon.github.io/posts/rust-started/</link>
        <pubDate>Fri, 09 Feb 2018 22:21:42 +0900</pubDate>
        <guid>https://myuon.github.io/posts/rust-started/</guid>
        <description>Rustに入門して2週間くらい経ったぜ
 TL;DR Rustは普通に便利ないい言語
入門した   入門にあたってはプログラミング言語Rustを読んだ。これの翻訳版ぽい。
 読んでRustに対して思ったこと:
  読んだやつは古いドキュメントの翻訳版だったようで一部記述が古いっぽかった
  構文はシンプルだけど必要なものは揃ってる感 ML風でADTもパターンマッチもあるしtraitもあって言うことナシでしょ
  所有権とか借用とかそういう聞いたことあるワードは参照という概念に対するアレっぽい
  ｽｨｰ言語を気軽に(unsafe)呼べるのはFFIするとき良さそう 強そう
  マクロ割と便利そうな雰囲気ある
  RcとかArcとかCellとかいう便利なものがあるらしい あとBoxはいつ使うんじゃ
  参照わかったようでわからない とりあえずスタックとヒープの違いは覚えたぞ
  入門書なのに普通にするする読めてしまったし特に難しいことがなかった、もしかしてRustは簡単なのでは？？？
  参照とかいう概念がある言語を長らくやっていなかった(Pythonは基本参照だった気がするけど意識する場面ないしHaskellの参照もあんまり使わないしなぁ)ので 「あー参照だとこういうことも考えないといけないのかぁ」って思ったりした
 参照、人類には早すぎるのでは？？？って感じ
  ちょっと書いたりした   ちょっと書いたりした(してる)
 どうせなのでなんか作ってみるかぁと思ってgstreamerとGtkで動画をごにょごにょするアプリケーションを作って遊んでる。 なんで入門していきなりそんな重いもの作ってんだよという感じなのだけどRustの強みはやっぱりCにFFIしやすいことな気がしていて逆にHaskellでは現状まともにビルドできてまともに使えるGUIライブラリがないので、そういう意味で(Rustの強みを活かせるという意味で)GUIアプリケーションぽいものに着手した。
 まぁまだそんな書いてないしな〜(と思ったがすでに700行近い。Haskellなら500行超えるだけで相当だけど中括弧でブロック表す上に手続きがデフォルトの言語ってめっちゃ行数かさむよね。)
 しばらく書いた感想:
  エラーメッセージがカラフルや…なんだこれ…(GHCも最近カラフルになったけど未だに慣れない感ある)
  ｽｨｰ言語と違って コンパイラが信用できるーーーﾔｯﾀーーー(踊りだす)
  エコシステムが強すぎてビビる(いやHaskellがダメなだけか…？)
  Rc Cell RefCellあたりがあまりに便利</description>
      </item>
    
      <item>
        <title>Namespace Haskell</title>
        <link>https://myuon.github.io/posts/namespace-haskell/</link>
        <pubDate>Sun, 04 Feb 2018 13:55:38 +0900</pubDate>
        <guid>https://myuon.github.io/posts/namespace-haskell/</guid>
        <description>Haskellにモジュールシステムが欲しすぎたのでNamespace Haskellとして提唱したい。
主な機能  open import   Agdaにもある機能で、importをimport(モジュール読み込み)とopen(現在のコンテキストに名前を公開)に分割する.
  import M とすると, M.func によってモジュールMの関数funcにアクセスできる
  open M とすると, それを指定したブロックでMの関数を修飾子なしでアクセスできる
  open import M とすると, import M; open M の意味になる(現在のHaskellのimport)
  openをwhereブロック内で宣言することで、一部でしか使わないimportをあっちこっちで展開するのを防げる。
  public export   現在のHaskellではモジュール宣言時に module M(..) where でexportする関数を選べる。
 そして module M where は全て公開の意味になるが、これを全て非公開に変更し、モジュール内で export (..) のように宣言したもののみexportすることにする。
  associated function   要は「メソッド」機能なんだけどtypeclassの関数のことをメソッドって呼ぶことがあるような気がするので名前の衝突を避けるためにここではassociated functionとよぶ.
 次のような、データ型とそれに対する特別な関数定義を行うスコープを用意する。
-- 例 data List a = Nil | Cons a (List a) impl (this :: List a) where { reverse :: List a reverse = .</description>
      </item>
    
      <item>
        <title>プロジェクトマネジメントを始めたい</title>
        <link>https://myuon.github.io/posts/want-to-start-project-management/</link>
        <pubDate>Sun, 14 Jan 2018 23:14:19 +0900</pubDate>
        <guid>https://myuon.github.io/posts/want-to-start-project-management/</guid>
        <description>資料    担当になったら知っておきたい「プロジェクトマネジメント」実践講座: 2ヶ月前くらいに買って読んだ
  ゲーム開発 プロジェクトマネジメント講座: スクエニの資料 具体例がゲーム開発だけど内容は業種を問わないと思う
    プロジェクトマネジメント実践講座を読んだ   内容は大変丁寧な感じでモチベーションと具体的な例を上げつつPMの重要性、あと必要な各種書類や仕事の詳しい日本語による解説という感じ。 それなりにページ数あるけど圧縮したら15ページ+図表くらいで収まる気がする(チートシートほしい) モチベーションを十分理解している人は安心して読み飛ばしていいと思う。
 個人的な感想
  PMでは「納期を守る」という感覚が一番大事っぽい
  やたらExcelを推してくるのは逆に言えばまともなツールが他にないのだろうなぁ
  リスク管理についても書いてあってなるほどと思った(リスクを先に想定しておくのは難しいけど大事っぽい)
  モチベーションの説明がわかりやすい
  プロジェクトの発足と仕事を作って人に割り振る時のマネージャーの動き方について主に書いてる感じ
  読んでる時はもっと色々思ったはずだけど読んでから時間経ちすぎて忘れた
  個人的に気になった方法論   「PMの話」っていうと結構マネージャーの動き方とか仕事の仕方的なものを指すこともあるんだけど(サイクルはこまめに回しましょうねとかそういう) 自分が欲しいのは方法論なのでそっちについてちょっとまとめておく
WBS &amp;amp; ガントチャート   各node Xに対しXを作るのに必要なもの/作業を子nodeに置いた高さ4のfin. branching treeをWBSと呼ぶ(めちゃくちゃかっこいいなこの説明って思ったけど誰にも伝わらないと思う)。 WBSに実際のスケジューリングを与えるものをガントチャートという。
 これらを作るのは自然なことなのだけど、問題は実際の作業の間には依存関係があることで、これを上手く管理するのは結構難しい。
 基本は依存関係に沿ってトポロジカルソートして作業を進めればよいがそういうことが簡単にできるツールって意外と少ないよな 本ではExcelって言ってたが果たして
  重要度-時間分割   これはスクエニの資料の方にあった話で、各作業に 重要度: 高/中/低 および かかる時間: 大/中/小 をそれぞれ割り振って3x3のボードに配置する。 手を付けるべき作業によい感じに優先順位を割り振るときに便利そう。</description>
      </item>
    
      <item>
        <title>GHC拡張一覧を眺める</title>
        <link>https://myuon.github.io/posts/ghc-exts/</link>
        <pubDate>Sat, 13 Jan 2018 00:38:01 +0900</pubDate>
        <guid>https://myuon.github.io/posts/ghc-exts/</guid>
        <description>GHC-8.2.2のGHC拡張を眺めます。
  10. GHC Language Features User&amp;#39;s Guideの該当セクション
  7.6.12. Language options 単に一覧が欲しいだけならここの -X から始まるものを見ると良い
  上から順に見ていって後から関連するものとかを再編します。
GHC拡張一覧    AllowAmbiguousTypes   型変数が全て決定していないものを通すようにする (個人的)非推奨1
  Arrows   arrow notationを使えるようにする FRPする人なんかは使う
  ApplicativeDo   do-notationがApplicativeに対しても使えるようになる 個人的には嫌い
  BangPatterns   関数の引数やデータ型のパラメーターをstrictに評価する; Strict拡張で事足りることが多い気がする
  BinaryLiterals   バイナリ表現が使えるようになる( 0b11001001 みたいなやつ); 使ったことない
  CApiFFI   FFI関連; 使ったことない
  ConstrainedClassMethods   型クラスのメソッドに型クラスが受け取る型変数を含む制約が使えるようにするやつ; これHaskell98だとだめってマジ？(そらそうよ)</description>
      </item>
    
      <item>
        <title>V.S. Hask圏</title>
        <link>https://myuon.github.io/posts/versus-hask-category/</link>
        <pubDate>Fri, 05 Jan 2018 22:52:56 +0900</pubDate>
        <guid>https://myuon.github.io/posts/versus-hask-category/</guid>
        <description>Hask圏   Haskellをラムダ計算とみなした時のsyntactic categoryをHask圏というのがよく言われる定義である(と思う)。 Haskellのtypeをobject, hom(A,B) をjudgement x:A |- M:B 全体(を適当な同値関係で割ったもの)とみなして圏を作る(このときしばしばjudgementとこのjudgementから作ったfunction λx.M を区別しない)。
 さて基本的な結果として次のことが知られている。
  Hask#Is Hask even a category?
  Hask is not a category
  というわけでHask圏は圏にならないのでそのようなものは存在しない。
  Why not?   これはundefinedというヤバイ元の存在とcall-by-needの悪魔的評価規則が合わさりこのような現象が生み出される。 主にこの2つが悪さをしているので、この辺をどうにかできればHask categoryが作れる可能性がある。
undefinedを抜く   undefinedは「評価ができない(プログラムが正しい値を返さない)」ことを表す元で、普通は(多分)domainのbottomに対応させ、無限ループするプログラムの解釈なんかに使う。 undefinedを抜くためにはプログラムが常に停止して値を返す必要があるので無限ループができないようにする必要がある。
 とまぁ言うのは簡単でfixpointを抜けばいいだけなんだけどfixpointもないcalculusがプログラミング言語を名乗るのは片腹痛いのでこれはちょっとナシかなという気持ちになったりする。
  call-by-needを捨てる   call-by-needを捨てて、call-by-valueとかcall-by-nameとかそういうやつに行くというのも1つだと思う。 GHCのStrict拡張を入れてライブラリもStrict付けて全てビルドしなおせばそれはもうcall-by-valueになる(よね？)はずだったり、まぁcall-by-nameもcall-by-needみたいなもんやろという乱暴な考え方によりcall-by-needを捨てるのは現実的な案だと個人的には思う。
 しかしcall-by-needではないHaskellはそれはもうHaskellなんですか(反語)ということもあるのでアイデンティティを捨てる勇気が必要かもしれない。
    ここからポエム   いずれにせよHaskellという純粋関数型プログラミング言語でHask圏を考えるというのは無理があるということが分かるのだけれど、じゃあHask圏についてcomputer science的に意味がないかというと個人的にはそんなことはないと言いたかった。
 個人的に、CSとは「計算機で観測可能な現象に説明をつける」学問であると思うので、実際にHaskellという言語で観測可能な現象について圏論で説明をつけようとする営み自体が否定されることはないと思う。 計算機が発明されて間もないからなのか人類が遅れてるのかはわからないけれど今は計算機の説明を付けるために用意した圏論的なモデルが上手くモデルとして機能していない(モデルが現象の構造を反映する力が弱い)のかもしれないけれど、とりあえず数学的にわかりやすいモデルを取ってきていくつかの技術的な難しさ(categoryにならないとかね)を無視した上で似たような現象をシミュレーション出来ないかを調べている段階だと思えばいいんじゃないかなと。</description>
      </item>
    
      <item>
        <title>2017年振り返り</title>
        <link>https://myuon.github.io/posts/end-of-2017/</link>
        <pubDate>Sun, 31 Dec 2017 20:24:14 +0900</pubDate>
        <guid>https://myuon.github.io/posts/end-of-2017/</guid>
        <description>2017年が終わりそうなので(去年の記事)。
アウトプット  プログラミング&amp;amp;定理証明   github見たら意外と色々やってた。 古い順に
  DOTO: todoリストをアレするwebアプリ。これは就活用に作ったような気がする。TypescriptとReactを使ってやっぱクライアントサイドはつらいって思った記憶。今ならElmとかで作ると思う。
  CatQ: Coqによる圏論の形式化。Setoidベースでやったけど、圏論側で仮定したくなる公理の妥当性がCoqの上でも妥当なのかとかが無限に気になりやっぱ真面目にやるなら依存型使うのはダメだなと悟って放棄。
  dan: やったことリストを登録してgithubの草みたいに表示したりするやつ。最近使ってない
  bwitterkuchen: CUI Twitterクライアント。nyantreamを作ることにしたのでメンテはしてないけどしばらく使ってた。
  avix: AviUtlという動画編集ソフトのexoファイルを生成するためのHaskellライブラリ。動画編集のときに使おうと思って作ってから一度も使ってない。
  sdlight/widx: sdlightはSDLのラッパーライブラリ(ゲームを作ろうとしてついでに作った)。widxはsdlightからwidgetだけを切り離してインターフェイスだけ提供するライブラリ、だったけどBackpackのバグが直らないので開発ができない状態になってる。
  nott: Type Theoryに関するまとめノート的なものを置くところ(プログラミング関係ない)。今のバタバタが終わったらまた再開したい。
  typed: 型付きラムダ計算の実装(TaPLみながら)と定理証明を雑に投げ込む場所。
  claire: LKベースのproof assistant。今年の一人アドベントカレンダーでやったやつ。
  myuon.github.io: このブログ。今年入ってからはてなブログからgithub pagesでホスティングすることにし、今はhugoを使うのに落ち着いてる。
  nyantream: CUIストリームクライアント(絶賛開発中)。時報/Twitter/Gmail/Slackに対応。GUI版も作りたい。
  あと開発中のゲーム(最近開発してないけど)もあった。sdlight/widxが真面目に動くようになれば再開したいけどどうだろう。
  絵   自分の中で二次創作という行為への折り合いが付き、二次創作を行えるようになったおかげか特に10月以降はかなり積極的に絵を描くようになった。 多分今年が一番絵が上手くなった(画力向上よりも魅せ方・道具の使い方的な意味で)1年だった気がする。
 あとブログ漁ってたら今年の初めに新しいペンタブを買ったようなのでそのおかげもかなりある。 というか、今までラップトップしか持ってなかったのをデスクトップPCを買うのに合わせて21.</description>
      </item>
    
      <item>
        <title>一人CSアドベントカレンダー・最終回</title>
        <link>https://myuon.github.io/posts/2017-csadv-finish/</link>
        <pubDate>Mon, 25 Dec 2017 00:11:02 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017-csadv-finish/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 25日目の記事です。
くぅ疲   くぅ〜疲れましたw これにて完結です！
 実は、一人アドベントカレンダーを一度くらいやってみたいなと思ったのが始まりでした
 本当は話のネタなかったのですが←
 ご厚意を無駄にするわけには行かないので自分の中の流行りのネタで挑んでみた所存ですw
 以下、各テーマ達のみんなへのメッセジをどぞ(ここだけ原作無視)
  Isabelle基礎編(チュートリアル): 初心者に伝わる内容になってたらいいですね prog-prove読んでたら完全に知らないことが書いてあったりしたのでみなさん読みましょうね
  Isabelle実践編(IMP): IMPはネタとしては面白いんだけどbig-stepのdeterministicくらいだと内容的には面白みにかけるなという感想
  Isabelle応用編(ラムダ計算): SNまで示せたらドヤ顔できたんだけどね(CRも割としんどいけど)
  Haskell小ネタ: 本当に小ネタだった Isabelle編が当初の予定より長引いたせいで日数的には全然必要なかった
  Proof Assistant理論編: まとまりのない文章になった感すごい(いつものことや)
  Proof Assistant実践編: 実装はまぁ別にそんな面白いものでもないなって解説書いてて思った
    感想   さて完走した感想(爆笑)ですが、まぁ事前に準備しとくのは大事だねと思いました。 今回はIsabelleの途中までは記事かきためてましたが、結局最後は前日の23時から描き始めるみたいなのが普通だったので書き溜めは大事だなみたいな。
 それでも1日も落とさなかった(常に当日0時半までには投稿してた気がする)のはめっちゃ偉いと思います。
 あと今年のAdCにもいくつかお誘いを頂いていたんですがまぁこっちがあったのとこっちの記事はシリーズものばかりだったので登録は見送りました。
 来年は……ネタがあれば何か書きたいなと思います。一人アドベントカレンダーはしばらく大丈夫です。
  おわりに   こんな記事読む人いるんかってずっと思いながら書いてましたがもし読んでくれる人がいたならありがとうございました。
 本当の本当に終わり1
  1 ってなんで俺くんが！？のところをやろうとしたら精神が持たなかったって言ったら「くぅ疲をやる覚悟が足りない」って言われました。そのとおりだと思います。</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・発展編 その7</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-7/</link>
        <pubDate>Sun, 24 Dec 2017 00:04:51 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-7/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 24日目の記事です。
  Proof Assistant 「Claire」の実装の説明は前回までで終わったので、よりProof Assistantとして発展させていくには、という話をします。
実装すべき機能など  prover   さていきなりめちゃくちゃ重い話ですが、今回はproverを実装しませんでしたがこれは是非とも欲しい機能ではあります。
 Isabelleでは色々なproverが提供されていますが、First-order logicのproverの実装は色々なやり方が知られているようなので(※やったことないのでよく知らない)実装できるとよさそうです。
  unifier   一旦示した定理は、自由変数を全部メタ変数に変えてから環境に追加されます。 この定理を後から使う場合はこのメタ変数に何か適当なものを代入する必要があり、今回のClaireの実装ではこれは全てユーザーが決定する必要がありました。
 各変数ごとに代入を行うのではなく適当な論理式を与えるとそれとunifyしたものを返すような感じにしてくれるコマンドを例えば追加すると多分便利です。
 あくまで一例ですが、 goal: |- P(a) /\ P(b) ==&amp;gt; P(a) かつ thm: ?X /\ ?Y ==&amp;gt; ?Z のとき、 このゴールを解消する exact thm を use thm; unify; assumption みたいに定義できるとよさそうです。
  HOLの実装   大変なだけです。技術的な難しさは特に無いです(IsabelleのHOLとか参考にするといいかも)。
 ところで、Claireには組み込みのequalityがないので、equalityはそれ用のpredicateを後から定義して、公理(reflexivitiyとsubst rule)を追加して使うことになります。
 それに関連するrefl, substなどのコマンドを定義しておくと便利です。
  マクロ記述言語   前回も説明しましたがhintでGHCをインタープリターとして使うのは起動に時間がかかりすぎるので、まともな言語を定義したほうが便利でしょう。</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・マクロ編 その6</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-6/</link>
        <pubDate>Sat, 23 Dec 2017 00:04:55 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-6/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 23日目の記事です。
  Proof Assistant 「Claire」の実装について説明していきます。
 リポジトリはこちら: myuon/claire
 今回はClaireのマクロ機能について説明します。
マクロ記述言語   Proof Assistantでは、コマンドが組み込みのものしか使えないと何かと不便なので(特にライブラリで定義されたデータに対する便利コマンドなんかは組み込みようがないので)、コマンドを定義するためのマクロ記述ができるようにするのが普通です。
 Coqでは専用の言語としてLtacがあります。IsabelleではSMLが(直接？この辺よく知らないけど実装側からインタープリター呼ぶみたいなことしてるのだろうか)呼べます。
 Claireにもそういう機能を乗っけたいわけですが、言語を新たに定義するのは面倒なのでHaskellで書いたものを直接インタープリターを呼ぶことにします。
 マクロはCommandを定義するものと、Declを定義するものと(これはまぁ今回の話とはちょっと違うのですが、あったほうが便利なので用意しておきました)あります。
  マクロの実装   マクロ自体は、適当な引数を受け取ってCommand, Declの列を返すような関数です。これはClaire言語やその証明の構文木を返しているわけです。
マクロ定義モジュール   定義は適当なHaskellのモジュールとして記述します。 export_command, export_declに定義したマクロを列挙します。
module Commands where import Claire macro :: Env -&amp;gt; Argument -&amp;gt; [Judgement] -&amp;gt; [Command] macro = ... export_command :: [(String, Env -&amp;gt; Argument -&amp;gt; [Judgement] -&amp;gt; [Command])] export_command = [ (&amp;#34;name&amp;#34;, macro) ] declmacro :: [Argument] -&amp;gt; [Decl] declmacro = .</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その5</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-5/</link>
        <pubDate>Fri, 22 Dec 2017 00:02:50 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-5/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 22日目の記事です。
  Proof Assistant 「Claire」の実装について説明していきます。
 リポジトリはこちら: myuon/claire
 機能まででproofcheckerのコア機能については説明しました。 今日は雑にtype systemの話をして、Claireを実際に動かして証明を書いてみます。
Environment   proofcheckerは環境とよばれる状態をもっていて、ここに証明した定理などを格納しています。 説明していませんでしたが一応紹介しておきます。
 Claire.Env
data Env = Env { thms :: M.Map ThmIndex Formula , types :: M.Map Ident Type , proof :: [(Command, String)] , newcommands :: M.Map Ident (Env -&amp;gt; Argument -&amp;gt; [Judgement] -&amp;gt; [Command]) , newdecls :: M.Map Ident ([Argument] -&amp;gt; [Decl]) }   上から順に、「すでに示した定理」「宣言された型つきの項」「直前の定理の証明」「マクロで定義されたコマンド」「マクロで定義された宣言」です。
 また、実は定理を示した時に(ThmD節による命題の宣言と証明がcheckされ、環境に定理を追加する時に)定理の自由変数をメタ変数としてgeneralizeする機構が挟んであります(Isabelleでもやっています)。</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その4</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-4/</link>
        <pubDate>Thu, 21 Dec 2017 00:20:35 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-4/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 21日目の記事です。
  Proof Assistant 「Claire」の実装について説明していきます。
 リポジトリはこちら: myuon/claire
 昨日に引き続いてClaireの宣言(Decl)について説明していきます。
Declarations   まずはtoplevelMの定義から。
toplevelM :: (Monad m, MonadIO m) =&amp;gt; Coroutine DeclSuspender (StateT Env m) () toplevelM = forever $ do let typecheck fml u k = do { env &amp;lt;- lift get; utyp &amp;lt;- liftIO $ try $ infer env fml; case utyp of Left err -&amp;gt; suspend $ DeclError &amp;#34;typecheck&amp;#34; (toException $ TypeError fml err) (return ()) Right typ | u == typ -&amp;gt; k Right typ -&amp;gt; suspend $ DeclError &amp;#34;typecheck&amp;#34; (toException $ TypeError fml (toException $ UnificationFailed u typ)) (return ()) } decl &amp;lt;- suspend (DeclAwait return) env &amp;lt;- lift get case decl of ここに実装を書く   Claireは実は(貧弱ながら)型システムを備えていて、型チェックを一応行います。 とりあえずそれは今はおいておいて、toplevelMはDeclを受け取って実行するのを繰り返すだけの単純なステートマシンです。</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その3</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-3/</link>
        <pubDate>Wed, 20 Dec 2017 00:12:26 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-3/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 20日目の記事です。
  Proof Assistant 「Claire」の実装について説明していきます。
 リポジトリはこちら: myuon/claire
Proofchecker state machine   さてClaireのproofcheckerを作っていきます。
 前回にもちょこっと話しましたが、proofcheckerをステートマシンとして捉えます。 これは、インタラクティブシェルを実装しなければいけない関係で、proofcheckerを1ステップずつ(証明ファイル1行ずつ)進むという処理をさせたいからです。
proof state   初めに仕様を固めます。
  (state:toplevel)   Declを読む; Theoremが来たらstate:commandに移行; 全ての入力を消費するか途中でエラーになったら停止する
  (state:command)   Comを読む; 途中で失敗したらエラーを吐いてstate:toplevelに戻る
  注意が必要なのは、state:commandでエラーが出たら、state:toplevelに戻ってエラーが出るところです。 このエラーというのはcheckerを走らせるときは普通のなんでもよいですが、インタラクティブシェルの場合はユーザーにエラー内容を表示しつつ再入力を促す必要があるのであとでcatchする必要があることも念頭に置いておきます。
  Coroutine monad   さてこういうステートマシンを作りたいときはどうするのがいいでしょうか？ 察しの良い方ならわかるとおりこのアドベントカレンダー14日目の記事 Coroutineモナドとステートマシン でも説明したとおり、Coroutine monadを使います1。
 Claire.Checker
Command Machine Suspender   簡単な方から行きます。
data ComSuspender y = ComAwait (Command -&amp;gt; y) | CommandError Ident SomeException y deriving (Functor) commandM :: (Monad m, MonadIO m) =&amp;gt; Env -&amp;gt; Coroutine ComSuspender (StateT [Judgement] m) () commandM = .</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その2</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-2/</link>
        <pubDate>Tue, 19 Dec 2017 00:00:24 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 19日目の記事です。
  Proof Assistant 「Claire」の実装について説明していきます。
 リポジトリはこちら: myuon/claire
LK proofchecker  ルールの適用   LKのproofcheckerを作ります。これは、LKのルールの列を受け取って、それを現在のJudgementに適用した結果を返すような関数です。
 例として次のルールを考えます。
Γ,A |- Δ ----------- (AndL1) Γ,A∧B |- Δ   このようなルールは下から上に向かって適用します。ので、 Γ,A∧B |- Δ のJudgementを Γ,A |- Δ に変換します。
 LKのルールはほとんどintro ruleなのでルールの名前を指定するだけでいいのですが、例えば次のルールCutは新たな(ゴールには出現しない)論理式Aを導入するので、これもルールに合わせて指定する必要があります。
Γ |- Δ,A A,Γ |- Δ -------------------- (Cut) Γ |- Δ   このようなことを鑑みて、前回も説明したとおりLKのRule型は次のような定義にしていました。
data Rule = I | Cut Formula -- CutはFormulaを引数に取る ...    チェッカー   Claire.</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・実装編 その1</title>
        <link>https://myuon.github.io/posts/proof-assistant-impl-1/</link>
        <pubDate>Mon, 18 Dec 2017 00:01:47 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-impl-1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 18日目の記事です。
  Proof Assistant 「Claire」の実装について説明していきます。
 リポジトリはこちら: myuon/claire
Syntax: FOL, LK, Claire   初めにSyntaxの定義をしてからパーサーを用意します。 これがないと何も出来ないので。
FOL   Claire.Syntax.FOL
data Term = Var Ident | Abs [Ident] Term | App Term [Term] deriving (Eq, Show) data Formula = Pred Ident [Term] | Top | Bottom | Formula :/\: Formula | Formula :\/: Formula | Formula :==&amp;gt;: Formula | Forall Ident Formula | Exist Ident Formula deriving (Eq, Show)   それぞれfirst-order logicの項と論理式の定義です。</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・理論編 その2</title>
        <link>https://myuon.github.io/posts/proof-assistant-theory-2/</link>
        <pubDate>Sun, 17 Dec 2017 00:17:12 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-theory-2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 17日目の記事です。
  昨日に引き続き、Proof Assistantを作る話をしていきます。
 今日は実際にこの後作っていくProof Assistant固有の話をしていきます。
Claire言語とその設計   唐突ですがこれから作るProof Assistantを「Claire1」と呼ぶことにします。
 リポジトリ: myuon/claire
 Claireは実際には複数の言語の組み合わせでできています:
  FOL: Pure logicとしてはfirst-order logicを採用します。
  LK: Proof SystemとしてはLK(Sequent Calculus)を採用します
  Claire: Proof Assistant Claireの証明記述用の言語の名前です
  コマンド記述言語(コマンド定義マクロ): コマンド記述言語はコマンド名からLKの規則の列を生成するものです。今回はHaskellで記述できるようにします。
  HOLライブラリ: Isabelleと同じく、HOLをライブラリとして実装することが出来ます。することができるというだけでかなり大変なのでしませんが。
  LKについて   Proof Systemとして、Sequent Calculus LKを採用します。定義はwikipediaのページでも見るといいんじゃないでしょうか。
 The system LK - Wikipedia
 今回LKを採用した理由として、natural deductionに比べると推論規則を適用した時のゴールの変形の選択肢が少ない(規則を適用する時に必要な情報が少ない)ことがあります。 というか、natural deductionは命題変数の数を減らすelimination ruleを多く含みますがelimination ruleはゴールに対して適用する、つまり下から上に読むと新たな変数を導入することになるので曖昧さが出やすいです。</description>
      </item>
    
      <item>
        <title>Proof Assistantを作る・理論編 その1</title>
        <link>https://myuon.github.io/posts/proof-assistant-theory-1/</link>
        <pubDate>Sat, 16 Dec 2017 00:04:42 +0900</pubDate>
        <guid>https://myuon.github.io/posts/proof-assistant-theory-1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 16日目の記事です。
  さてCSアドベントカレンダーも後半戦ということで、Proof Assistantを作ります。
 Proof Assistantを作ったことがある人は少ないと思うのでまずどういう風に言語を設計していくかという話をしてから、今回実際に作る言語の説明に入ります。
Proof Assistantとは   Proof Assistantは大体次のいずれかの方式をとるものが多いです。
  適当なロジックの適当な公理系の証明を解釈するもの: 数学がやっている証明の形式化をそのままやるやり方です。IsabelleやHOLなど。
  Curry-Howard対応を用いるもの: 要は型付きラムダ計算を直接実装するやり方です。CoqやAgdaなど。
  どっちでも構いませんがどっちを選ぶかによって実装は割と変わってきます。今回はIsabelleと同じく前者の方法をとります。
 ところで、Proof Assistant(言語)には大きく分けると次の2種類の言語を持ちます。
  命題記述言語: これは命題を記述する言語というだけでなく、Proof Assistantに組み込まれているロジックそのものを表現するために必要な言語でもあります。
  証明記述言語: 証明を記述するためには専用の言語が必要な場合があります。ラムダ計算を直接実装する場合はラムダ項そのものでも別に構いません(Agdaみたいな)が、証明を記述するためにメタ言語を載せている言語も(Coqとか)あります。あるいはproverを実装するならこの言語から呼び出せるようにします。
  Isabelleの場合は、前者がPure logicと呼ばれるロジックで、後者はIsarが該当します。
  証明の記述について   証明の記述にはいくつかのやり方があります。ラムダ計算を実装する場合はラムダ項を直接書くようにするのが楽ですが、公理系を実装する場合は真面目に作る必要があります。
 雰囲気としては、次のような操作で記述できるとよさそうです。 (インタラクティブに書けるならこんな感じという気持ちですが、普通にファイルに記述してチェッカーを走らせる場合も裏ではこういう感じになっています)
  Proof Assistantを起動する
  証明したい命題を入力 (例: a -&amp;gt; a)
  現在のゴールが a -&amp;gt; a になる</description>
      </item>
    
      <item>
        <title>Haskellプロジェクトを始めるにあたって</title>
        <link>https://myuon.github.io/posts/haskell-project-setup/</link>
        <pubDate>Fri, 15 Dec 2017 00:04:21 +0900</pubDate>
        <guid>https://myuon.github.io/posts/haskell-project-setup/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 15日目の記事です。
  Computer Science何も関係ないけど大丈夫か？(まぁ一応Haskellはテーマの1つであったというアレはあるけど)
 今回はHaskellで開発を始める時にいつもやってるセットアップの作業とかの説明をします。 どうも、Haskellerによるstackみたいな周辺ツールの情報の発信が足りてないんじゃないかみたいな噂が流れてきたのでじゃあまぁなんか記事にするかという流れです。
 ところでstackの説明はググれば日本語の記事がそれなりにヒットするようになったと思うのでここではあんまり説明しません。
開発環境構築   このセクションは初回のみです。
Haskellのインストール   stackはプロジェクトを管理するツールっていうのかな？まぁビルドツールになったりパッケージマネージャーになったりghcを管理するのに使ったりなんかまぁそういうツールです(なんて言えばいいんだろう)。
 linux系なら公式ドキュメントを見ながら次のようにするといいと思います。
$ curl -sSL https://get.haskellstack.org/ | sh # stackのinstall $ stack setup # GHC(コンパイラ)を入れる   stackを入れてから stack setup でコンパイラが入るのでのんびり待ちます。 ~/.local/bin/ にパスを通しておきます。
  エディタ    emacsの人: intero
  spacemacsの人: haskell layer
  IntelliJ IDEAの人: intellij-haskell
  を使いましょう。その他のエディタは知らない(emacs/intellijのプラグインが特に優秀みたいなので可能ならどっちかを使うのがいいんじゃないでしょうか)。
    プロジェクトセットアップ  stack new   [2017/12/16追記]</description>
      </item>
    
      <item>
        <title>Coroutineモナドとステートマシン</title>
        <link>https://myuon.github.io/posts/coroutine-monad-as-state-machine/</link>
        <pubDate>Thu, 14 Dec 2017 00:03:01 +0900</pubDate>
        <guid>https://myuon.github.io/posts/coroutine-monad-as-state-machine/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 14日目の記事です。
  今回は小ネタです。
 monad-coroutineというライブラリを使って状態遷移してそうなプログラムを書こうみたいな話をします。
Coroutine-monad  example: coroutine   名前の通りmonad-coroutineはコルーチン(つまりプログラムを一旦停止して値を返し、再び停止したところから再開できるような仕組み)を提供します。
 サンプルとしては次のような感じ:
countup :: Coroutine (Yield Int) IO () countup = do lift $ print &amp;#34;counting...&amp;#34; yield 1 lift $ print &amp;#34;counting...&amp;#34; yield 2 return () printProduce :: Show x =&amp;gt; Coroutine (Yield x) IO r -&amp;gt; IO r printProduce producer = pogoStick (\(Yield x cont) -&amp;gt; lift (print x) &amp;gt;&amp;gt; cont) producer {- &amp;gt; printProduce countup counting.</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その4</title>
        <link>https://myuon.github.io/posts/nominal-lambda-4/</link>
        <pubDate>Wed, 13 Dec 2017 00:04:03 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-4/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 13日目の記事です。
  さて、前回はChurch-Rosserを示しました。今回は型付きラムダ計算もやっとかないとだめかなと思ったのでsimply-typedのtype soundnessです。 流石にラムダ計算の話題ばっかりで疲れてきたと思いますが今回は1日ですべて終わらせます。
 まぁCRに比べればずっと簡単なのでいけるでしょ(適当)
 今回解説するコードは以下にあります:
 myuon:typed/theory/Simply.thy
Simply-typed  nominal_datatype simply = TVar string | TArr simply simply (infixr &amp;#34;→&amp;#34; 90)   simply-typedな型はtype variableとfunction typeからなる。 typeの定義自体は特にbinderを含まないが、後に型を含むnominal_inductiveの宣言をしたりする都合上nominal_datatypeにしてある。
valid context   さて型付けに必要になるcontext(変数とその型を組にしたもの)は同じ変数を複数含んではいけないという制約があるので、それを表すvalidという述語を定義する。
inductive valid :: &amp;#34;(name × simply) list ⇒ bool&amp;#34; where valid_nil: &amp;#34;valid []&amp;#34; | valid_cons: &amp;#34;⟦ valid Γ; x ♯ Γ ⟧ ⟹ valid ((x,T)#Γ)&amp;#34; equivariance valid lemma elim_valid_cons: &amp;#34;valid ((x,T)#Γ) ⟹ valid Γ ∧ x ♯ Γ&amp;#34; by (cases rule: valid.</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その3</title>
        <link>https://myuon.github.io/posts/nominal-lambda-3/</link>
        <pubDate>Tue, 12 Dec 2017 00:05:37 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-3/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 12日目の記事です。
  前回はCRの証明の途中までやったので続きです。 内容多めですが今回で頑張って終わらせます。
confluenceへ (cont.)  coherent lemmas   parallel betaのcoherent lemmaを示す。 証明は基本的に場合分けやるだけなので省略するとして、まぁ常識的なことが成り立つよねという補題である。(説明の放棄)
lemma elim_pb_var: &amp;#34;Var x ⇒β N ⟹ N = Var x&amp;#34; lemma elim_pb_abs: assumes &amp;#34;lam [x]. M ⇒β N&amp;#39;&amp;#34; &amp;#34;x ♯ N&amp;#39;&amp;#34; obtains N where &amp;#34;M ⇒β N&amp;#34; &amp;#34;N&amp;#39; = lam [x]. N&amp;#34; lemma elim_pb_app: assumes &amp;#34;M1 $ M2 ⇒β N&amp;#34; obtains N1 N2 where &amp;#34;N = N1 $ N2&amp;#34; &amp;#34;M1 ⇒β N1&amp;#34; &amp;#34;M2 ⇒β N2&amp;#34; | x P P&amp;#39; L where &amp;#34;M1 = lam[x].</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その2</title>
        <link>https://myuon.github.io/posts/nominal-lambda-2/</link>
        <pubDate>Mon, 11 Dec 2017 00:13:11 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 11日目の記事です。
  前回はNominal Isabelleの説明と証明を少しだけしました。 今回から徐々に証明したいことの内容(ラムダ計算そのもの)の話もしていきます。
equivarianceとnominal_inductive  補題   さて2つの補題を示しておく。
lemma subst_eqvt[eqvt]: fixes π :: &amp;#34;var prm&amp;#34; shows &amp;#34;π∙(t[x ::= s]) = (π∙t)[(π∙x) ::= (π∙s)]&amp;#34; apply (nominal_induct t avoiding: x s rule: strong_induct) apply (simp add: perm_bij) apply (simp) apply (simp add: fresh_bij) done lemma subst_rename: assumes &amp;#34;x ♯ t&amp;#34; shows &amp;#34;([(x,y)]∙t) [x ::= s] = t [y ::= s]&amp;#34; using assms apply (nominal_induct t avoiding: x y s rule: lambda.</description>
      </item>
    
      <item>
        <title>Nominal Isabelleとラムダ計算 その1</title>
        <link>https://myuon.github.io/posts/nominal-lambda-1/</link>
        <pubDate>Sun, 10 Dec 2017 00:13:17 +0900</pubDate>
        <guid>https://myuon.github.io/posts/nominal-lambda-1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 10日目の記事です。
  前回、4日分に分けてIMPのoperational semanticsの証明の解説をしてみました。 今回はより発展的な話題として、Nominal Isabelleを用いてChurch-Rosser性やSimply-typedのsoundnessなどを示してみようと思います。
 定理証明に詳しい人ならもうこれだけでつらさが伝わるかと思うのですが、実際証明はかなり大変なので今回は発展編(応用編)としてこの話題を選んでみました。
 今回解説するコードは以下に置いてあります。
 myuon/CR.thy
前置き  ラムダ計算   この記事をわざわざ読む人はラムダ計算についてはある程度知っている人が多いと思うのですが、簡単に説明をしておきます。
 ラムダ計算は計算のモデルとなるべく作られた言語で、「関数を作る・作った関数を呼び出す(関数を適用すること)」の2つの操作を基本とします。 ここでの「計算」とは数を与えたら数を返す、のような、電卓で行われるような最も我々がイメージしやすい計算のことです。ラムダ計算ではこの「計算」を、項を別の項に変換するような操作によって実現します。 これは単に 1+2 という項があったらそれを 3 へと変換する、あるいは f(x)=x+2 という項があるときに、 f(10) を 12 へと変換する、そういう操作を計算と呼びますというだけなので難しいことはありません。
 さてラムダ計算の項(何がラムダ計算の項かはまだちゃんと説明していないけど)は通常変数の付け替えを同一視します。具体的には f(x)=x と f(y)=y を区別しないのですが、この同値をα同値と呼びます。
 ラムダ計算の定理証明で最も厄介なのはこのα同値性の扱いで、というか定理証明による形式化ではそもそも「同一視」とか「同値関係で割る」みたいな操作を扱うのがめちゃくちゃ苦手です。 これは主に、一般に同一視されているかが計算によって判定可能でないこと1と、同一視された項同士の計算はしばしば(人間は気にしないけど)それらの項の変形の構成に依存するからだと個人的には思っています。
 はてさて真面目にラムダ計算の形式化をやると地獄をみますが、そんな時にNominal Isabelleが便利なんですよ〜！っていうのがこの導入です。
  Nominal Isabelle   Nominal Isabelleは(ラムダ項だけではなく; ラムダ計算みたい題材が最も威力を発揮することは間違いないが)binderを含むデータ型を扱う際に利用すると便利なライブラリである。 binderは [x]. M のような形をしていて、この束縛変数 x の変数名の付け替えを区別しないような項である。
 Nominal Isabelleではこの変数の付け替え、「例えば変数 x を y に付け替える」という操作を「置換 (x,y) を作用させる」という操作とみなす、というところからスタートする。 より厳密には次のようなことである: 無限の変数からなる集合 V が与えられている時、 List (V×V) の元を置換と呼ぶ。このとき置換の作用を ∙ でかくことにし、 ((x,y)::xs)∙M := xs∙(Mに出現する自由変数xをyに、yをxに書き換えた項); []∙M := M のようにして定める。</description>
      </item>
    
      <item>
        <title>IsabelleについてのQ&amp;A</title>
        <link>https://myuon.github.io/posts/isabelle-qanda/</link>
        <pubDate>Sat, 09 Dec 2017 00:03:23 +0900</pubDate>
        <guid>https://myuon.github.io/posts/isabelle-qanda/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 9日目の記事です。
  さて、Isabelleの入門編・基礎編が終わったところで、お口直しに(？？)Isabelleで証明していると遭遇するかもしれない疑問に答えたりする記事を用意してみました。
 というか、私がIsabelleを学ぶ過程で公式のリファレンス以外に困った時に頼れるものがなかったりして大変苦労したのでせめて後の人のために身についたノウハウは記事に還元していきたいという気持ちからこういうコーナーを挟んでみました。
Syntax関係  矢印がいっぱいあるんだけど何    =&amp;gt; : HOLのfunction type constructor
  ==&amp;gt; : Pure logicのimplication
  --&amp;gt; : HOLのimplication
    Pure logicってなんですか   (この辺の話は後半のところでもやる予定なんですが)Isabelleはライブラリのとは別に組み込みのロジックあって、これがPure logicと呼ばれています。 そもそもIsabelleは本来Pure logic上で証明を行うproof assistantなんですが、このPure logicの上に別のlogicを構成することが出来て、それがHOLやZFCです。
 なのでHOLの証明は内部的には全てPure logicの証明図に置き換えてcheckされます。 AgdaやCoqなどの言語ではこういうことはしない(組み込みのものをそのまま使う)ので慣れないと不思議に感じるかもしれません。
  依存型とかないんですか   ないよ(無慈悲)
  知らないキーワード・コマンド・attributeが出てきた/便利なコマンドについて知りたい    isar-ref.pdfのAppendixにquick referenceあるので眺めるとよいかも？
      証明関係  Sledgehammerと仲良くなれない   これは慣れもありますが、 (1) goalを優しくする (2) 証明の選び方 の2点がポイントです。</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その4</title>
        <link>https://myuon.github.io/posts/2017csadv-day8/</link>
        <pubDate>Fri, 08 Dec 2017 00:01:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day8/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 8日目の記事です。
  前回は、big-stepがdeterministicであることを示した。
9. Small-step long reduction   csmallを複数回適用した、ということを表す関係を &amp;lt;_,_&amp;gt; ⟶* &amp;lt;_,_&amp;gt; でかいて、次のように定める。
subsubsection {* small-step long reduction *} inductive csmall_long (&amp;#34;&amp;lt;_,_&amp;gt; ⟶* &amp;lt;_,_&amp;gt;&amp;#34;) where SL_refl: &amp;#34;&amp;lt;c,st&amp;gt; ⟶* &amp;lt;c,st&amp;gt;&amp;#34; | SL_trans1: &amp;#34;⟦ &amp;lt;c,st&amp;gt; ⟶ &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt;; &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt; ⟧ ⟹ &amp;lt;c,st&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt;&amp;#34; lemma SL_trans: &amp;#34;⟦ &amp;lt;c,st&amp;gt; ⟶* &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt;; &amp;lt;c&amp;#39;,st&amp;#39;&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt; ⟧ ⟹ &amp;lt;c,st&amp;gt; ⟶* &amp;lt;c&amp;#39;&amp;#39;,st&amp;#39;&amp;#39;&amp;gt;&amp;#34; apply (induction arbitrary: c&amp;#39;&amp;#39; st&amp;#39;&amp;#39; rule: csmall_long.induct) apply simp apply (blast intro: SL_trans1) done lemma SL_SeqStep: &amp;#34;&amp;lt;c1,st&amp;gt; ⟶* &amp;lt;c1&amp;#39;,st&amp;#39;&amp;gt; ⟹ &amp;lt;c1;;c2,st&amp;gt; ⟶* &amp;lt;c1&amp;#39;;;c2,st&amp;#39;&amp;gt;&amp;#34; apply (induction arbitrary: c2 rule: csmall_long.</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その3</title>
        <link>https://myuon.github.io/posts/2017csadv-day7/</link>
        <pubDate>Thu, 07 Dec 2017 00:18:10 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day7/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 7日目の記事です。
  前回はcommandとcommandの評価を定義した。
6. Coherent lemmas  SKIP  subsection {* Coherent lemmas *} lemma coh_B_Skip: assumes &amp;#34;&amp;lt;SKIP,st&amp;gt; ⇓ st&amp;#39;&amp;#34; shows &amp;#34;st = st&amp;#39;&amp;#34; using cbig.cases [OF assms] by auto   始めの補題はSKIPについてで、 &amp;lt;SKIP,st&amp;gt; ⇓ st&amp;#39; ならば st = st&amp;#39; というものである。 直観的には明らかであろうし、証明も場合分けをするだけで済む。
  Ass  lemma coh_B_Ass: assumes &amp;#34;&amp;lt;x ::= a , st&amp;gt; ⇓ st&amp;#39;&amp;#34; shows &amp;#34;st&amp;#39; = st [x ↦ aeval st a]&amp;#34; using cbig.</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その2</title>
        <link>https://myuon.github.io/posts/2017csadv-day6/</link>
        <pubDate>Wed, 06 Dec 2017 00:07:53 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day6/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 6日目の記事です。
  前回はaexp/bexpとそのevaluationを定めた。
3. Commands   さて次にcommandを定義する。
 これはIMPの「命令」や「文」にあたるもので、変数の代入、If文、While文などが用意されている。
section {* Commands *} subsection {* Syntax *} datatype com = CSkip | CAssign id aexp | CSeq com com | CIf bexp com com | CWhile bexp com notation CSkip (&amp;#34;SKIP&amp;#34;) and CAssign (&amp;#34;_ ::= _&amp;#34; [50,50] 90) and CSeq (infixr &amp;#34;;;&amp;#34; 30) and CIf (&amp;#34;IF _ THEN _ ELSE _&amp;#34; 80) and CWhile (&amp;#34;WHILE _ DO _&amp;#34; 90)   comを定義した後、notationによって各コンストラクタをよりそれらしいnotationで記述できるようにしている。 このように定義しておくと、例えば以下のような記述ができるようになる。</description>
      </item>
    
      <item>
        <title>IMPのoperational semantics その1</title>
        <link>https://myuon.github.io/posts/2017csadv-day5/</link>
        <pubDate>Tue, 05 Dec 2017 00:02:29 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day5/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 5日目の記事です。
  今回から実際に実践的な証明をしながらIsabelleの解説をしていこうと思います。 そしてこの記事は一人computer scienceアドベントカレンダーなのでCSらしい話題を、ということで、 IMPのoperational semanticsの話でもしようと思います。
IMPについて   IMPとはimperative languageの頭文字を取ったもので、natとboolを基本型にもつ簡単な手続き型言語です。 CSの教科書とかでよく見かけるやつです。 IMPの定義をし、そのevaluationを定めます。
 ただし、IMPはチューリング完全なので評価は一般には停止しません。つまりプログラムを「評価」して結果を返すような関数は全域関数にはなりません。 このような評価を表す部分関数(関係)を定め、実際にこれがいい感じの性質をもつことを示していきます。
  0. States   IMPの定義を行う前の準備。IMPは変数を扱うことができるので変数名を処理するための型が必要になるのと、プログラムの実行には実際に各変数の値を記録したもの(環境の一種)が必要になるのでそれらを定義する。
section {* States *} type_synonym id = string type_synonym state = &amp;#34;id ⇒ nat&amp;#34; definition empty :: &amp;#34;state&amp;#34; where &amp;#34;empty _ = 0&amp;#34; no_syntax &amp;#34;_maplet&amp;#34; :: &amp;#34;[&amp;#39;a, &amp;#39;a] ⇒ maplet&amp;#34; (&amp;#34;_ /↦/ _&amp;#34;) fun update :: &amp;#34;state ⇒ id ⇒ nat ⇒ state&amp;#34; (&amp;#34;_[_ ↦ _]&amp;#34; [80,80,80] 80) where &amp;#34;update st x n y = (if x = y then n else st y)&amp;#34;   sectionコマンドは証明には影響を与えないが、Sidekickにsectionとして表示されたりLaTeXに出力すると実際に節として扱われたりするもの。chapter, subsectio, subsubsectionなどもある。</description>
      </item>
    
      <item>
        <title>Isabelle/HOLの基本 その3</title>
        <link>https://myuon.github.io/posts/2017csadv-day4/</link>
        <pubDate>Mon, 04 Dec 2017 00:39:09 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day4/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 4日目の記事です。
  テキスト代わりのチュートリアル: prog-prove.pdf
 前回はHOLと自動証明についてやりました。 今回やる4章では、Isarという新しい言語(？)について見ていきます。
4. Isar: A Language for Structured Proofs   IsabelleはIsarという、structured proofを記述するための言語を別に提供している。 これはapplyを繋げて証明をするのとは違い、構造化された証明をキーワードを組み合わせて記述する、より自然言語による証明に近い記述を可能にする言語である。
 Isarのsyntaxのコアは次のようになっている(実際はもっと膨大):
proof = &amp;#39;by&amp;#39; method | &amp;#39;proof&amp;#39; [method] step* &amp;#39;qed&amp;#39; step = &amp;#39;fix&amp;#39; variables | &amp;#39;assume&amp;#39; proposition | [&amp;#39;from&amp;#39; fact+] (&amp;#39;have&amp;#39; | &amp;#39;show&amp;#39;) proposition proof proposition = [name :] &amp;#34;formula&amp;#34;  4.1 Isar by Example   初めにIsarによる証明を見せるので眺めてみよう。
lemma &amp;#34;¬ surj (f :: &amp;#39;a ⇒ &amp;#39;a set)&amp;#34; proof - assume srjf: &amp;#34;surj f&amp;#34; from srjf have fa: &amp;#34;∀A.</description>
      </item>
    
      <item>
        <title>Isabelle/HOLの基本 その2</title>
        <link>https://myuon.github.io/posts/2017csadv-day3/</link>
        <pubDate>Sun, 03 Dec 2017 00:01:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day3/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 3日目の記事です。
  テキスト代わりのチュートリアル: prog-prove.pdf
 前回は導入と型・関数・証明について学びました。 今回やる3章では、HOLについてと証明を書く際に知っておくと便利なあれこれについてです。
3. Logic and Proof Beyond Equality  3.1 Formulas   HOLのformulaの定義は次: form ::= True | False | term = term | ¬ form | form ∧ form | form ∨ form | form --&amp;gt; form | ∀x. form | ∃x. form   termはラムダ式とifとかcaseとかletとかそのへん
  3.2 Sets   &amp;#39;a のsetを &amp;#39;a set とかく。次のようなnotationが定義されている。
  {} , {e1,e2,e3}</description>
      </item>
    
      <item>
        <title>Isabelle/HOLの基本 その1</title>
        <link>https://myuon.github.io/posts/2017csadv-day2/</link>
        <pubDate>Sat, 02 Dec 2017 00:00:44 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day2/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 2日目の記事です。
 さて今回よりIsabelle/HOL(HOLはライブラリの名前)の基本の解説をしていきます。 一応極基本的なことを最初に少し説明をしてから、あとは実践形式で実際に証明を書きながら細かい機能などの説明をしていく予定です。 説明に割くページ数とコンテンツの内容と時間的な問題で、定理証明とは何かなどは詳しく話しません。
Isabelle資料   Isabelleのお勉強のための資料をまとめておきます。
  prog-prove.pdf: 公式チュートリアルの一番基本のやつ。入門するならこれだけは 必ず読みましょう 。チュートリアルは他にもトピックごとに色々あるよ！
  isar-ref: 主にIsarに関するReference Manualだけど慣れてきたら参照する機会が多いと思う。
  caeruiroさんのIsabelle Tutorialシリーズ: 大変貴重な日本語の入門記事。Isabelle-2009を使っているらしいのでもしかしたら古い記述もあるかもしれない。
  Concrete Semantics: Isabelleでプログラミング言語のセマンティクスとかやるテキスト。前半はIsabelle入門、後半はCSのテキストみたいな構成。
  AFP: Archive of Formal Proofs; Isabelleで証明されたあれこれが投稿されてる証明集みたいなサイト
  Isabelleの入門の入門: 遥か昔に書いた記事; 何かの役には立つかもしれない
    このシリーズの目的   prog-prove.pdfを読んでねでチュートリアルを済ませてしまっても良いのですが、まぁ読んでって言って読んでもらった試しがないので もう少し実際に証明を書きながら解説をすることで、英語が読みたくない人や雰囲気だけ知りたい人にも優しい解説シリーズになればいいかなと思っています。 ひとまずこのIsabelle/HOLの基本シリーズでは上のprog-prove.pdfに沿って話を進めていきます。
 内容全部やるなら単なる翻訳になってしまうので適度にぶっ飛ばしつつ要所要所を解説していく感じにします。 定理証明全くしたことないと厳しいこともあるかもぐらいでお願いします。
  はじめに. jEditについて   現在Isabelleが公式にサポートしているのはjEditのみです1。 jEditを起動し、エディター画面とアウトプットパネルが表示されていれば問題ありません。アウトプットパネルはなければ Plugins&amp;gt;Isabelle から表示させます。</description>
      </item>
    
      <item>
        <title>一人CSアドベントカレンダー開催のお知らせ</title>
        <link>https://myuon.github.io/posts/2017csadv-day1/</link>
        <pubDate>Fri, 01 Dec 2017 00:06:00 +0900</pubDate>
        <guid>https://myuon.github.io/posts/2017csadv-day1/</guid>
        <description>これは一人Computer Scienceアドベントカレンダー 1日目の記事です。
概要的なもの   「一人アドベントカレンダーって面白そうだな、やってみたい」みたいなノリで登録したんですが、 25日毎日記事を同じテーマで投稿し続けるのどう考えてもめっちゃ大変なのでやはりここは自分が一番得意な分野で行くしかないかなとなりCS関係ということになりました。
 上のQiitaのページでも書いてますが、キーワードとして&amp;#34;ラムダ計算・定理証明・Haskell・ML・圏論 とかなんかそのへん&amp;#34;を挙げていますので そのへんのお話になります。今のところは無難に定理証明を中心にテーマをいくつか選んでおいたので多分そのへんの話です。
  スケジュール   最終的にはQiitaのカレンダー見ればわかることなんでいいんですが一応今後どういう感じで進めていくのかのスケジュール的なものをまとめておきます。
Isabelle編  Isabelle/HOL入門(3-4日くらい)   最初にIsabelle(ここではHOL系しか扱わない)に入門します。って言ってもチュートリアルの解説をするだけです。 ある程度知ってる人が読む意味はないんですが、Isabelle全く知らん人向けに日本語で読める資料ってあんまりなさそうなので、チュートリアルを適当にやるだけでも実は意味があるんでは的な発想でとりあえずこれをやることにしました。
 真面目に入門したくて英語にそこまで抵抗ない人は公式のprog-prove.pdf読みに行く方が早いです。
  Isabelleでの定理証明・基礎編(3-4日くらい)   ここでは実際にIsabelle/HOLを使った証明を紹介・解説していきます。今の所IMPの意味論ちょろっとやるみたいな感じです。 Isabelleの解説がメインなので内容は薄いですがIsabelleってこうやって使うんだよ〜証明ってこうやって書くんだよ〜って雰囲気が伝わればいいかなと思っています。 (そういうのが伝わる日本語資料もあんまりない気がしたので)
  Isabelleでの定理証明・実践編(2-3日+2日？くらい)   せっかくなので個人的にこの前お世話になったりしたNominal Isabelle使ってtyped lambda calculusの簡単な証明とかやってみようかなという内容です。 あとかつてIsabelleで圏論(Yoneda lemma示すくらいまで)もやったことあるのでその解説もやってもいいかもしれないということで2日分くらいは余裕を持たせてあります。
 この辺は後で変更あるかも知れないのでそのへんはあしからず。
    Haskell編  ライブラリ紹介(1日1ライブラリ, 日数未定)   Haskellで最近使ったり使ってなかったりするライブラリの紹介とか解説とかをします。 ここ以外のコンテンツで25日分埋まらなかった場合に備えて空けてある枠なので日数は未定です。 Haskell編の最初にまとめてやるかも不明ですが一応ってことで。
  定理証明支援系を作ろう・理論編(2-3日くらい)   ここからがメインコンテンツで、Haskellを使ってproof assistantを作ります。 (最初に断っておくとproverは作りません。あくまでcheckerとそのassistする部分がメインです。)</description>
      </item>
    
      <item>
        <title>HakyllからHugoに移行した</title>
        <link>https://myuon.github.io/posts/migrate-to-hugo/</link>
        <pubDate>Fri, 10 Nov 2017 02:37:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/migrate-to-hugo/</guid>
        <description>移行理由   前はHakyll+pandocでorg-modeで書く→htmlに変換してgithub pagesで公開という手順を踏んでいたのだけれど、pandocのorg-mode対応が中途半端すぎて、対応していない記法があったりcode block(こういうの)の中で特殊な記号を使うと上手くパース出来なかったりして色々厳しくなってきていたというのが理由。 困ってたところにhugoというのを教えてもらったのでそれに移行することにした。
  手順諸々  導入   hugoをsnapdから入れて使う。テストサイトを作って挙動を確認してから必要なものをsourceブランチに持ってきて導入はおしまい。 各記事はfront matterを少し書きなおすだけ。ありがたいことにorg-modeでかく場合は大体似たような文法なのでちょこっと書き換えるだけで動く。
 hugo serve --watch --buildDrafts でドラフトも見れるようにできるので、ドラフト確認してOKならhugoからpublishするというのが正しいフローっぽい。
  テーマ   Hakyllの時からテーマは自作していたのでテンプレートのカスタマイズとcssを持ってくるみたいな作業が必要になったのでやった。 hugo new theme [テーマ名] で必要なファイル群が themes にできるのであとは Templates にテンプレートの公式ドキュメントがあるのでそれとかhugoの実際のテンプレートを見てカスタマイズをした。
 まぁ変に汎用性とか気にしなければ簡単、だと思う。
  コードのsyntax highlight   config.tomlに
pygmentscodefences = true pygmentsstyle = &amp;#34;manni&amp;#34;   と書いた。 pygmentscodefencesはmarkdownで ```lang みたいに書けるようにするやつだけど、org-modeのcode blockもありがたいことに対応してくれてたのでそのまま色がついた。
 カラースキームはPygmentsの公式サイトから色々試してしっくり来るやつを探すと良さそう。
syntax highlight関係のデザイン   pandocではsyntax highlight用にcssを用意して色を指定していたんだけどそれが不要になった。 それと、pygmentsstyleで色をつけるとpreの背景の色を強制的に指定されてしまうので今までは色をつけてたんだけどそれを外した(文章中のcodeはそのままにしてる)。</description>
      </item>
    
      <item>
        <title>n番煎じのrecursion-scheme</title>
        <link>https://myuon.github.io/posts/recursion-scheme/</link>
        <pubDate>Fri, 27 Oct 2017 00:59:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/recursion-scheme/</guid>
        <description>前提になりそうなことをちょこっとPreliminariesに書いた.
Recursion schemes   以下, C は適当な条件を満たすfunctor F: C -&amp;gt; C がFixをもち, さらにそれがCofixにもなっていることを仮定する1. 以下ではこの適当な条件を満たすfunctorしか考えないものとする.
catamorphism   F-algebra p: FA -&amp;gt; A に対し, D のinitialityにより得られる射 cata(p): D -&amp;gt; A を catamorphism とよぶ. これは in; cata(p) = fmap F cata(p); p: FD -&amp;gt; A を満たす.
  anamorphism   catamorphismの双対. F-coalgebra q: A -&amp;gt; FA に対し, D のterminalityにより得られる射 ana(q): A -&amp;gt; D を anamorphism とよぶ. これは q; fmap F ana(q) = ana(q); out を満たす.</description>
      </item>
    
      <item>
        <title>Overlapping Instancesと戦う</title>
        <link>https://myuon.github.io/posts/overlapping-instances/</link>
        <pubDate>Mon, 21 Aug 2017 00:31:03 +0900</pubDate>
        <guid>https://myuon.github.io/posts/overlapping-instances/</guid>
        <description>Overlapping Instances   Haskellで少し凝ったinstanceをいくつか書いたりしているとoverlapping instancesに悩まされることはよくある。 この辺のまとまった解説があると便利なのではと思ったので書く。
  ユーザーガイドにて   実際、overlapping instancesが何故起こるのかについてはGHCユーザーガイドにそれなりに詳しく書いてあるのでそこを読めば良いと思う。
 GHCユーザーガイド - Overlapping instances
 勝手に抄訳すると次のような感じ
9.8.3.6 Overlapping instances   一般に、Instance resolutionで述べたように、 GHCは、型クラス制約を解決するために使用されるinstance宣言が曖昧ではないことを要求する。 GHCは、 最も具体的な形が存在する時に限って 複数のinstanceにマッチすることを許すという方法で、instanceの解決を緩める方法も提供している。さらに、これはもっと緩くすることもできて、最も具体的な形があるかどうかにかかわらず、複数のinstanceにマッチすることを許すこともできる。この節で詳しく述べる。
 instanceの選択をコントロールするには、それぞれのinstanceについてオーバーラップしたときの挙動を指定することができる。 instance キーワードの直後に次のいずれかのプラグマを書けば良い: {-# OVERLAPPING #-}, {-# OVERLAPPABLE #-}, {-# OVERLAPS #-} または {-# INCOHERENT #-}
  INCOHERENT はinstanceが自由にoverlapしたりされたりすることを許すが、使わないほうがいいプラグマなので出来る限り避けたほうがいい。 また、後にもあるように OVERLAPS は OVERLAPPING と OVERLAPPABLE のいずれにもなるので OVERLAPS で事足りる場合も多いと思う。
 また、いちいちプラグマを書かなくてもいいように、デフォルトの挙動を指定するための拡張 -XIncoherentInstances と -XOverlappingInstances も あるけれど使用は出来る限り避けよう。</description>
      </item>
    
      <item>
        <title>HakyllでBlogを作る</title>
        <link>https://myuon.github.io/posts/hakyll-blog/</link>
        <pubDate>Wed, 16 Aug 2017 22:39:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/hakyll-blog/</guid>
        <description>Hakyllでこのブログを作ったのでそのあれこれを
概要   やりたいことは以下
  orgで文章をかく(大事)
  orgから良い感じのHTMLを生成し
  github pagesで公開
    Hakyllのsetup   次を参考にした
  Hakyll Tutorials
  Hakyll, stack, Travis CI, Github でブログを管理する
  GitHub Pages はじめました
  hakyll package
  stack でパッケージを入れて、 hakyll-init → stack build → stack exec site watch で動かすところまでは簡単にいけた 2番目のリンクにあるように、 _site をsubmoduleに登録しておいて、これをmasterブランチにpushして公開するようにしておく
  文書の変換・Hakyllの設定   プロジェクトの構造は次のようになっている
- root - _site できたHTMLファイルが置かれる - _cache - css できたCSSファイルが置かれる(圧縮済) - images 画像ファイルが(ry - posts ここにorg or markdownで書いた記事を入れる - site.</description>
      </item>
    
  </channel>
</rss>
