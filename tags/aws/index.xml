<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on The curse of λ</title>
    <link>https://myuon.github.io/tags/aws/</link>
    <description>Recent content in AWS on The curse of λ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Fri, 03 Apr 2020 01:10:11 +0900</lastBuildDate>
    
      <atom:link href="https://myuon.github.io/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>Lightsailでやっていくサービス開発</title>
        <link>https://myuon.github.io/posts/try-lightsail/</link>
        <pubDate>Fri, 03 Apr 2020 01:10:11 +0900</pubDate>
        <guid>https://myuon.github.io/posts/try-lightsail/</guid>
        <description>ジト目王国を始めた ジト目王国というサービスを始めました。ガチャでみょんポイントが引けます。(はい)
ところでこのサービスは現在AWSで維持されていて、固定費としてかかるのは月$3.5程度で済んでる(厳密には通信費とかあるけどGB単位でアレしないとかからないのでまぁ今の位の規模なら無視していいと思う)ので、せっかくなのでAWSでのあれこれを解説していく。
アプリの構成  APIサーバー: Rust製 DB: MySQL ↑の2つをdocker-composeに乗せてサービスとして運用(この構成だと1インスタンスにDBとAPIサーバーが同居しているのでAPIサーバーに負荷がかかるとDBが死ぬ危険性がある。まぁあくまで個人開発の小規模な時期にお金を頑張って節約したいという前提があるということで…) クライアントサイドはNowでホスティング  Lightsail LightsailはEC2をいい感じにパッケージングしたみたいなサービス。AWSとは思えないほど管理画面が使いやすいことと、基本的に全部のせでインスタンスだけでなく監視(CloudWatch)やロードバランサー(ALB)やDNSレコード管理(Route53)などが全部中途半端な状態でついてくるという便利なのかそうでないのかよくわからない感じのサービス。
使い方として(実際AWSも言っているが)最初はLightsailで維持して、規模が大きくなってきたらAMIを吐いてEC2に移行するのが割とおすすめ。
インフラ構成 インスタンスの確保 インスタンスは適当にぽちぽちして確保する。一番安いプランだと$3.5で、512MBと1vCPU(t2.nano程度のスペック)、20GBのEBSボリュームなどがついてくる。AWSでサービス開発してるとなんやかんや色々なサービス使わせられて、覚えるのが大変な上、合計利用料金が慣れないと読みづらいというのが解消されていて割と良いと思う。このプランで、Amazon Linuxを選択する。
一つ注意としては、AMIが現在Amazon Linux 2ではなくAmazon Linuxのせいで、情報を探すときは気をつけたほうがいい。他のディストリビューションでもいいけどAmazon Linux使っておくほうが多分何かと便利。
SSMの設定 LightsailはデフォルトだとHTTPの80番ポートとSSHの22番ポートが空いているが、まぁ22番ポートなんぞ全世界公開したくないし2020年なのでインスタンスへはSSM セッションマネージャー経由でアクセスをする。注意としてLightsailは現状(公式には)セッションマネージャーに対応しておらず、さらにAmazon Linuxだとagentが古いので自力で頑張る必要がある。
 amazon-ssm-agentをアップデートする: https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-manual-agent-install.html 次に、SSMを利用するためアクティベーションコードの発行を行う: https://qiita.com/kooohei/items/35340bd9d36163c33f54  最初にAmazonSSMManagedInstanceCoreをポリシーとしてアタッチされたロールを作成する アクティベーションコードを発行する インスタンスの中に入って、 amazon-ssm-agent コマンドを叩いてアクティベーションを行う あとは22番ポートを閉じてから、SSMのセッションマネージャーからセッションを起動する    アプリを動かす  dockerとdocker-composeをインストール: https://qiita.com/shinespark/items/a8019b7ca99e4a30d286  インスタンスに入って適当に docker-compose up とかする。この辺はAWS関係ないのでまぁ省略。
EIPの付与  アプリが動いたら静的IPでアクセスできることを確認する Elastic IPをLightsailの中で作成して貼り付ける。EIPはアタッチしているインスタンスが動いてると無料だけどインスタンスが停止しているときやどのインスタンスにもアタッチされてないと課金されるので無闇に作らないようにしよう。  SSLターミネーション 2020年なのでHTTPSに対応する必要があるわけだけど、自分で証明書の鍵の管理とかしたくないでござる〜ってことでマネージドサービス使いたいならCloudFrontを使うとできるが、ただ労力に見合ってない感じがあるのでnginxコンテナ生やすほうが早いでしょというのはそうかも…。まぁCloudFront入れておけばSSLターミネーションの他についでにキャッシュとDDoS対策も付いてくるのでお得！(ほんまか)
 まずRoute53でドメインを取得する(example.com など) ACMで証明書を発行する。例えば example.com をwebサイトそのもののために使って、APIサーバーでは api.example.com を使いたい場合はACMで *.example.com の証明書を発行する必要があることと、us-east-1リージョンで発行する必要があることに注意。 Route53でAレコードを登録する。ここで使うゾーンはLightsailインスタンス専用のやつで外には公開しないものなので、 api-lightsail.</description>
      </item>
    
      <item>
        <title>Pipeline Resolverを使ったAppSync Authorizerパターン</title>
        <link>https://myuon.github.io/posts/pipeline-resolver-authorizer/</link>
        <pubDate>Sun, 16 Jun 2019 14:26:31 +0900</pubDate>
        <guid>https://myuon.github.io/posts/pipeline-resolver-authorizer/</guid>
        <description>調べたけどあんまり情報がなかったので。
AppSync Pipeline Resolver AppSyncにはPipeline Resolverというリゾルバーがあり、これによって複数のリゾルバーを指定できる、とある。
CFnにはfunctionConfigurationを指定するといいよと書いてある。serverless-appsync-pluginだと次のように書ける。
custom:appSync:mappingTemplates:- type:Queryfield:testPipelineQueryrequest:&amp;#39;./mapping-templates/before.vtl&amp;#39;# the pipeline&amp;#39;s &amp;#34;before&amp;#34; mapping templateresponse:&amp;#39;./mapping-templates/after.vtl&amp;#39;# the pipeline&amp;#39;s &amp;#34;after&amp;#34; mapping templatekind:PIPELINEfunctions:- authorizeFunction- fetchDataFunctionfunctionConfigurations:- dataSource:graphqlLambdaname:&amp;#39;authorizeFunction&amp;#39;request:&amp;#39;./mapping-templates/authorize-request.vtl&amp;#39;response:&amp;#39;./mapping-templates/common-response.vtl&amp;#39;- dataSource:dataTablename:&amp;#39;fetchDataFunction&amp;#39;request:&amp;#39;./mapping-templates/fetchData.vtl&amp;#39;response:&amp;#39;./mapping-templates/common-response.vtl&amp;#39;でこれが意外とわかりにくいのだがドキュメントをよく読むと次のような意味であることがわかる。
 リゾルバーに対して指定できる処理の単位を&amp;quot;function&amp;quot;とここでは呼んでいる functionを複数指定すると、それぞれが順番に実行される functionには(通常のリゾルバー同様)リクエスト・レスポンスマッピングテンプレートを指定する 上記とは別に、pipelineの最初と最後にマッピングテンプレートを指定する DynamoDBリゾルバー、Lambdaリゾルバーも内部では1つの&amp;quot;functionからなる&amp;quot; Pipeline ResolverでLambdaに通してからDynamoDBに送るみたいなことをしたいなら2つのfunctionをlambda dataSource, dynamodb dataSourceを指定して作成する必要がある  で、上のような例だと次のように処理が進む
before mapping template ↓ authorizeFunction request mapping template ↓ authorizeFunction本体 ↓ authorizeFunction response mapping template ↓ fetchDataFunction request mapping template ↓ fetchDataFunction本体 ↓ fetchDataFunction response mapping template ↓ after mapping template functionという概念はpipeline resolverにしか出てこないが他のリゾルバーでも内部的には使われてるとみなして良いと思う。
Authorizer 上の例でもあるように、DyanmoDB Resolverにcustom authorizerを付けたいというようなユースケースではPipeline Resolverを使うのが良い。</description>
      </item>
    
      <item>
        <title>DynamoDB LocalをTerraformから使う</title>
        <link>https://myuon.github.io/posts/dynanmodb-local-terraform/</link>
        <pubDate>Mon, 11 Feb 2019 00:22:05 +0900</pubDate>
        <guid>https://myuon.github.io/posts/dynanmodb-local-terraform/</guid>
        <description>タイトルの通り。大体以下のPRの説明読めば分かる。
https://github.com/hashicorp/terraform/pull/2825
Terraform側の設定 local envで環境を作ってDynamoDB Localをテスト用途で動かすという前提。以下がproject structure。
&amp;lt;project root&amp;gt; - infrastructure - local/ - main.tf ここにDynamoDB Localの設定を入れる - modules/ - dynamodb/table.tf ここにテーブルの設定など infrastructure/local/main.tfでは、endpointsを指定することができる。(デプロイ時にこのendpointを参照してテーブルを作ったりする)
provider &amp;quot;aws&amp;quot; { region = &amp;quot;ap-northeast-1&amp;quot; endpoints { dynamodb = &amp;quot;http://localhost:8000&amp;quot; } } DynamoDB Localは普通に動かせばよい。
port:8000で起動させたら、いつも通りterraform -e dev applyでDynamoDB Localにテーブルができる。
スクリプト テストで使おうと思ったら、このDynamoDB Localを立ち上げる→terraform apply→テスト実行→DynamoDB Localを落とすを何度も繰り返すことになって面倒なので、私はMakefileを書いている。
install: mkdir -p ./infrastructure/local/.dynamodb cd ./infrastructure/local/.dynamodb; \ 	wget https://s3-ap-northeast-1.amazonaws.com/dynamodb-local-tokyo/dynamodb_local_latest.tar.gz; \ 	tar -xf ./dynamodb_local_latest.tar.gz test: $(MAKE) startTest # ここでテスト export ...; \ 	go test .</description>
      </item>
    
      <item>
        <title>Lambda FunctionをReasonで書く</title>
        <link>https://myuon.github.io/posts/serverless-reason/</link>
        <pubDate>Fri, 23 Nov 2018 21:00:48 +0900</pubDate>
        <guid>https://myuon.github.io/posts/serverless-reason/</guid>
        <description>Reason ML、やっていこうな 世はまさに大サーバーレス時代なのでLambda Functionやっていきというお気持ち。
AWS Lambdaで現時点(2018年11月)で対応されている言語はNode.js, Python, Go, C#(dotnet), Javaの5つ。このうち後ろ2つはコールドスタートが激遅なので使い物にならない。で前3つのうちではドキュメントの多いNode.jsが安定ですが、Node.jsをランタイムに採用するとしてしかしJSは書きたくない、そういうときにReason MLはいい感じな選択肢なのでは？というのがこの記事の趣旨です。
serverless-reason serverless frameworkというサーバーレスアプリをやるのにとても便利なツールがあって、それのReasonで動くテンプレートを作っておいたので好きに使ってくださいという感じ。
  以下このプロジェクトの中身の解説をする。
echo.re Lambda Functionとしてechoというものがsrc/functions/echo.reに定義されている。
/* Sorry I&amp;#39;m a lazy person! */ type event = { . &amp;#34;pathParameters&amp;#34;: Js.Dict.t(string), }; type context = unit; type callback = (. Js.null(string), Js.Json.t) =&amp;gt; Js.Promise.t(unit); type response = { . &amp;#34;statusCode&amp;#34;: int, &amp;#34;body&amp;#34;: string, }; let handler : (event, context, callback) =&amp;gt; Js.Promise.t(response) = (event, _, _) =&amp;gt; { Js.</description>
      </item>
    
  </channel>
</rss>
